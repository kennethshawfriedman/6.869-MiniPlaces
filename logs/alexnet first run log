[2017-11-05 01:53:01]:
-Iter 0, Training Loss= 4.9348, Accuracy Top1 = 0.00, Top5 = 0.06
-Iter 0, Validation Loss= 4.9592, Accuracy Top1 = 0.03, Top5 = 0.06
[2017-11-05 01:56:46]:
-Iter 50, Training Loss= 4.6064, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 50, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 01:59:16]:
-Iter 100, Training Loss= 4.6090, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 100, Validation Loss= 4.6071, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 02:01:46]:
-Iter 150, Training Loss= 4.6030, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 150, Validation Loss= 4.6029, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 02:04:15]:
-Iter 200, Training Loss= 4.6080, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 200, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 02:06:45]:
-Iter 250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 250, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 02:09:15]:
-Iter 300, Training Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 300, Validation Loss= 4.6037, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:11:46]:
-Iter 350, Training Loss= 4.6068, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 350, Validation Loss= 4.6079, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 02:14:18]:
-Iter 400, Training Loss= 4.6052, Accuracy Top1 = 0.02, Top5 = 0.05
-Iter 400, Validation Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.05
[2017-11-05 02:16:50]:
-Iter 450, Training Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 450, Validation Loss= 4.6066, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 02:19:22]:
-Iter 500, Training Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 500, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.05
[2017-11-05 02:21:54]:
-Iter 550, Training Loss= 4.6063, Accuracy Top1 = 0.00, Top5 = 0.02
-Iter 550, Validation Loss= 4.6048, Accuracy Top1 = 0.00, Top5 = 0.05
[2017-11-05 02:24:25]:
-Iter 600, Training Loss= 4.6071, Accuracy Top1 = 0.00, Top5 = 0.02
-Iter 600, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 02:26:57]:
-Iter 650, Training Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 650, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:29:29]:
-Iter 700, Training Loss= 4.6067, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 700, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:32:01]:
-Iter 750, Training Loss= 4.6055, Accuracy Top1 = 0.02, Top5 = 0.05
-Iter 750, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 02:34:32]:
-Iter 800, Training Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 800, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 02:37:04]:
-Iter 850, Training Loss= 4.6062, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 850, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.02
[2017-11-05 02:39:36]:
-Iter 900, Training Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.06
-Iter 900, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 02:42:07]:
-Iter 950, Training Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 950, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:44:39]:
-Iter 1000, Training Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 1000, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 02:47:11]:
-Iter 1050, Training Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 1050, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 02:49:42]:
-Iter 1100, Training Loss= 4.6061, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 1100, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:52:14]:
-Iter 1150, Training Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 1150, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 02:54:45]:
-Iter 1200, Training Loss= 4.6065, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 1200, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 02:57:17]:
-Iter 1250, Training Loss= 4.6056, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 1250, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 02:59:48]:
-Iter 1300, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 1300, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 03:02:20]:
-Iter 1350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 1350, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 03:04:52]:
-Iter 1400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 1400, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.05
[2017-11-05 03:07:23]:
-Iter 1450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 1450, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 03:09:55]:
-Iter 1500, Training Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 1500, Validation Loss= 4.6049, Accuracy Top1 = 0.02, Top5 = 0.05
[2017-11-05 03:12:26]:
-Iter 1550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 1550, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 03:14:58]:
-Iter 1600, Training Loss= 4.6061, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 1600, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 03:17:30]:
-Iter 1650, Training Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 1650, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 03:20:01]:
-Iter 1700, Training Loss= 4.6063, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 1700, Validation Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 03:22:33]:
-Iter 1750, Training Loss= 4.6055, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 1750, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 03:25:04]:
-Iter 1800, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 1800, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 03:27:36]:
-Iter 1850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 1850, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 03:30:07]:
-Iter 1900, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 1900, Validation Loss= 4.6040, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 03:32:39]:
-Iter 1950, Training Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 1950, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 03:35:11]:
-Iter 2000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 2000, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
[2017-11-05 03:37:42]:
-Iter 2050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 2050, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 03:40:14]:
-Iter 2100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2100, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 03:42:45]:
-Iter 2150, Training Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2150, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 03:45:17]:
-Iter 2200, Training Loss= 4.6063, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 2200, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 03:47:49]:
-Iter 2250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 2250, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 03:50:20]:
-Iter 2300, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2300, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 03:52:52]:
-Iter 2350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 2350, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 03:55:24]:
-Iter 2400, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2400, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 03:57:55]:
-Iter 2450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 2450, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 04:00:27]:
-Iter 2500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 2500, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.01
[2017-11-05 04:02:58]:
-Iter 2550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2550, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:05:30]:
-Iter 2600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 2600, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 04:08:01]:
-Iter 2650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:10:33]:
-Iter 2700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 2700, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 04:13:04]:
-Iter 2750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 2750, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:15:36]:
-Iter 2800, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2800, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:18:08]:
-Iter 2850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 2850, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 04:20:39]:
-Iter 2900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 2900, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 04:23:11]:
-Iter 2950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 2950, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:25:43]:
-Iter 3000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 3000, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 04:28:14]:
-Iter 3050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 3050, Validation Loss= 4.6049, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 04:30:46]:
-Iter 3100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 3100, Validation Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 04:33:17]:
-Iter 3150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 3150, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 04:35:49]:
-Iter 3200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 3200, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 04:38:20]:
-Iter 3250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 3250, Validation Loss= 4.6044, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:40:52]:
-Iter 3300, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 3300, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 04:43:24]:
-Iter 3350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 3350, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 04:45:55]:
-Iter 3400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 3400, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 04:48:27]:
-Iter 3450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 3450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 04:50:58]:
-Iter 3500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 3500, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 04:53:30]:
-Iter 3550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 3550, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 04:56:02]:
-Iter 3600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 3600, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 04:58:33]:
-Iter 3650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 3650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 05:01:05]:
-Iter 3700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 3700, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 05:03:36]:
-Iter 3750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 3750, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 05:06:08]:
-Iter 3800, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 3800, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 05:08:39]:
-Iter 3850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 3850, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 05:11:11]:
-Iter 3900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 3900, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.06
[2017-11-05 05:13:42]:
-Iter 3950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 3950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 05:16:14]:
-Iter 4000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 4000, Validation Loss= 4.6050, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 05:18:46]:
-Iter 4050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4050, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 05:21:17]:
-Iter 4100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4100, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 05:23:49]:
-Iter 4150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4150, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 05:26:21]:
-Iter 4200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4200, Validation Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 05:28:52]:
-Iter 4250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 4250, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 05:31:24]:
-Iter 4300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4300, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 05:33:55]:
-Iter 4350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 4350, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 05:36:27]:
-Iter 4400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 4400, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 05:38:59]:
-Iter 4450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 4450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 05:41:30]:
-Iter 4500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 4500, Validation Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 05:44:02]:
-Iter 4550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 4550, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 05:46:33]:
-Iter 4600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4600, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 05:49:05]:
-Iter 4650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 05:51:36]:
-Iter 4700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4700, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 05:54:08]:
-Iter 4750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 4750, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 05:56:40]:
-Iter 4800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 4800, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 05:59:11]:
-Iter 4850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 4850, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:01:43]:
-Iter 4900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 4900, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:04:15]:
-Iter 4950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 4950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:06:46]:
-Iter 5000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 5000, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:09:18]:
-Iter 5050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 5050, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:11:50]:
-Iter 5100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5100, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:14:21]:
-Iter 5150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5150, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:16:53]:
-Iter 5200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 5200, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:19:25]:
-Iter 5250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 5250, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:21:56]:
-Iter 5300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5300, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:24:28]:
-Iter 5350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 5350, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 06:26:59]:
-Iter 5400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 5400, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:29:31]:
-Iter 5450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 5450, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:32:02]:
-Iter 5500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 5500, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 06:34:34]:
-Iter 5550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 5550, Validation Loss= 4.6049, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:37:06]:
-Iter 5600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5600, Validation Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 06:39:37]:
-Iter 5650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5650, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 06:42:09]:
-Iter 5700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5700, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 06:44:41]:
-Iter 5750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 5750, Validation Loss= 4.6044, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:47:12]:
-Iter 5800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 5800, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 06:49:44]:
-Iter 5850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 5850, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 06:52:15]:
-Iter 5900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 5900, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 06:54:47]:
-Iter 5950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 5950, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 06:57:18]:
-Iter 6000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 6000, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 06:59:50]:
-Iter 6050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6050, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 07:02:22]:
-Iter 6100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6100, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 07:04:53]:
-Iter 6150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6150, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 07:07:25]:
-Iter 6200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 6200, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 07:09:57]:
-Iter 6250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 6250, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 07:12:28]:
-Iter 6300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6300, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 07:15:00]:
-Iter 6350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 6350, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 07:17:31]:
-Iter 6400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 6400, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.06
[2017-11-05 07:20:03]:
-Iter 6450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 6450, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 07:22:35]:
-Iter 6500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 6500, Validation Loss= 4.6050, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 07:25:06]:
-Iter 6550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 6550, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 07:27:38]:
-Iter 6600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6600, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 07:30:09]:
-Iter 6650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6650, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 07:32:41]:
-Iter 6700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6700, Validation Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 07:35:13]:
-Iter 6750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 6750, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 07:37:44]:
-Iter 6800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 6800, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 07:40:16]:
-Iter 6850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 6850, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 07:42:47]:
-Iter 6900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 6900, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 07:45:19]:
-Iter 6950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 6950, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 07:47:51]:
-Iter 7000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 7000, Validation Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 07:50:22]:
-Iter 7050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 7050, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 07:52:54]:
-Iter 7100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7100, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 07:55:26]:
-Iter 7150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 7150, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 07:57:57]:
-Iter 7200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7200, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 08:00:29]:
-Iter 7250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 7250, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:03:00]:
-Iter 7300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7300, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 08:05:32]:
-Iter 7350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 7350, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:08:04]:
-Iter 7400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 7400, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:10:35]:
-Iter 7450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 7450, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:13:07]:
-Iter 7500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 7500, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:15:39]:
-Iter 7550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7550, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:18:10]:
-Iter 7600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7600, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:20:42]:
-Iter 7650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7650, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:23:13]:
-Iter 7700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7700, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:25:45]:
-Iter 7750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 7750, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:28:17]:
-Iter 7800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 7800, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:30:48]:
-Iter 7850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 7850, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 08:33:20]:
-Iter 7900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 7900, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:35:51]:
-Iter 7950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 7950, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:38:23]:
-Iter 8000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 8000, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 08:40:55]:
-Iter 8050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8050, Validation Loss= 4.6049, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:43:26]:
-Iter 8100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8100, Validation Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 08:45:58]:
-Iter 8150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 8150, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 08:48:29]:
-Iter 8200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8200, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 08:51:01]:
-Iter 8250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 8250, Validation Loss= 4.6044, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 08:53:32]:
-Iter 8300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8300, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 08:56:04]:
-Iter 8350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 8350, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 08:58:36]:
-Iter 8400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 8400, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 09:01:07]:
-Iter 8450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 8450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 09:03:39]:
-Iter 8500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 8500, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 09:06:11]:
-Iter 8550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8550, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 09:08:42]:
-Iter 8600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8600, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 09:11:14]:
-Iter 8650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 09:13:45]:
-Iter 8700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8700, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 09:16:17]:
-Iter 8750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 8750, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 09:18:48]:
-Iter 8800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 8800, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 09:21:20]:
-Iter 8850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 8850, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 09:23:52]:
-Iter 8900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 8900, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.06
[2017-11-05 09:26:23]:
-Iter 8950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 8950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 09:28:55]:
-Iter 9000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 9000, Validation Loss= 4.6050, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 09:31:26]:
-Iter 9050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9050, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 09:33:58]:
-Iter 9100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9100, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 09:36:29]:
-Iter 9150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9150, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 09:39:01]:
-Iter 9200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9200, Validation Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 09:41:33]:
-Iter 9250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 9250, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 09:44:05]:
-Iter 9300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9300, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 09:46:36]:
-Iter 9350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 9350, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 09:49:08]:
-Iter 9400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 9400, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 09:51:39]:
-Iter 9450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 9450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 09:54:11]:
-Iter 9500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 9500, Validation Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 09:56:42]:
-Iter 9550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 9550, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 09:59:14]:
-Iter 9600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 9600, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 10:01:46]:
-Iter 9650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:04:18]:
-Iter 9700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9700, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 10:06:49]:
-Iter 9750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.05
-Iter 9750, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:09:21]:
-Iter 9800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 9800, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 10:11:53]:
-Iter 9850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 9850, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:14:24]:
-Iter 9900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 9900, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 10:16:56]:
-Iter 9950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 9950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
Model saved at Iter 10000 !
[2017-11-05 10:19:30]:
-Iter 10000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 10000, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:22:02]:
-Iter 10050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10050, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:24:34]:
-Iter 10100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 10100, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:27:07]:
-Iter 10150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10150, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:29:39]:
-Iter 10200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10200, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:32:11]:
-Iter 10250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 10250, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:34:43]:
-Iter 10300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10300, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:37:15]:
-Iter 10350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 10350, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 10:39:47]:
-Iter 10400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 10400, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:42:19]:
-Iter 10450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 10450, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 10:44:51]:
-Iter 10500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 10500, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 10:47:23]:
-Iter 10550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10550, Validation Loss= 4.6049, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:49:55]:
-Iter 10600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 10600, Validation Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 10:52:28]:
-Iter 10650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10650, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 10:55:00]:
-Iter 10700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 10700, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 10:57:31]:
-Iter 10750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 10750, Validation Loss= 4.6044, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 11:00:03]:
-Iter 10800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 10800, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 11:02:35]:
-Iter 10850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 10850, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 11:05:07]:
-Iter 10900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 10900, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 11:07:39]:
-Iter 10950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 10950, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 11:10:11]:
-Iter 11000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 11000, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 11:12:43]:
-Iter 11050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11050, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 11:15:15]:
-Iter 11100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11100, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 11:17:48]:
-Iter 11150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 11150, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 11:20:19]:
-Iter 11200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11200, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 11:22:51]:
-Iter 11250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 11250, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 11:25:23]:
-Iter 11300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11300, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 11:27:55]:
-Iter 11350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 11350, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 11:30:28]:
-Iter 11400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 11400, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.06
[2017-11-05 11:32:59]:
-Iter 11450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 11450, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 11:35:31]:
-Iter 11500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 11500, Validation Loss= 4.6050, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 11:38:04]:
-Iter 11550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 11550, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 11:40:36]:
-Iter 11600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11600, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 11:43:07]:
-Iter 11650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11650, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 11:45:40]:
-Iter 11700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11700, Validation Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 11:48:11]:
-Iter 11750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 11750, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 11:50:44]:
-Iter 11800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 11800, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 11:53:16]:
-Iter 11850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 11850, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 11:55:48]:
-Iter 11900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 11900, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 11:58:20]:
-Iter 11950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 11950, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 12:00:51]:
-Iter 12000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 12000, Validation Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 12:03:23]:
-Iter 12050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12050, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 12:05:55]:
-Iter 12100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12100, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 12:08:27]:
-Iter 12150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12150, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:10:59]:
-Iter 12200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12200, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 12:13:31]:
-Iter 12250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 12250, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 12:16:03]:
-Iter 12300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12300, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 12:18:35]:
-Iter 12350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 12350, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 12:21:07]:
-Iter 12400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 12400, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 12:23:39]:
-Iter 12450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 12450, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:26:11]:
-Iter 12500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 12500, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 12:28:43]:
-Iter 12550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12550, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:31:15]:
-Iter 12600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12600, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 12:33:47]:
-Iter 12650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 12650, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:36:19]:
-Iter 12700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12700, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 12:38:51]:
-Iter 12750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.05
-Iter 12750, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:41:23]:
-Iter 12800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 12800, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:43:55]:
-Iter 12850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 12850, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 12:46:27]:
-Iter 12900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 12900, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:48:59]:
-Iter 12950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 12950, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 12:51:30]:
-Iter 13000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 13000, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 12:54:02]:
-Iter 13050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 13050, Validation Loss= 4.6049, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 12:56:34]:
-Iter 13100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13100, Validation Loss= 4.6055, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 12:59:06]:
-Iter 13150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13150, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 13:01:38]:
-Iter 13200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 13200, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 13:04:10]:
-Iter 13250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 13250, Validation Loss= 4.6044, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 13:06:42]:
-Iter 13300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13300, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 13:09:14]:
-Iter 13350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 13350, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 13:11:46]:
-Iter 13400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 13400, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.02
[2017-11-05 13:14:18]:
-Iter 13450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 13450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 13:16:50]:
-Iter 13500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 13500, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 13:19:22]:
-Iter 13550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13550, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 13:21:54]:
-Iter 13600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13600, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 13:24:26]:
-Iter 13650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 13650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 13:26:58]:
-Iter 13700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13700, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 13:29:30]:
-Iter 13750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 13750, Validation Loss= 4.6047, Accuracy Top1 = 0.01, Top5 = 0.09
[2017-11-05 13:32:02]:
-Iter 13800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 13800, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 13:34:34]:
-Iter 13850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 13850, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 13:37:06]:
-Iter 13900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 13900, Validation Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.06
[2017-11-05 13:39:38]:
-Iter 13950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 13950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 13:42:10]:
-Iter 14000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 14000, Validation Loss= 4.6050, Accuracy Top1 = 0.02, Top5 = 0.04
[2017-11-05 13:44:42]:
-Iter 14050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 14050, Validation Loss= 4.6051, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 13:47:14]:
-Iter 14100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14100, Validation Loss= 4.6054, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 13:49:46]:
-Iter 14150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14150, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.03
[2017-11-05 13:52:18]:
-Iter 14200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14200, Validation Loss= 4.6060, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 13:54:50]:
-Iter 14250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 14250, Validation Loss= 4.6046, Accuracy Top1 = 0.01, Top5 = 0.08
[2017-11-05 13:57:22]:
-Iter 14300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14300, Validation Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.07
[2017-11-05 13:59:54]:
-Iter 14350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 14350, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 14:02:26]:
-Iter 14400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 14400, Validation Loss= 4.6041, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:04:58]:
-Iter 14450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 14450, Validation Loss= 4.6045, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 14:07:30]:
-Iter 14500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 14500, Validation Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 14:10:02]:
-Iter 14550, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14550, Validation Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.05
[2017-11-05 14:12:34]:
-Iter 14600, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14600, Validation Loss= 4.6056, Accuracy Top1 = 0.00, Top5 = 0.04
[2017-11-05 14:15:06]:
-Iter 14650, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.05
-Iter 14650, Validation Loss= 4.6052, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:17:37]:
-Iter 14700, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 14700, Validation Loss= 4.6053, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 14:20:09]:
-Iter 14750, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 14750, Validation Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:22:41]:
-Iter 14800, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 14800, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 14:25:13]:
-Iter 14850, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 14850, Validation Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:27:45]:
-Iter 14900, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 14900, Validation Loss= 4.6057, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:30:17]:
-Iter 14950, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 14950, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:32:49]:
-Iter 15000, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 15000, Validation Loss= 4.6055, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:35:21]:
-Iter 15050, Training Loss= 4.6058, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 15050, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:37:53]:
-Iter 15100, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 15100, Validation Loss= 4.6059, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:40:25]:
-Iter 15150, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 15150, Validation Loss= 4.6051, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:42:57]:
-Iter 15200, Training Loss= 4.6062, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 15200, Validation Loss= 4.6050, Accuracy Top1 = 0.00, Top5 = 0.03
[2017-11-05 14:45:29]:
-Iter 15250, Training Loss= 4.6054, Accuracy Top1 = 0.02, Top5 = 0.04
-Iter 15250, Validation Loss= 4.6050, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:48:01]:
-Iter 15300, Training Loss= 4.6053, Accuracy Top1 = 0.00, Top5 = 0.04
-Iter 15300, Validation Loss= 4.6048, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:50:33]:
-Iter 15350, Training Loss= 4.6058, Accuracy Top1 = 0.01, Top5 = 0.03
-Iter 15350, Validation Loss= 4.6064, Accuracy Top1 = 0.01, Top5 = 0.04
[2017-11-05 14:53:05]:
-Iter 15400, Training Loss= 4.6052, Accuracy Top1 = 0.00, Top5 = 0.03
-Iter 15400, Validation Loss= 4.6054, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:55:37]:
-Iter 15450, Training Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.05
-Iter 15450, Validation Loss= 4.6057, Accuracy Top1 = 0.01, Top5 = 0.06
[2017-11-05 14:58:09]:
-Iter 15500, Training Loss= 4.6056, Accuracy Top1 = 0.01, Top5 = 0.04
-Iter 15500, Validation Loss= 4.6049, Accuracy Top1 = 0.01, Top5 = 0.07
[w