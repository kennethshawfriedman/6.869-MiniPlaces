Last login: Sun Nov  5 11:09:15 on ttys000
Kennys-MacBook-Pro:~ Kenny$ ssh -i "team2.pem" ubuntu@ec2-54-174-118-82.compute-1.amazonaws.com
Warning: Identity file team2.pem not accessible: No such file or directory.
ssh: connect to host ec2-54-174-118-82.compute-1.amazonaws.com port 22: Connection refused
Kennys-MacBook-Pro:~ Kenny$ ssh -i "team2.pem" ubuntu@ec2-54-174-118-82.compute-1.amazonaws.com
Warning: Identity file team2.pem not accessible: No such file or directory.
The authenticity of host 'ec2-54-174-118-82.compute-1.amazonaws.com (54.174.118.82)' can't be established.
ECDSA key fingerprint is SHA256:o1bBZOYGLM+tZYkvl/s2isrhSB8gjvHNDnrD+fkwt9k.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'ec2-54-174-118-82.compute-1.amazonaws.com,54.174.118.82' (ECDSA) to the list of known hosts.
===================================
Deep Learning AMI for Ubuntu
===================================
The README file for the AMI : /home/ubuntu/src/AMI.README.md

Tests for deep learning frameworks ➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜➜ /home/ubuntu/src/bin

Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-1022-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  Get cloud support with Ubuntu Advantage Cloud Guest:
    http://www.ubuntu.com/business/services/cloud

6 packages can be updated.
6 updates are security updates.



The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

ubuntu@ip-172-31-5-64:~$ ls
src
ubuntu@ip-172-31-5-64:~$ git clone https://github.com/kennethshawfriedman/6.869-MiniPlaces.git
Cloning into '6.869-MiniPlaces'...
remote: Counting objects: 124134, done.
remote: Compressing objects: 100% (120237/120237), done.
remote: Total 124134 (delta 3865), reused 124134 (delta 3865), pack-reused 0
Receiving objects: 100% (124134/124134), 495.25 MiB | 52.17 MiB/s, done.
Resolving deltas: 100% (3865/3865), done.
Checking connectivity... done.
Checking out files: 100% (123895/123895), done.
ubuntu@ip-172-31-5-64:~$ ls
6.869-MiniPlaces  src
ubuntu@ip-172-31-5-64:~$ cd 6.869-MiniPlaces/
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces$ ls
data  evaluation  model  README.md  teaser.jpg  util
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces$ cd model
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model$ ls
matconvnet  tensorflow
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model$ cd tensorflow/
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ ls
alexnet_bn_train.py  alexnet_train.py  DataLoader.py  prepro_data.py  README.md
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ python alexnet_bn_train.py 
('# Images found:', 100000)
('# Images found:', 10000)
2017-11-05 16:51:29.145334: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 16:51:29.145387: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 16:51:29.145403: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 16:51:30.490291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 16:51:30.490764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 16:51:30.526768: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47ecce0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 16:51:30.527086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 16:51:30.527517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:04.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 16:51:30.564266: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47f0ad0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 16:51:30.564592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 16:51:30.565002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:05.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 16:51:30.604004: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4814940 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 16:51:30.604312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 16:51:30.604712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:06.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 16:51:30.605630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1
2017-11-05 16:51:30.605671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-11-05 16:51:30.605700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-11-05 16:51:30.605726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0
2017-11-05 16:51:30.605752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-11-05 16:51:30.605778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-11-05 16:51:30.605803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-11-05 16:51:30.605831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-11-05 16:51:30.605856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 3
2017-11-05 16:51:30.605881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-11-05 16:51:30.605906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-11-05 16:51:30.605931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 2
2017-11-05 16:51:30.606009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-11-05 16:51:30.606028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y N N N 
2017-11-05 16:51:30.606043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   N Y N N 
2017-11-05 16:51:30.606057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y N 
2017-11-05 16:51:30.606070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N N Y 
2017-11-05 16:51:30.606084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
2017-11-05 16:51:30.606122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K520, pci bus id: 0000:00:04.0)
2017-11-05 16:51:30.606139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GRID K520, pci bus id: 0000:00:05.0)
2017-11-05 16:51:30.606151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GRID K520, pci bus id: 0000:00:06.0)
[2017-11-05 16:51:56]:
-Iter 0, Training Loss= 4.929808, Accuracy Top1 = 0.0156, Top5 = 0.0547
-Iter 0, Validation Loss= 4.939791, Accuracy Top1 = 0.0078, Top5 = 0.0312
2017-11-05 16:52:33.190480: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 818.27MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:52:34.467501: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:52:36.239845: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.07GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:07.897757: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:15.936427: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:18.783001: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:26.848598: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:42.685676: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:53.390787: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-11-05 16:53:56.243942: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 944.00MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
[2017-11-05 16:55:16]:
-Iter 50, Training Loss= 4.474094, Accuracy Top1 = 0.0586, Top5 = 0.2109
-Iter 50, Validation Loss= 4.443215, Accuracy Top1 = 0.0664, Top5 = 0.2188
[2017-11-05 16:57:30]:
-Iter 100, Training Loss= 4.627251, Accuracy Top1 = 0.0938, Top5 = 0.2812
-Iter 100, Validation Loss= 5.046168, Accuracy Top1 = 0.0547, Top5 = 0.2773
[2017-11-05 16:59:43]:
-Iter 150, Training Loss= 4.044641, Accuracy Top1 = 0.0938, Top5 = 0.3008
-Iter 150, Validation Loss= 3.947219, Accuracy Top1 = 0.0977, Top5 = 0.3438
[2017-11-05 17:01:58]:
-Iter 200, Training Loss= 4.854140, Accuracy Top1 = 0.0977, Top5 = 0.2656
-Iter 200, Validation Loss= 4.854821, Accuracy Top1 = 0.0898, Top5 = 0.2695
[2017-11-05 17:04:12]:
-Iter 250, Training Loss= 3.551018, Accuracy Top1 = 0.1211, Top5 = 0.3867
-Iter 250, Validation Loss= 3.846774, Accuracy Top1 = 0.1250, Top5 = 0.3086
[2017-11-05 17:06:27]:
-Iter 300, Training Loss= 3.433747, Accuracy Top1 = 0.1719, Top5 = 0.4492
-Iter 300, Validation Loss= 3.553462, Accuracy Top1 = 0.1758, Top5 = 0.4102
[2017-11-05 17:08:41]:
-Iter 350, Training Loss= 3.379504, Accuracy Top1 = 0.1914, Top5 = 0.4258
-Iter 350, Validation Loss= 3.664666, Accuracy Top1 = 0.1797, Top5 = 0.4414
[2017-11-05 17:10:56]:
-Iter 400, Training Loss= 3.305830, Accuracy Top1 = 0.1953, Top5 = 0.4414
-Iter 400, Validation Loss= 3.426677, Accuracy Top1 = 0.1523, Top5 = 0.4688
[2017-11-05 17:13:10]:
-Iter 450, Training Loss= 3.766187, Accuracy Top1 = 0.1172, Top5 = 0.3867
-Iter 450, Validation Loss= 3.748237, Accuracy Top1 = 0.1562, Top5 = 0.3633
[2017-11-05 17:15:24]:
-Iter 500, Training Loss= 3.161721, Accuracy Top1 = 0.2383, Top5 = 0.4805
-Iter 500, Validation Loss= 3.764337, Accuracy Top1 = 0.2109, Top5 = 0.5000
[2017-11-05 17:17:37]:
-Iter 550, Training Loss= 3.378748, Accuracy Top1 = 0.1680, Top5 = 0.4531
-Iter 550, Validation Loss= 3.455837, Accuracy Top1 = 0.2266, Top5 = 0.5234
[2017-11-05 17:19:50]:
-Iter 600, Training Loss= 3.486884, Accuracy Top1 = 0.1797, Top5 = 0.4492
-Iter 600, Validation Loss= 4.730505, Accuracy Top1 = 0.1797, Top5 = 0.4492
[2017-11-05 17:22:04]:
-Iter 650, Training Loss= 3.121127, Accuracy Top1 = 0.2344, Top5 = 0.5195
-Iter 650, Validation Loss= 3.532705, Accuracy Top1 = 0.1836, Top5 = 0.4766
[2017-11-05 17:24:17]:
-Iter 700, Training Loss= 3.158067, Accuracy Top1 = 0.2266, Top5 = 0.4844
-Iter 700, Validation Loss= 3.209998, Accuracy Top1 = 0.2344, Top5 = 0.4805
[2017-11-05 17:26:32]:
-Iter 750, Training Loss= 2.957570, Accuracy Top1 = 0.2773, Top5 = 0.5586
-Iter 750, Validation Loss= 3.102776, Accuracy Top1 = 0.2109, Top5 = 0.5000
2017-11-05 17:28:25.863567: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 73.50MiB.  Current allocation summary follows.
2017-11-05 17:28:25.863658: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863682: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863701: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863720: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 2, Chunks in use: 0 5.8KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863738: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863753: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863767: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863784: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863799: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863820: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863837: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863854: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863871: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863885: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863900: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863915: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863939: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863956: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863976: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.863996: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.864017: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-05 17:28:25.864035: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 73.50MiB was 64.00MiB, Chunk State: 
2017-11-05 17:28:25.864065: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00000 of size 1280
2017-11-05 17:28:25.864079: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00500 of size 256
2017-11-05 17:28:25.864092: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00600 of size 256
2017-11-05 17:28:25.864104: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00700 of size 256
2017-11-05 17:28:25.864116: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00800 of size 256
2017-11-05 17:28:25.864128: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00900 of size 256
2017-11-05 17:28:25.864141: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00a00 of size 256
2017-11-05 17:28:25.864149: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00b00 of size 256
2017-11-05 17:28:25.864162: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00c00 of size 512
2017-11-05 17:28:25.864174: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e00e00 of size 512
2017-11-05 17:28:25.864187: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01000 of size 512
2017-11-05 17:28:25.864200: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01200 of size 512
2017-11-05 17:28:25.864212: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01400 of size 512
2017-11-05 17:28:25.864224: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01600 of size 1024
2017-11-05 17:28:25.864237: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01a00 of size 1024
2017-11-05 17:28:25.864249: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e01e00 of size 1024
2017-11-05 17:28:25.864261: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e02200 of size 1024
2017-11-05 17:28:25.864273: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e02600 of size 1536
2017-11-05 17:28:25.864286: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e02c00 of size 1536
2017-11-05 17:28:25.864294: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e03200 of size 1536
2017-11-05 17:28:25.864302: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e03800 of size 1536
2017-11-05 17:28:25.864314: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e03e00 of size 1024
2017-11-05 17:28:25.864326: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e04200 of size 1024
2017-11-05 17:28:25.864339: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e04600 of size 1024
2017-11-05 17:28:25.864351: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e04a00 of size 1024
2017-11-05 17:28:25.864362: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e04e00 of size 1024
2017-11-05 17:28:25.864374: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e05200 of size 1024
2017-11-05 17:28:25.864387: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e05600 of size 1024
2017-11-05 17:28:25.864399: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e05a00 of size 1024
2017-11-05 17:28:25.864411: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e05e00 of size 16384
2017-11-05 17:28:25.864423: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e09e00 of size 16384
2017-11-05 17:28:25.864435: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e0de00 of size 16384
2017-11-05 17:28:25.864447: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e11e00 of size 16384
2017-11-05 17:28:25.864460: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e15e00 of size 16384
2017-11-05 17:28:25.864472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e19e00 of size 16384
2017-11-05 17:28:25.864481: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e1de00 of size 16384
2017-11-05 17:28:25.864493: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e21e00 of size 16384
2017-11-05 17:28:25.864501: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e25e00 of size 256
2017-11-05 17:28:25.864512: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e25f00 of size 256
2017-11-05 17:28:25.864521: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e26000 of size 139520
2017-11-05 17:28:25.864533: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1208e48100 of size 2457600
2017-11-05 17:28:25.864545: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12090a0100 of size 3538944
2017-11-05 17:28:25.864553: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1209400100 of size 3538944
2017-11-05 17:28:25.864565: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1209760100 of size 2359296
2017-11-05 17:28:25.864577: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12099a0100 of size 205520896
2017-11-05 17:28:25.864586: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1215da0100 of size 67108864
2017-11-05 17:28:25.864598: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219da0100 of size 1638400
2017-11-05 17:28:25.864607: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f30100 of size 512
2017-11-05 17:28:25.864619: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f30300 of size 512
2017-11-05 17:28:25.864630: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f30500 of size 1024
2017-11-05 17:28:25.864639: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f30900 of size 1536
2017-11-05 17:28:25.864651: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f30f00 of size 1024
2017-11-05 17:28:25.864666: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f31300 of size 1024
2017-11-05 17:28:25.864675: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f31700 of size 16384
2017-11-05 17:28:25.864696: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f35700 of size 16384
2017-11-05 17:28:25.864709: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1219f39700 of size 6136064
2017-11-05 17:28:25.864716: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121a513800 of size 3538944
2017-11-05 17:28:25.864723: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121a873800 of size 67108864
2017-11-05 17:28:25.864735: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121e873800 of size 1638400
2017-11-05 17:28:25.864747: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03800 of size 256
2017-11-05 17:28:25.864768: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03900 of size 256
2017-11-05 17:28:25.864780: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03a00 of size 256
2017-11-05 17:28:25.864789: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03b00 of size 256
2017-11-05 17:28:25.864800: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03c00 of size 256
2017-11-05 17:28:25.864812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03d00 of size 256
2017-11-05 17:28:25.864821: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03e00 of size 256
2017-11-05 17:28:25.864832: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea03f00 of size 256
2017-11-05 17:28:25.864844: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04000 of size 256
2017-11-05 17:28:25.864852: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04100 of size 256
2017-11-05 17:28:25.864864: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04200 of size 256
2017-11-05 17:28:25.864875: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04300 of size 256
2017-11-05 17:28:25.864883: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04400 of size 256
2017-11-05 17:28:25.864895: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04500 of size 256
2017-11-05 17:28:25.864906: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04600 of size 256
2017-11-05 17:28:25.864915: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04700 of size 256
2017-11-05 17:28:25.864927: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04800 of size 256
2017-11-05 17:28:25.864938: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04900 of size 256
2017-11-05 17:28:25.864947: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04a00 of size 256
2017-11-05 17:28:25.864958: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04b00 of size 256
2017-11-05 17:28:25.864971: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04c00 of size 256
2017-11-05 17:28:25.864979: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04d00 of size 256
2017-11-05 17:28:25.864991: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04e00 of size 256
2017-11-05 17:28:25.865002: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea04f00 of size 256
2017-11-05 17:28:25.865011: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05000 of size 256
2017-11-05 17:28:25.865022: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05100 of size 256
2017-11-05 17:28:25.865034: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05200 of size 256
2017-11-05 17:28:25.865043: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05300 of size 256
2017-11-05 17:28:25.865055: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05400 of size 256
2017-11-05 17:28:25.865067: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05500 of size 256
2017-11-05 17:28:25.865075: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05600 of size 256
2017-11-05 17:28:25.865086: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05700 of size 256
2017-11-05 17:28:25.865099: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05800 of size 256
2017-11-05 17:28:25.865107: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05900 of size 256
2017-11-05 17:28:25.865118: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05a00 of size 256
2017-11-05 17:28:25.865130: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05b00 of size 256
2017-11-05 17:28:25.865138: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05c00 of size 256
2017-11-05 17:28:25.865150: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05d00 of size 256
2017-11-05 17:28:25.865163: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05e00 of size 256
2017-11-05 17:28:25.865171: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea05f00 of size 256
2017-11-05 17:28:25.865182: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06000 of size 256
2017-11-05 17:28:25.865194: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06100 of size 256
2017-11-05 17:28:25.865202: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06200 of size 256
2017-11-05 17:28:25.865216: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06300 of size 256
2017-11-05 17:28:25.865228: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06400 of size 256
2017-11-05 17:28:25.865237: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x121ea06d00 of size 207866624
2017-11-05 17:28:25.865248: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b043800 of size 512
2017-11-05 17:28:25.865260: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b043a00 of size 512
2017-11-05 17:28:25.865268: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b043c00 of size 512
2017-11-05 17:28:25.865280: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b043e00 of size 512
2017-11-05 17:28:25.865292: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b044000 of size 512
2017-11-05 17:28:25.865301: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b044200 of size 1024
2017-11-05 17:28:25.865312: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b044600 of size 1024
2017-11-05 17:28:25.865324: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b044a00 of size 1024
2017-11-05 17:28:25.865333: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b044e00 of size 1024
2017-11-05 17:28:25.865344: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b045200 of size 1536
2017-11-05 17:28:25.865356: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b045800 of size 1536
2017-11-05 17:28:25.865364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b045e00 of size 1536
2017-11-05 17:28:25.865375: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b046400 of size 1536
2017-11-05 17:28:25.865387: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b046a00 of size 1024
2017-11-05 17:28:25.865396: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b046e00 of size 1024
2017-11-05 17:28:25.865407: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b047200 of size 1024
2017-11-05 17:28:25.865419: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b047600 of size 1024
2017-11-05 17:28:25.865428: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b047a00 of size 1024
2017-11-05 17:28:25.865439: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b047e00 of size 1024
2017-11-05 17:28:25.865451: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b048200 of size 1024
2017-11-05 17:28:25.865459: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b048600 of size 1024
2017-11-05 17:28:25.865470: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b048a00 of size 16384
2017-11-05 17:28:25.865483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b04ca00 of size 16384
2017-11-05 17:28:25.865491: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b050a00 of size 16384
2017-11-05 17:28:25.865503: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b054a00 of size 16384
2017-11-05 17:28:25.865514: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b058a00 of size 16384
2017-11-05 17:28:25.865523: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b05ca00 of size 16384
2017-11-05 17:28:25.865534: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b060a00 of size 16384
2017-11-05 17:28:25.865546: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b064a00 of size 16384
2017-11-05 17:28:25.865555: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b068a00 of size 256
2017-11-05 17:28:25.865566: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b068b00 of size 256
2017-11-05 17:28:25.865578: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b068c00 of size 139520
2017-11-05 17:28:25.865590: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b08ad00 of size 139520
2017-11-05 17:28:25.865603: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b0ace00 of size 2457600
2017-11-05 17:28:25.865616: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b304e00 of size 2457600
2017-11-05 17:28:25.865624: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b55ce00 of size 3538944
2017-11-05 17:28:25.865635: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122b8bce00 of size 3538944
2017-11-05 17:28:25.865644: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122bc1ce00 of size 3538944
2017-11-05 17:28:25.865655: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122bf7ce00 of size 3538944
2017-11-05 17:28:25.865667: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122c2dce00 of size 2359296
2017-11-05 17:28:25.865676: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122c51ce00 of size 2359296
2017-11-05 17:28:25.865687: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x122c75ce00 of size 205520896
2017-11-05 17:28:25.865699: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1238b5ce00 of size 205520896
2017-11-05 17:28:25.865707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1244f5ce00 of size 67108864
2017-11-05 17:28:25.865719: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1248f5ce00 of size 67108864
2017-11-05 17:28:25.865731: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124cf5ce00 of size 1638400
2017-11-05 17:28:25.865740: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d0ece00 of size 1638400
2017-11-05 17:28:25.865756: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27ce00 of size 512
2017-11-05 17:28:25.865768: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27d000 of size 512
2017-11-05 17:28:25.865780: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27d200 of size 512
2017-11-05 17:28:25.865788: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27d400 of size 512
2017-11-05 17:28:25.865800: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27d600 of size 512
2017-11-05 17:28:25.865823: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27d800 of size 512
2017-11-05 17:28:25.865832: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27da00 of size 1024
2017-11-05 17:28:25.865840: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27de00 of size 1024
2017-11-05 17:28:25.865851: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27e200 of size 1024
2017-11-05 17:28:25.865863: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27e600 of size 1024
2017-11-05 17:28:25.865884: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27ea00 of size 1536
2017-11-05 17:28:25.865896: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27f000 of size 1536
2017-11-05 17:28:25.865904: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27f600 of size 1536
2017-11-05 17:28:25.865916: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d27fc00 of size 1536
2017-11-05 17:28:25.865924: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d280200 of size 1024
2017-11-05 17:28:25.865932: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d280600 of size 1024
2017-11-05 17:28:25.865951: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d280a00 of size 1024
2017-11-05 17:28:25.865963: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d280e00 of size 1024
2017-11-05 17:28:25.865974: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d281200 of size 1024
2017-11-05 17:28:25.865984: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d281600 of size 1024
2017-11-05 17:28:25.865995: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d281a00 of size 1024
2017-11-05 17:28:25.866008: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d281e00 of size 1024
2017-11-05 17:28:25.866017: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d282200 of size 16384
2017-11-05 17:28:25.866029: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d286200 of size 16384
2017-11-05 17:28:25.866041: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d28a200 of size 16384
2017-11-05 17:28:25.866049: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d28e200 of size 16384
2017-11-05 17:28:25.866057: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d292200 of size 16384
2017-11-05 17:28:25.866068: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d296200 of size 16384
2017-11-05 17:28:25.866080: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d29a200 of size 16384
2017-11-05 17:28:25.866089: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d29e200 of size 16384
2017-11-05 17:28:25.866129: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d2a2200 of size 139520
2017-11-05 17:28:25.866141: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d2c4300 of size 2457600
2017-11-05 17:28:25.866152: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d51c300 of size 3538944
2017-11-05 17:28:25.866164: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x124d87c300 of size 205520896
2017-11-05 17:28:25.866173: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1259c7d200 of size 308281344
2017-11-05 17:28:25.866185: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x126c27d200 of size 512
2017-11-05 17:28:25.866197: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x126c27d400 of size 512
2017-11-05 17:28:25.866205: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x126c27d600 of size 512
2017-11-05 17:28:25.866217: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x126c27d800 of size 77070336
2017-11-05 17:28:25.866229: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1270bfd800 of size 78448896
2017-11-05 17:28:25.866242: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12756ce100 of size 308281344
2017-11-05 17:28:25.866254: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x1287cce100 of size 565184000
2017-11-05 17:28:25.866268: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12a97ce700 of size 256
2017-11-05 17:28:25.866280: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12a97ce800 of size 77070336
2017-11-05 17:28:25.866289: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12ae14e800 of size 588586240
2017-11-05 17:28:25.866300: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12d12a0500 of size 256
2017-11-05 17:28:25.866312: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12d12a0600 of size 2457600
2017-11-05 17:28:25.866321: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x12d14f8600 of size 516717056
2017-11-05 17:28:25.866333: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x121ea06500 of size 2048
2017-11-05 17:28:25.866346: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1259c7c300 of size 3840
2017-11-05 17:28:25.866359: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-05 17:28:25.866375: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 58 Chunks of size 256 totalling 14.5KiB
2017-11-05 17:28:25.866392: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 21 Chunks of size 512 totalling 10.5KiB
2017-11-05 17:28:25.866407: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 1024 totalling 39.0KiB
2017-11-05 17:28:25.866421: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-05 17:28:25.866435: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 1536 totalling 19.5KiB
2017-11-05 17:28:25.866448: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 26 Chunks of size 16384 totalling 416.0KiB
2017-11-05 17:28:25.866462: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 139520 totalling 545.0KiB
2017-11-05 17:28:25.866475: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 1638400 totalling 6.25MiB
2017-11-05 17:28:25.866488: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 3 Chunks of size 2359296 totalling 6.75MiB
2017-11-05 17:28:25.866502: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 2457600 totalling 11.72MiB
2017-11-05 17:28:25.866515: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 3538944 totalling 27.00MiB
2017-11-05 17:28:25.866528: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6136064 totalling 5.85MiB
2017-11-05 17:28:25.866542: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 67108864 totalling 256.00MiB
2017-11-05 17:28:25.866555: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 77070336 totalling 147.00MiB
2017-11-05 17:28:25.866569: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 78448896 totalling 74.81MiB
2017-11-05 17:28:25.866584: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 4 Chunks of size 205520896 totalling 784.00MiB
2017-11-05 17:28:25.866594: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 207866624 totalling 198.24MiB
2017-11-05 17:28:25.866609: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 308281344 totalling 588.00MiB
2017-11-05 17:28:25.866619: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 516717056 totalling 492.78MiB
2017-11-05 17:28:25.866632: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 565184000 totalling 539.00MiB
2017-11-05 17:28:25.866646: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 588586240 totalling 561.32MiB
2017-11-05 17:28:25.866659: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 3.61GiB
2017-11-05 17:28:25.866676: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                  3879469056
InUse:                  3879463168
MaxInUse:               3879469056
NumAllocs:                  263778
MaxAllocSize:           2058225920

2017-11-05 17:28:25.866704: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ***************************************************************xxxxxx***********xxxxxx*********xxxxx
2017-11-05 17:28:25.866732: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[256,96,28,28]
Traceback (most recent call last):
  File "alexnet_bn_train.py", line 178, in <module>
    sess.run(train_optimizer, feed_dict={x: images_batch, y: labels_batch, keep_dropout: dropout, train_phase: True})
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[256,96,28,28]
	 [[Node: gradients/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format="NHWC", ksize=[1, 3, 3, 1], padding="SAME", strides=[1, 2, 2, 1], _device="/job:localhost/replica:0/task:0/gpu:0"](Relu, MaxPool, gradients/Conv2D_1_grad/tuple/control_dependency)]]

Caused by op u'gradients/MaxPool_grad/MaxPoolGrad', defined at:
  File "alexnet_bn_train.py", line 130, in <module>
    train_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 315, in minimize
    grad_loss=grad_loss)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 542, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 348, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 542, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_grad.py", line 526, in _MaxPoolGrad
    data_format=op.get_attr("data_format"))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 1752, in _max_pool_grad
    data_format=data_format, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

...which was originally created as op u'MaxPool', defined at:
  File "alexnet_bn_train.py", line 126, in <module>
    logits = alexnet(x, keep_dropout, train_phase)
  File "alexnet_bn_train.py", line 52, in alexnet
    pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py", line 1772, in max_pool
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 1605, in _max_pool
    data_format=data_format, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,96,28,28]
	 [[Node: gradients/MaxPool_grad/MaxPoolGrad = MaxPoolGrad[T=DT_FLOAT, data_format="NHWC", ksize=[1, 3, 3, 1], padding="SAME", strides=[1, 2, 2, 1], _device="/job:localhost/replica:0/task:0/gpu:0"](Relu, MaxPool, gradients/Conv2D_1_grad/tuple/control_dependency)]]

ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ ls
alexnet_bn_train.py  alexnet_train.py  DataLoader.py  DataLoader.pyc  prepro_data.py  README.md
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ vi alexnet_bn_train.py 
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ python alexnet_bn_train.py 
('# Images found:', 100000)
('# Images found:', 10000)
2017-11-05 17:39:18.824161: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 17:39:18.824218: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 17:39:18.824236: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-11-05 17:39:18.972948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 17:39:18.973415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 17:39:19.009827: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4996e10 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 17:39:19.010170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 17:39:19.010598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:04.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 17:39:19.048800: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x499ac00 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 17:39:19.049126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 17:39:19.049562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:05.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 17:39:19.086661: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x49bea70 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-05 17:39:19.086983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-05 17:39:19.087400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:06.0
Total memory: 3.94GiB
Free memory: 3.91GiB
2017-11-05 17:39:19.087548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 1
2017-11-05 17:39:19.087580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-11-05 17:39:19.087607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-11-05 17:39:19.087633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 0
2017-11-05 17:39:19.087660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-11-05 17:39:19.087694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-11-05 17:39:19.087721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-11-05 17:39:19.087747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-11-05 17:39:19.087774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 3
2017-11-05 17:39:19.087800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-11-05 17:39:19.087825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-11-05 17:39:19.087851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 2
2017-11-05 17:39:19.087933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-11-05 17:39:19.087952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y N N N 
2017-11-05 17:39:19.087962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   N Y N N 
2017-11-05 17:39:19.087974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y N 
2017-11-05 17:39:19.087988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N N Y 
2017-11-05 17:39:19.088006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
2017-11-05 17:39:19.088022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GRID K520, pci bus id: 0000:00:04.0)
2017-11-05 17:39:19.088034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GRID K520, pci bus id: 0000:00:05.0)
2017-11-05 17:39:19.088047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GRID K520, pci bus id: 0000:00:06.0)
[2017-11-05 17:39:20]:
-Iter 0, Training Loss= 4.842912, Accuracy Top1 = 0.0000, Top5 = 0.0312
-Iter 0, Validation Loss= 5.019762, Accuracy Top1 = 0.0078, Top5 = 0.0391
[2017-11-05 17:40:50]:
-Iter 50, Training Loss= 4.595072, Accuracy Top1 = 0.0703, Top5 = 0.1953
-Iter 50, Validation Loss= 4.510961, Accuracy Top1 = 0.0703, Top5 = 0.1797
[2017-11-05 17:42:00]:
-Iter 100, Training Loss= 4.292855, Accuracy Top1 = 0.0547, Top5 = 0.2188
-Iter 100, Validation Loss= 4.187445, Accuracy Top1 = 0.1094, Top5 = 0.2578
[2017-11-05 17:43:10]:
-Iter 150, Training Loss= 6.236748, Accuracy Top1 = 0.0703, Top5 = 0.1875
-Iter 150, Validation Loss= 4.244177, Accuracy Top1 = 0.0859, Top5 = 0.2969
[2017-11-05 17:44:20]:
-Iter 200, Training Loss= 3.894045, Accuracy Top1 = 0.1172, Top5 = 0.3203
-Iter 200, Validation Loss= 4.291419, Accuracy Top1 = 0.0859, Top5 = 0.2656
[2017-11-05 17:45:30]:
-Iter 250, Training Loss= 3.839490, Accuracy Top1 = 0.1172, Top5 = 0.4062
-Iter 250, Validation Loss= 3.835467, Accuracy Top1 = 0.1172, Top5 = 0.3203
[2017-11-05 17:46:40]:
-Iter 300, Training Loss= 4.015907, Accuracy Top1 = 0.1250, Top5 = 0.3203
-Iter 300, Validation Loss= 4.458046, Accuracy Top1 = 0.1484, Top5 = 0.3750
[2017-11-05 17:47:50]:
-Iter 350, Training Loss= 4.327947, Accuracy Top1 = 0.0781, Top5 = 0.2969
-Iter 350, Validation Loss= 3.629469, Accuracy Top1 = 0.1250, Top5 = 0.3984
[2017-11-05 17:49:00]:
-Iter 400, Training Loss= 5.032119, Accuracy Top1 = 0.1328, Top5 = 0.3594
-Iter 400, Validation Loss= 3.973801, Accuracy Top1 = 0.1484, Top5 = 0.3906
[2017-11-05 17:50:10]:
-Iter 450, Training Loss= 3.519045, Accuracy Top1 = 0.1562, Top5 = 0.3906
-Iter 450, Validation Loss= 3.594006, Accuracy Top1 = 0.1875, Top5 = 0.4766
[2017-11-05 17:51:20]:
-Iter 500, Training Loss= 3.548788, Accuracy Top1 = 0.1562, Top5 = 0.4141
-Iter 500, Validation Loss= 3.659978, Accuracy Top1 = 0.1641, Top5 = 0.3750
[2017-11-05 17:52:30]:
-Iter 550, Training Loss= 3.585109, Accuracy Top1 = 0.2109, Top5 = 0.5000
-Iter 550, Validation Loss= 3.756540, Accuracy Top1 = 0.1328, Top5 = 0.3516
[2017-11-05 17:53:40]:
-Iter 600, Training Loss= 3.454535, Accuracy Top1 = 0.1641, Top5 = 0.4062
-Iter 600, Validation Loss= 3.603021, Accuracy Top1 = 0.1797, Top5 = 0.4219
[2017-11-05 17:54:50]:
-Iter 650, Training Loss= 3.504570, Accuracy Top1 = 0.1719, Top5 = 0.4297
-Iter 650, Validation Loss= 3.262565, Accuracy Top1 = 0.2109, Top5 = 0.4609
[2017-11-05 17:56:00]:
-Iter 700, Training Loss= 3.381002, Accuracy Top1 = 0.2422, Top5 = 0.5000
-Iter 700, Validation Loss= 3.732833, Accuracy Top1 = 0.1719, Top5 = 0.4141
[2017-11-05 17:57:10]:
-Iter 750, Training Loss= 3.572969, Accuracy Top1 = 0.1406, Top5 = 0.3672
-Iter 750, Validation Loss= 4.308612, Accuracy Top1 = 0.1953, Top5 = 0.3906
[2017-11-05 17:58:20]:
-Iter 800, Training Loss= 3.266067, Accuracy Top1 = 0.2031, Top5 = 0.4375
-Iter 800, Validation Loss= 4.591184, Accuracy Top1 = 0.1406, Top5 = 0.3906
[2017-11-05 17:59:30]:
-Iter 850, Training Loss= 2.980308, Accuracy Top1 = 0.2578, Top5 = 0.5781
-Iter 850, Validation Loss= 3.035819, Accuracy Top1 = 0.2344, Top5 = 0.5547
[2017-11-05 18:00:40]:
-Iter 900, Training Loss= 3.641037, Accuracy Top1 = 0.1328, Top5 = 0.3750
-Iter 900, Validation Loss= 3.633377, Accuracy Top1 = 0.1172, Top5 = 0.4219
[2017-11-05 18:01:50]:
-Iter 950, Training Loss= 3.366266, Accuracy Top1 = 0.1953, Top5 = 0.4609
-Iter 950, Validation Loss= 3.526088, Accuracy Top1 = 0.1719, Top5 = 0.4453
[2017-11-05 18:03:01]:
-Iter 1000, Training Loss= 3.025963, Accuracy Top1 = 0.2422, Top5 = 0.5312
-Iter 1000, Validation Loss= 2.938231, Accuracy Top1 = 0.2812, Top5 = 0.6094
[2017-11-05 18:04:11]:
-Iter 1050, Training Loss= 3.408820, Accuracy Top1 = 0.2188, Top5 = 0.4609
-Iter 1050, Validation Loss= 3.534698, Accuracy Top1 = 0.2578, Top5 = 0.4844
[2017-11-05 18:05:21]:
-Iter 1100, Training Loss= 3.440382, Accuracy Top1 = 0.1641, Top5 = 0.4141
-Iter 1100, Validation Loss= 3.854175, Accuracy Top1 = 0.2031, Top5 = 0.4453
[2017-11-05 18:06:31]:
-Iter 1150, Training Loss= 3.087378, Accuracy Top1 = 0.2188, Top5 = 0.4922
-Iter 1150, Validation Loss= 3.258437, Accuracy Top1 = 0.1953, Top5 = 0.5156
[2017-11-05 18:07:41]:
-Iter 1200, Training Loss= 3.293584, Accuracy Top1 = 0.2109, Top5 = 0.4688
-Iter 1200, Validation Loss= 5.198562, Accuracy Top1 = 0.2188, Top5 = 0.5547
[2017-11-05 18:08:51]:
-Iter 1250, Training Loss= 5.574570, Accuracy Top1 = 0.2109, Top5 = 0.4922
-Iter 1250, Validation Loss= 3.752863, Accuracy Top1 = 0.1953, Top5 = 0.4688
[2017-11-05 18:10:01]:
-Iter 1300, Training Loss= 3.275627, Accuracy Top1 = 0.2031, Top5 = 0.4609
-Iter 1300, Validation Loss= 3.320925, Accuracy Top1 = 0.2031, Top5 = 0.5234
[2017-11-05 18:11:11]:
-Iter 1350, Training Loss= 3.163193, Accuracy Top1 = 0.2031, Top5 = 0.4609
-Iter 1350, Validation Loss= 3.221413, Accuracy Top1 = 0.1562, Top5 = 0.4844
[2017-11-05 18:12:21]:
-Iter 1400, Training Loss= 3.120030, Accuracy Top1 = 0.2500, Top5 = 0.5391
-Iter 1400, Validation Loss= 3.338959, Accuracy Top1 = 0.2578, Top5 = 0.4922
[2017-11-05 18:13:31]:
-Iter 1450, Training Loss= 3.034502, Accuracy Top1 = 0.2422, Top5 = 0.5078
-Iter 1450, Validation Loss= 2.932959, Accuracy Top1 = 0.2578, Top5 = 0.5391
[2017-11-05 18:14:41]:
-Iter 1500, Training Loss= 2.968828, Accuracy Top1 = 0.2578, Top5 = 0.5234
-Iter 1500, Validation Loss= 3.187510, Accuracy Top1 = 0.2344, Top5 = 0.5625
[2017-11-05 18:15:51]:
-Iter 1550, Training Loss= 3.196816, Accuracy Top1 = 0.2031, Top5 = 0.4766
-Iter 1550, Validation Loss= 3.278373, Accuracy Top1 = 0.2266, Top5 = 0.5000
[2017-11-05 18:17:01]:
-Iter 1600, Training Loss= 3.207068, Accuracy Top1 = 0.2031, Top5 = 0.5391
-Iter 1600, Validation Loss= 3.193359, Accuracy Top1 = 0.2422, Top5 = 0.5469
[2017-11-05 18:18:11]:
-Iter 1650, Training Loss= 2.927827, Accuracy Top1 = 0.2578, Top5 = 0.5938
-Iter 1650, Validation Loss= 3.177225, Accuracy Top1 = 0.2109, Top5 = 0.5312
[2017-11-05 18:19:21]:
-Iter 1700, Training Loss= 3.027175, Accuracy Top1 = 0.3359, Top5 = 0.5391
-Iter 1700, Validation Loss= 2.748063, Accuracy Top1 = 0.3047, Top5 = 0.6719
[2017-11-05 18:20:31]:
-Iter 1750, Training Loss= 3.408677, Accuracy Top1 = 0.2031, Top5 = 0.4453
-Iter 1750, Validation Loss= 2.883785, Accuracy Top1 = 0.2109, Top5 = 0.5469
[2017-11-05 18:21:41]:
-Iter 1800, Training Loss= 2.997177, Accuracy Top1 = 0.2656, Top5 = 0.5625
-Iter 1800, Validation Loss= 3.685006, Accuracy Top1 = 0.2578, Top5 = 0.4844
[2017-11-05 18:22:51]:
-Iter 1850, Training Loss= 3.119786, Accuracy Top1 = 0.2266, Top5 = 0.5234
-Iter 1850, Validation Loss= 3.062855, Accuracy Top1 = 0.2266, Top5 = 0.5703
[2017-11-05 18:24:01]:
-Iter 1900, Training Loss= 3.189454, Accuracy Top1 = 0.2031, Top5 = 0.5547
-Iter 1900, Validation Loss= 2.976892, Accuracy Top1 = 0.2422, Top5 = 0.6016
[2017-11-05 18:25:11]:
-Iter 1950, Training Loss= 3.023183, Accuracy Top1 = 0.2109, Top5 = 0.5312
-Iter 1950, Validation Loss= 3.334332, Accuracy Top1 = 0.1797, Top5 = 0.4609
[2017-11-05 18:26:21]:
-Iter 2000, Training Loss= 2.979980, Accuracy Top1 = 0.2578, Top5 = 0.6016
-Iter 2000, Validation Loss= 2.684250, Accuracy Top1 = 0.3203, Top5 = 0.6328
[2017-11-05 18:27:31]:
-Iter 2050, Training Loss= 3.356315, Accuracy Top1 = 0.2188, Top5 = 0.4922
-Iter 2050, Validation Loss= 3.183464, Accuracy Top1 = 0.1953, Top5 = 0.5312
[2017-11-05 18:28:41]:
-Iter 2100, Training Loss= 2.976686, Accuracy Top1 = 0.2734, Top5 = 0.5469
-Iter 2100, Validation Loss= 2.851697, Accuracy Top1 = 0.3203, Top5 = 0.5859
[2017-11-05 18:29:51]:
-Iter 2150, Training Loss= 2.852940, Accuracy Top1 = 0.2891, Top5 = 0.5938
-Iter 2150, Validation Loss= 3.041638, Accuracy Top1 = 0.2812, Top5 = 0.5234
[2017-11-05 18:31:01]:
-Iter 2200, Training Loss= 2.929621, Accuracy Top1 = 0.2578, Top5 = 0.5625
-Iter 2200, Validation Loss= 2.753815, Accuracy Top1 = 0.2500, Top5 = 0.5703
[2017-11-05 18:32:11]:
-Iter 2250, Training Loss= 2.949523, Accuracy Top1 = 0.3203, Top5 = 0.5781
-Iter 2250, Validation Loss= 3.117917, Accuracy Top1 = 0.2109, Top5 = 0.5234
[2017-11-05 18:33:21]:
-Iter 2300, Training Loss= 2.762699, Accuracy Top1 = 0.3438, Top5 = 0.5859
-Iter 2300, Validation Loss= 2.936107, Accuracy Top1 = 0.2656, Top5 = 0.5781
[2017-11-05 18:34:31]:
-Iter 2350, Training Loss= 2.894310, Accuracy Top1 = 0.3203, Top5 = 0.6094
-Iter 2350, Validation Loss= 3.059524, Accuracy Top1 = 0.2031, Top5 = 0.5391
[2017-11-05 18:35:42]:
-Iter 2400, Training Loss= 2.717464, Accuracy Top1 = 0.2891, Top5 = 0.6797
-Iter 2400, Validation Loss= 3.090457, Accuracy Top1 = 0.2656, Top5 = 0.5312
[2017-11-05 18:36:52]:
-Iter 2450, Training Loss= 3.059182, Accuracy Top1 = 0.2734, Top5 = 0.5156
-Iter 2450, Validation Loss= 2.706516, Accuracy Top1 = 0.3203, Top5 = 0.6406
[2017-11-05 18:38:02]:
-Iter 2500, Training Loss= 2.856792, Accuracy Top1 = 0.2656, Top5 = 0.6094
-Iter 2500, Validation Loss= 3.014638, Accuracy Top1 = 0.2578, Top5 = 0.4922
[2017-11-05 18:39:12]:
-Iter 2550, Training Loss= 2.603940, Accuracy Top1 = 0.3281, Top5 = 0.6797
-Iter 2550, Validation Loss= 2.908893, Accuracy Top1 = 0.2891, Top5 = 0.5859
[2017-11-05 18:40:22]:
-Iter 2600, Training Loss= 2.875066, Accuracy Top1 = 0.2969, Top5 = 0.5312
-Iter 2600, Validation Loss= 2.954314, Accuracy Top1 = 0.2734, Top5 = 0.5625
[2017-11-05 18:41:32]:
-Iter 2650, Training Loss= 2.733870, Accuracy Top1 = 0.2969, Top5 = 0.6172
-Iter 2650, Validation Loss= 2.909946, Accuracy Top1 = 0.2734, Top5 = 0.5625
[2017-11-05 18:42:42]:
-Iter 2700, Training Loss= 3.054348, Accuracy Top1 = 0.2734, Top5 = 0.5156
-Iter 2700, Validation Loss= 3.053601, Accuracy Top1 = 0.2109, Top5 = 0.5469
[2017-11-05 18:43:52]:
-Iter 2750, Training Loss= 2.710472, Accuracy Top1 = 0.2891, Top5 = 0.6172
-Iter 2750, Validation Loss= 2.790516, Accuracy Top1 = 0.2188, Top5 = 0.5781
[2017-11-05 18:45:02]:
-Iter 2800, Training Loss= 3.026667, Accuracy Top1 = 0.2266, Top5 = 0.6016
-Iter 2800, Validation Loss= 2.844508, Accuracy Top1 = 0.2812, Top5 = 0.5938
[2017-11-05 18:46:12]:
-Iter 2850, Training Loss= 2.665365, Accuracy Top1 = 0.3359, Top5 = 0.6875
-Iter 2850, Validation Loss= 2.421913, Accuracy Top1 = 0.4062, Top5 = 0.6641
[2017-11-05 18:47:22]:
-Iter 2900, Training Loss= 2.922315, Accuracy Top1 = 0.3125, Top5 = 0.6250
-Iter 2900, Validation Loss= 2.689399, Accuracy Top1 = 0.3281, Top5 = 0.6250
[2017-11-05 18:48:32]:
-Iter 2950, Training Loss= 2.904562, Accuracy Top1 = 0.2500, Top5 = 0.6172
-Iter 2950, Validation Loss= 2.862582, Accuracy Top1 = 0.2969, Top5 = 0.5625
[2017-11-05 18:49:42]:
-Iter 3000, Training Loss= 2.671671, Accuracy Top1 = 0.3594, Top5 = 0.6250
-Iter 3000, Validation Loss= 2.936695, Accuracy Top1 = 0.2656, Top5 = 0.5703
[2017-11-05 18:50:52]:
-Iter 3050, Training Loss= 2.563543, Accuracy Top1 = 0.3047, Top5 = 0.7031
-Iter 3050, Validation Loss= 3.083838, Accuracy Top1 = 0.2344, Top5 = 0.5625
[2017-11-05 18:52:02]:
-Iter 3100, Training Loss= 2.564186, Accuracy Top1 = 0.3281, Top5 = 0.6641
-Iter 3100, Validation Loss= 2.801296, Accuracy Top1 = 0.2891, Top5 = 0.5859
[2017-11-05 18:53:12]:
-Iter 3150, Training Loss= 3.014734, Accuracy Top1 = 0.2656, Top5 = 0.5547
-Iter 3150, Validation Loss= 2.714077, Accuracy Top1 = 0.3125, Top5 = 0.6641
[2017-11-05 18:54:22]:
-Iter 3200, Training Loss= 2.593515, Accuracy Top1 = 0.3281, Top5 = 0.6797
-Iter 3200, Validation Loss= 2.758564, Accuracy Top1 = 0.3125, Top5 = 0.6797
[2017-11-05 18:55:32]:
-Iter 3250, Training Loss= 2.787123, Accuracy Top1 = 0.2500, Top5 = 0.6016
-Iter 3250, Validation Loss= 2.425441, Accuracy Top1 = 0.3359, Top5 = 0.6797
[2017-11-05 18:56:42]:
-Iter 3300, Training Loss= 2.461874, Accuracy Top1 = 0.3516, Top5 = 0.7109
-Iter 3300, Validation Loss= 2.811873, Accuracy Top1 = 0.2734, Top5 = 0.5625
[2017-11-05 18:57:52]:
-Iter 3350, Training Loss= 2.641516, Accuracy Top1 = 0.3281, Top5 = 0.6406
-Iter 3350, Validation Loss= 2.838260, Accuracy Top1 = 0.3203, Top5 = 0.5859
[2017-11-05 18:59:02]:
-Iter 3400, Training Loss= 2.681353, Accuracy Top1 = 0.3203, Top5 = 0.5938
-Iter 3400, Validation Loss= 2.422898, Accuracy Top1 = 0.4531, Top5 = 0.6094
[2017-11-05 19:00:12]:
-Iter 3450, Training Loss= 2.446111, Accuracy Top1 = 0.3906, Top5 = 0.7031
-Iter 3450, Validation Loss= 2.565400, Accuracy Top1 = 0.3047, Top5 = 0.6875
[2017-11-05 19:01:22]:
-Iter 3500, Training Loss= 2.657780, Accuracy Top1 = 0.3047, Top5 = 0.5703
-Iter 3500, Validation Loss= 2.594397, Accuracy Top1 = 0.3047, Top5 = 0.6562
[2017-11-05 19:02:32]:
-Iter 3550, Training Loss= 2.543514, Accuracy Top1 = 0.3438, Top5 = 0.6641
-Iter 3550, Validation Loss= 2.620400, Accuracy Top1 = 0.3516, Top5 = 0.6172
[2017-11-05 19:03:42]:
-Iter 3600, Training Loss= 2.746188, Accuracy Top1 = 0.3047, Top5 = 0.5859
-Iter 3600, Validation Loss= 2.553549, Accuracy Top1 = 0.3594, Top5 = 0.6406
[2017-11-05 19:04:52]:
-Iter 3650, Training Loss= 2.698669, Accuracy Top1 = 0.2891, Top5 = 0.6484
-Iter 3650, Validation Loss= 3.040744, Accuracy Top1 = 0.3125, Top5 = 0.5156
[2017-11-05 19:06:02]:
-Iter 3700, Training Loss= 2.522006, Accuracy Top1 = 0.3438, Top5 = 0.6562
-Iter 3700, Validation Loss= 2.525310, Accuracy Top1 = 0.3984, Top5 = 0.6484
[2017-11-05 19:07:12]:
-Iter 3750, Training Loss= 2.340140, Accuracy Top1 = 0.3672, Top5 = 0.6797
-Iter 3750, Validation Loss= 2.353404, Accuracy Top1 = 0.4141, Top5 = 0.6797
[2017-11-05 19:08:22]:
-Iter 3800, Training Loss= 2.476191, Accuracy Top1 = 0.3672, Top5 = 0.6562
-Iter 3800, Validation Loss= 2.670696, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-05 19:09:32]:
-Iter 3850, Training Loss= 2.349475, Accuracy Top1 = 0.3672, Top5 = 0.7031
-Iter 3850, Validation Loss= 2.557717, Accuracy Top1 = 0.3281, Top5 = 0.6484
[2017-11-05 19:10:42]:
-Iter 3900, Training Loss= 2.591613, Accuracy Top1 = 0.3828, Top5 = 0.6641
-Iter 3900, Validation Loss= 2.683512, Accuracy Top1 = 0.3594, Top5 = 0.6094
[2017-11-05 19:11:52]:
-Iter 3950, Training Loss= 2.741451, Accuracy Top1 = 0.2578, Top5 = 0.6328
-Iter 3950, Validation Loss= 2.619693, Accuracy Top1 = 0.3438, Top5 = 0.6094
[2017-11-05 19:13:02]:
-Iter 4000, Training Loss= 2.407401, Accuracy Top1 = 0.3516, Top5 = 0.6719
-Iter 4000, Validation Loss= 2.804542, Accuracy Top1 = 0.2422, Top5 = 0.5938
[2017-11-05 19:14:12]:
-Iter 4050, Training Loss= 2.508170, Accuracy Top1 = 0.3203, Top5 = 0.7031
-Iter 4050, Validation Loss= 2.630654, Accuracy Top1 = 0.3672, Top5 = 0.6484
[2017-11-05 19:15:22]:
-Iter 4100, Training Loss= 2.517526, Accuracy Top1 = 0.3750, Top5 = 0.6875
-Iter 4100, Validation Loss= 2.685583, Accuracy Top1 = 0.3438, Top5 = 0.6562
[2017-11-05 19:16:32]:
-Iter 4150, Training Loss= 2.420486, Accuracy Top1 = 0.3750, Top5 = 0.6328
-Iter 4150, Validation Loss= 2.642200, Accuracy Top1 = 0.3047, Top5 = 0.6406
[2017-11-05 19:17:42]:
-Iter 4200, Training Loss= 2.346480, Accuracy Top1 = 0.4219, Top5 = 0.7188
-Iter 4200, Validation Loss= 2.517870, Accuracy Top1 = 0.3203, Top5 = 0.7109
[2017-11-05 19:18:52]:
-Iter 4250, Training Loss= 2.695081, Accuracy Top1 = 0.3594, Top5 = 0.6250
-Iter 4250, Validation Loss= 2.936888, Accuracy Top1 = 0.2109, Top5 = 0.5625
[2017-11-05 19:20:02]:
-Iter 4300, Training Loss= 2.231987, Accuracy Top1 = 0.4375, Top5 = 0.7188
-Iter 4300, Validation Loss= 2.448801, Accuracy Top1 = 0.3906, Top5 = 0.6484
[2017-11-05 19:21:12]:
-Iter 4350, Training Loss= 2.289788, Accuracy Top1 = 0.4297, Top5 = 0.6719
-Iter 4350, Validation Loss= 2.542139, Accuracy Top1 = 0.2891, Top5 = 0.6562
[2017-11-05 19:22:22]:
-Iter 4400, Training Loss= 2.359401, Accuracy Top1 = 0.3750, Top5 = 0.7109
-Iter 4400, Validation Loss= 2.492501, Accuracy Top1 = 0.3438, Top5 = 0.6641
[2017-11-05 19:23:32]:
-Iter 4450, Training Loss= 2.333608, Accuracy Top1 = 0.3672, Top5 = 0.7266
-Iter 4450, Validation Loss= 2.831686, Accuracy Top1 = 0.2969, Top5 = 0.6094
[2017-11-05 19:24:43]:
-Iter 4500, Training Loss= 2.466070, Accuracy Top1 = 0.3828, Top5 = 0.6719
-Iter 4500, Validation Loss= 2.727476, Accuracy Top1 = 0.2969, Top5 = 0.6172
[2017-11-05 19:25:53]:
-Iter 4550, Training Loss= 2.392717, Accuracy Top1 = 0.3672, Top5 = 0.6641
-Iter 4550, Validation Loss= 2.528107, Accuracy Top1 = 0.3594, Top5 = 0.6562
[2017-11-05 19:27:03]:
-Iter 4600, Training Loss= 2.156127, Accuracy Top1 = 0.4375, Top5 = 0.7578
-Iter 4600, Validation Loss= 2.462548, Accuracy Top1 = 0.3594, Top5 = 0.6875
[2017-11-05 19:28:13]:
-Iter 4650, Training Loss= 2.538776, Accuracy Top1 = 0.3438, Top5 = 0.6797
-Iter 4650, Validation Loss= 3.060287, Accuracy Top1 = 0.3281, Top5 = 0.5703
[2017-11-05 19:29:23]:
-Iter 4700, Training Loss= 3.137470, Accuracy Top1 = 0.3203, Top5 = 0.6328
-Iter 4700, Validation Loss= 3.027766, Accuracy Top1 = 0.1875, Top5 = 0.5781
[2017-11-05 19:30:33]:
-Iter 4750, Training Loss= 2.317636, Accuracy Top1 = 0.3047, Top5 = 0.7344
-Iter 4750, Validation Loss= 2.511453, Accuracy Top1 = 0.3438, Top5 = 0.6797
[2017-11-05 19:31:43]:
-Iter 4800, Training Loss= 2.342654, Accuracy Top1 = 0.3516, Top5 = 0.7109
-Iter 4800, Validation Loss= 2.612829, Accuracy Top1 = 0.3203, Top5 = 0.6562
[2017-11-05 19:32:53]:
-Iter 4850, Training Loss= 2.101153, Accuracy Top1 = 0.4219, Top5 = 0.7422
-Iter 4850, Validation Loss= 2.789549, Accuracy Top1 = 0.2734, Top5 = 0.6172
[2017-11-05 19:34:03]:
-Iter 4900, Training Loss= 2.059272, Accuracy Top1 = 0.4688, Top5 = 0.7891
-Iter 4900, Validation Loss= 2.445355, Accuracy Top1 = 0.3828, Top5 = 0.6875
[2017-11-05 19:35:13]:
-Iter 4950, Training Loss= 2.195491, Accuracy Top1 = 0.3828, Top5 = 0.6953
-Iter 4950, Validation Loss= 2.568582, Accuracy Top1 = 0.3828, Top5 = 0.6641
[2017-11-05 19:36:23]:
-Iter 5000, Training Loss= 2.436618, Accuracy Top1 = 0.3125, Top5 = 0.6875
-Iter 5000, Validation Loss= 2.710822, Accuracy Top1 = 0.3281, Top5 = 0.6406
[2017-11-05 19:37:33]:
-Iter 5050, Training Loss= 2.414387, Accuracy Top1 = 0.3359, Top5 = 0.7109
-Iter 5050, Validation Loss= 2.536308, Accuracy Top1 = 0.3906, Top5 = 0.7031
[2017-11-05 19:38:43]:
-Iter 5100, Training Loss= 1.914662, Accuracy Top1 = 0.4688, Top5 = 0.7656
-Iter 5100, Validation Loss= 2.462725, Accuracy Top1 = 0.2891, Top5 = 0.7031
[2017-11-05 19:39:53]:
-Iter 5150, Training Loss= 2.387803, Accuracy Top1 = 0.3828, Top5 = 0.6953
-Iter 5150, Validation Loss= 2.890699, Accuracy Top1 = 0.3359, Top5 = 0.5859
[2017-11-05 19:41:03]:
-Iter 5200, Training Loss= 2.311463, Accuracy Top1 = 0.4453, Top5 = 0.7266
-Iter 5200, Validation Loss= 2.404442, Accuracy Top1 = 0.4062, Top5 = 0.6562
[2017-11-05 19:42:13]:
-Iter 5250, Training Loss= 2.662272, Accuracy Top1 = 0.2734, Top5 = 0.6328
-Iter 5250, Validation Loss= 2.779684, Accuracy Top1 = 0.3281, Top5 = 0.6172
[2017-11-05 19:43:23]:
-Iter 5300, Training Loss= 2.443116, Accuracy Top1 = 0.3672, Top5 = 0.6641
-Iter 5300, Validation Loss= 3.040619, Accuracy Top1 = 0.2812, Top5 = 0.5781
[2017-11-05 19:44:33]:
-Iter 5350, Training Loss= 2.378796, Accuracy Top1 = 0.3906, Top5 = 0.6953
-Iter 5350, Validation Loss= 2.255103, Accuracy Top1 = 0.3984, Top5 = 0.7266
[2017-11-05 19:45:43]:
-Iter 5400, Training Loss= 2.319039, Accuracy Top1 = 0.4375, Top5 = 0.7031
-Iter 5400, Validation Loss= 2.777097, Accuracy Top1 = 0.2969, Top5 = 0.5938
[2017-11-05 19:46:53]:
-Iter 5450, Training Loss= 2.223855, Accuracy Top1 = 0.4375, Top5 = 0.7188
-Iter 5450, Validation Loss= 2.575640, Accuracy Top1 = 0.3281, Top5 = 0.6406
[2017-11-05 19:48:03]:
-Iter 5500, Training Loss= 2.232514, Accuracy Top1 = 0.4297, Top5 = 0.6797
-Iter 5500, Validation Loss= 2.245059, Accuracy Top1 = 0.3984, Top5 = 0.6953
[2017-11-05 19:49:13]:
-Iter 5550, Training Loss= 2.093472, Accuracy Top1 = 0.4141, Top5 = 0.7422
-Iter 5550, Validation Loss= 2.495709, Accuracy Top1 = 0.3672, Top5 = 0.6562
[2017-11-05 19:50:23]:
-Iter 5600, Training Loss= 2.550178, Accuracy Top1 = 0.2969, Top5 = 0.6953
-Iter 5600, Validation Loss= 2.225384, Accuracy Top1 = 0.4297, Top5 = 0.7109
[2017-11-05 19:51:33]:
-Iter 5650, Training Loss= 2.320492, Accuracy Top1 = 0.4141, Top5 = 0.7109
-Iter 5650, Validation Loss= 2.512363, Accuracy Top1 = 0.3438, Top5 = 0.6172
[2017-11-05 19:52:43]:
-Iter 5700, Training Loss= 2.635677, Accuracy Top1 = 0.3203, Top5 = 0.5547
-Iter 5700, Validation Loss= 2.885569, Accuracy Top1 = 0.2812, Top5 = 0.5859
[2017-11-05 19:53:53]:
-Iter 5750, Training Loss= 1.886458, Accuracy Top1 = 0.4688, Top5 = 0.7812
-Iter 5750, Validation Loss= 2.479071, Accuracy Top1 = 0.3750, Top5 = 0.6328
[2017-11-05 19:55:03]:
-Iter 5800, Training Loss= 2.236139, Accuracy Top1 = 0.3828, Top5 = 0.7031
-Iter 5800, Validation Loss= 2.437926, Accuracy Top1 = 0.3594, Top5 = 0.6641
[2017-11-05 19:56:13]:
-Iter 5850, Training Loss= 2.352869, Accuracy Top1 = 0.3906, Top5 = 0.7344
-Iter 5850, Validation Loss= 2.562988, Accuracy Top1 = 0.3438, Top5 = 0.6016
[2017-11-05 19:57:23]:
-Iter 5900, Training Loss= 2.132601, Accuracy Top1 = 0.4375, Top5 = 0.7500
-Iter 5900, Validation Loss= 2.182139, Accuracy Top1 = 0.3906, Top5 = 0.7266
[2017-11-05 19:58:33]:
-Iter 5950, Training Loss= 2.313067, Accuracy Top1 = 0.3594, Top5 = 0.7266
-Iter 5950, Validation Loss= 2.439742, Accuracy Top1 = 0.3828, Top5 = 0.6719
[2017-11-05 19:59:43]:
-Iter 6000, Training Loss= 2.423429, Accuracy Top1 = 0.3438, Top5 = 0.7109
-Iter 6000, Validation Loss= 2.368694, Accuracy Top1 = 0.3672, Top5 = 0.7109
[2017-11-05 20:00:54]:
-Iter 6050, Training Loss= 2.176752, Accuracy Top1 = 0.4141, Top5 = 0.7266
-Iter 6050, Validation Loss= 2.452702, Accuracy Top1 = 0.3906, Top5 = 0.6719
[2017-11-05 20:02:04]:
-Iter 6100, Training Loss= 2.201767, Accuracy Top1 = 0.5000, Top5 = 0.7031
-Iter 6100, Validation Loss= 2.667952, Accuracy Top1 = 0.3438, Top5 = 0.6484
[2017-11-05 20:03:13]:
-Iter 6150, Training Loss= 2.215762, Accuracy Top1 = 0.3672, Top5 = 0.7422
-Iter 6150, Validation Loss= 2.645103, Accuracy Top1 = 0.2734, Top5 = 0.6641
[2017-11-05 20:04:24]:
-Iter 6200, Training Loss= 2.294119, Accuracy Top1 = 0.4219, Top5 = 0.7188
-Iter 6200, Validation Loss= 2.464821, Accuracy Top1 = 0.4062, Top5 = 0.6562
[2017-11-05 20:05:34]:
-Iter 6250, Training Loss= 2.298047, Accuracy Top1 = 0.3828, Top5 = 0.7188
-Iter 6250, Validation Loss= 2.827941, Accuracy Top1 = 0.2656, Top5 = 0.6094
[2017-11-05 20:06:43]:
-Iter 6300, Training Loss= 2.095768, Accuracy Top1 = 0.4688, Top5 = 0.7422
-Iter 6300, Validation Loss= 2.670282, Accuracy Top1 = 0.3125, Top5 = 0.6250
[2017-11-05 20:07:53]:
-Iter 6350, Training Loss= 1.933133, Accuracy Top1 = 0.4531, Top5 = 0.7891
-Iter 6350, Validation Loss= 2.208910, Accuracy Top1 = 0.3828, Top5 = 0.7188
[2017-11-05 20:09:03]:
-Iter 6400, Training Loss= 2.118571, Accuracy Top1 = 0.4297, Top5 = 0.7266
-Iter 6400, Validation Loss= 2.348417, Accuracy Top1 = 0.3984, Top5 = 0.6641
[2017-11-05 20:10:13]:
-Iter 6450, Training Loss= 1.942459, Accuracy Top1 = 0.4922, Top5 = 0.7812
-Iter 6450, Validation Loss= 2.418380, Accuracy Top1 = 0.4297, Top5 = 0.6875
[2017-11-05 20:11:23]:
-Iter 6500, Training Loss= 2.146101, Accuracy Top1 = 0.4688, Top5 = 0.7266
-Iter 6500, Validation Loss= 2.611115, Accuracy Top1 = 0.3359, Top5 = 0.6797
[2017-11-05 20:12:33]:
-Iter 6550, Training Loss= 2.201206, Accuracy Top1 = 0.3906, Top5 = 0.7188
-Iter 6550, Validation Loss= 2.510287, Accuracy Top1 = 0.3438, Top5 = 0.6562
[2017-11-05 20:13:44]:
-Iter 6600, Training Loss= 2.360240, Accuracy Top1 = 0.4141, Top5 = 0.7188
-Iter 6600, Validation Loss= 2.663619, Accuracy Top1 = 0.2656, Top5 = 0.6562
[2017-11-05 20:14:54]:
-Iter 6650, Training Loss= 1.751312, Accuracy Top1 = 0.4922, Top5 = 0.8203
-Iter 6650, Validation Loss= 2.364023, Accuracy Top1 = 0.3672, Top5 = 0.6641
[2017-11-05 20:16:04]:
-Iter 6700, Training Loss= 1.930447, Accuracy Top1 = 0.4688, Top5 = 0.7891
-Iter 6700, Validation Loss= 2.366177, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-05 20:17:14]:
-Iter 6750, Training Loss= 2.015939, Accuracy Top1 = 0.4766, Top5 = 0.7500
-Iter 6750, Validation Loss= 2.172323, Accuracy Top1 = 0.4375, Top5 = 0.7188
[2017-11-05 20:18:24]:
-Iter 6800, Training Loss= 2.095314, Accuracy Top1 = 0.4688, Top5 = 0.7500
-Iter 6800, Validation Loss= 2.363981, Accuracy Top1 = 0.4375, Top5 = 0.6953
[2017-11-05 20:19:34]:
-Iter 6850, Training Loss= 2.149744, Accuracy Top1 = 0.4062, Top5 = 0.7578
-Iter 6850, Validation Loss= 2.355515, Accuracy Top1 = 0.4453, Top5 = 0.6797
[2017-11-05 20:20:44]:
-Iter 6900, Training Loss= 2.072455, Accuracy Top1 = 0.4141, Top5 = 0.7500
-Iter 6900, Validation Loss= 2.563419, Accuracy Top1 = 0.3359, Top5 = 0.6484
[2017-11-05 20:21:54]:
-Iter 6950, Training Loss= 2.138224, Accuracy Top1 = 0.4375, Top5 = 0.7578
-Iter 6950, Validation Loss= 2.639240, Accuracy Top1 = 0.3750, Top5 = 0.6562
[2017-11-05 20:23:04]:
-Iter 7000, Training Loss= 2.209335, Accuracy Top1 = 0.3594, Top5 = 0.7578
-Iter 7000, Validation Loss= 2.815397, Accuracy Top1 = 0.3047, Top5 = 0.6484
[2017-11-05 20:24:14]:
-Iter 7050, Training Loss= 2.004669, Accuracy Top1 = 0.4766, Top5 = 0.8281
-Iter 7050, Validation Loss= 2.212806, Accuracy Top1 = 0.4609, Top5 = 0.7344
[2017-11-05 20:25:24]:
-Iter 7100, Training Loss= 1.991663, Accuracy Top1 = 0.5000, Top5 = 0.7812
-Iter 7100, Validation Loss= 2.532367, Accuracy Top1 = 0.3750, Top5 = 0.6719
[2017-11-05 20:26:34]:
-Iter 7150, Training Loss= 2.150716, Accuracy Top1 = 0.4297, Top5 = 0.7500
-Iter 7150, Validation Loss= 2.080335, Accuracy Top1 = 0.4531, Top5 = 0.7344
[2017-11-05 20:27:44]:
-Iter 7200, Training Loss= 2.192054, Accuracy Top1 = 0.3906, Top5 = 0.7812
-Iter 7200, Validation Loss= 2.424663, Accuracy Top1 = 0.3594, Top5 = 0.6641
[2017-11-05 20:28:54]:
-Iter 7250, Training Loss= 1.834549, Accuracy Top1 = 0.4844, Top5 = 0.7969
-Iter 7250, Validation Loss= 2.490216, Accuracy Top1 = 0.3750, Top5 = 0.6484
[2017-11-05 20:30:04]:
-Iter 7300, Training Loss= 1.856552, Accuracy Top1 = 0.5312, Top5 = 0.8047
-Iter 7300, Validation Loss= 2.285243, Accuracy Top1 = 0.3906, Top5 = 0.7188
[2017-11-05 20:31:14]:
-Iter 7350, Training Loss= 2.091621, Accuracy Top1 = 0.4453, Top5 = 0.7578
-Iter 7350, Validation Loss= 2.410463, Accuracy Top1 = 0.3984, Top5 = 0.6797
[2017-11-05 20:32:24]:
-Iter 7400, Training Loss= 2.001157, Accuracy Top1 = 0.4922, Top5 = 0.7344
-Iter 7400, Validation Loss= 2.126621, Accuracy Top1 = 0.4531, Top5 = 0.8047
[2017-11-05 20:33:34]:
-Iter 7450, Training Loss= 2.164006, Accuracy Top1 = 0.4609, Top5 = 0.7266
-Iter 7450, Validation Loss= 2.516848, Accuracy Top1 = 0.3516, Top5 = 0.6641
[2017-11-05 20:34:44]:
-Iter 7500, Training Loss= 2.079205, Accuracy Top1 = 0.5312, Top5 = 0.7969
-Iter 7500, Validation Loss= 2.104250, Accuracy Top1 = 0.4766, Top5 = 0.7734
[2017-11-05 20:35:54]:
-Iter 7550, Training Loss= 1.946872, Accuracy Top1 = 0.4219, Top5 = 0.7891
-Iter 7550, Validation Loss= 2.733754, Accuracy Top1 = 0.3203, Top5 = 0.5547
[2017-11-05 20:37:04]:
-Iter 7600, Training Loss= 2.016439, Accuracy Top1 = 0.4531, Top5 = 0.7422
-Iter 7600, Validation Loss= 2.223783, Accuracy Top1 = 0.4688, Top5 = 0.6953
[2017-11-05 20:38:14]:
-Iter 7650, Training Loss= 2.141344, Accuracy Top1 = 0.4375, Top5 = 0.7344
-Iter 7650, Validation Loss= 2.380958, Accuracy Top1 = 0.4141, Top5 = 0.7031
[2017-11-05 20:39:24]:
-Iter 7700, Training Loss= 1.816851, Accuracy Top1 = 0.5078, Top5 = 0.7891
-Iter 7700, Validation Loss= 2.562732, Accuracy Top1 = 0.3594, Top5 = 0.6562
[2017-11-05 20:40:34]:
-Iter 7750, Training Loss= 1.962080, Accuracy Top1 = 0.5156, Top5 = 0.7891
-Iter 7750, Validation Loss= 2.097723, Accuracy Top1 = 0.4141, Top5 = 0.7422
[2017-11-05 20:41:44]:
-Iter 7800, Training Loss= 2.026436, Accuracy Top1 = 0.4531, Top5 = 0.7578
-Iter 7800, Validation Loss= 2.764445, Accuracy Top1 = 0.3047, Top5 = 0.6016
[2017-11-05 20:42:54]:
-Iter 7850, Training Loss= 1.818406, Accuracy Top1 = 0.4766, Top5 = 0.8125
-Iter 7850, Validation Loss= 2.423510, Accuracy Top1 = 0.4375, Top5 = 0.6719
[2017-11-05 20:44:04]:
-Iter 7900, Training Loss= 1.710709, Accuracy Top1 = 0.5078, Top5 = 0.8047
-Iter 7900, Validation Loss= 2.663134, Accuracy Top1 = 0.3359, Top5 = 0.6172
[2017-11-05 20:45:14]:
-Iter 7950, Training Loss= 1.868052, Accuracy Top1 = 0.4922, Top5 = 0.7969
-Iter 7950, Validation Loss= 2.326799, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-05 20:46:24]:
-Iter 8000, Training Loss= 2.115049, Accuracy Top1 = 0.4453, Top5 = 0.7266
-Iter 8000, Validation Loss= 2.625958, Accuracy Top1 = 0.3359, Top5 = 0.6797
[2017-11-05 20:47:34]:
-Iter 8050, Training Loss= 1.952585, Accuracy Top1 = 0.4844, Top5 = 0.7812
-Iter 8050, Validation Loss= 2.741197, Accuracy Top1 = 0.3281, Top5 = 0.6562
[2017-11-05 20:48:44]:
-Iter 8100, Training Loss= 1.814877, Accuracy Top1 = 0.4688, Top5 = 0.8047
-Iter 8100, Validation Loss= 2.385623, Accuracy Top1 = 0.3906, Top5 = 0.6719
[2017-11-05 20:49:54]:
-Iter 8150, Training Loss= 1.857055, Accuracy Top1 = 0.4844, Top5 = 0.8125
-Iter 8150, Validation Loss= 2.465502, Accuracy Top1 = 0.3594, Top5 = 0.6797
[2017-11-05 20:51:04]:
-Iter 8200, Training Loss= 2.079368, Accuracy Top1 = 0.3984, Top5 = 0.7812
-Iter 8200, Validation Loss= 2.430696, Accuracy Top1 = 0.4141, Top5 = 0.6562
[2017-11-05 20:52:14]:
-Iter 8250, Training Loss= 1.931219, Accuracy Top1 = 0.4453, Top5 = 0.7500
-Iter 8250, Validation Loss= 2.364271, Accuracy Top1 = 0.3594, Top5 = 0.6875
[2017-11-05 20:53:24]:
-Iter 8300, Training Loss= 2.096204, Accuracy Top1 = 0.4766, Top5 = 0.7266
-Iter 8300, Validation Loss= 2.383813, Accuracy Top1 = 0.3828, Top5 = 0.7031
[2017-11-05 20:54:34]:
-Iter 8350, Training Loss= 1.939171, Accuracy Top1 = 0.4766, Top5 = 0.7500
-Iter 8350, Validation Loss= 2.473684, Accuracy Top1 = 0.3281, Top5 = 0.6797
[2017-11-05 20:55:44]:
-Iter 8400, Training Loss= 1.952030, Accuracy Top1 = 0.5469, Top5 = 0.7656
-Iter 8400, Validation Loss= 2.353474, Accuracy Top1 = 0.3438, Top5 = 0.7031
[2017-11-05 20:56:54]:
-Iter 8450, Training Loss= 1.912211, Accuracy Top1 = 0.4844, Top5 = 0.8359
-Iter 8450, Validation Loss= 2.458362, Accuracy Top1 = 0.3906, Top5 = 0.6484
[2017-11-05 20:58:04]:
-Iter 8500, Training Loss= 1.698147, Accuracy Top1 = 0.5703, Top5 = 0.8203
-Iter 8500, Validation Loss= 2.215558, Accuracy Top1 = 0.4297, Top5 = 0.7031
[2017-11-05 20:59:14]:
-Iter 8550, Training Loss= 1.889933, Accuracy Top1 = 0.4766, Top5 = 0.8125
-Iter 8550, Validation Loss= 3.010601, Accuracy Top1 = 0.2891, Top5 = 0.5625
[2017-11-05 21:00:24]:
-Iter 8600, Training Loss= 1.841863, Accuracy Top1 = 0.5234, Top5 = 0.8281
-Iter 8600, Validation Loss= 2.452838, Accuracy Top1 = 0.3281, Top5 = 0.6875
[2017-11-05 21:01:34]:
-Iter 8650, Training Loss= 1.691847, Accuracy Top1 = 0.5469, Top5 = 0.8594
-Iter 8650, Validation Loss= 2.135517, Accuracy Top1 = 0.4219, Top5 = 0.7812
[2017-11-05 21:02:44]:
-Iter 8700, Training Loss= 1.863882, Accuracy Top1 = 0.4609, Top5 = 0.8047
-Iter 8700, Validation Loss= 2.443815, Accuracy Top1 = 0.3984, Top5 = 0.6797
[2017-11-05 21:03:54]:
-Iter 8750, Training Loss= 1.757798, Accuracy Top1 = 0.5000, Top5 = 0.8516
-Iter 8750, Validation Loss= 2.473613, Accuracy Top1 = 0.3516, Top5 = 0.6953
[2017-11-05 21:05:04]:
-Iter 8800, Training Loss= 1.675972, Accuracy Top1 = 0.5547, Top5 = 0.8594
-Iter 8800, Validation Loss= 2.189666, Accuracy Top1 = 0.4297, Top5 = 0.7500
[2017-11-05 21:06:14]:
-Iter 8850, Training Loss= 1.838345, Accuracy Top1 = 0.5078, Top5 = 0.8281
-Iter 8850, Validation Loss= 2.533754, Accuracy Top1 = 0.3672, Top5 = 0.6719
[2017-11-05 21:07:24]:
-Iter 8900, Training Loss= 1.736008, Accuracy Top1 = 0.5234, Top5 = 0.8438
-Iter 8900, Validation Loss= 2.459620, Accuracy Top1 = 0.3672, Top5 = 0.7109
[2017-11-05 21:08:34]:
-Iter 8950, Training Loss= 1.847889, Accuracy Top1 = 0.5234, Top5 = 0.7656
-Iter 8950, Validation Loss= 2.295949, Accuracy Top1 = 0.3516, Top5 = 0.7188
[2017-11-05 21:09:44]:
-Iter 9000, Training Loss= 1.778159, Accuracy Top1 = 0.4609, Top5 = 0.8125
-Iter 9000, Validation Loss= 2.189127, Accuracy Top1 = 0.3828, Top5 = 0.7656
[2017-11-05 21:10:54]:
-Iter 9050, Training Loss= 1.770179, Accuracy Top1 = 0.5234, Top5 = 0.8125
-Iter 9050, Validation Loss= 2.687513, Accuracy Top1 = 0.3125, Top5 = 0.6016
[2017-11-05 21:12:04]:
-Iter 9100, Training Loss= 1.778592, Accuracy Top1 = 0.4844, Top5 = 0.8125
-Iter 9100, Validation Loss= 2.580351, Accuracy Top1 = 0.4062, Top5 = 0.6641
[2017-11-05 21:13:14]:
-Iter 9150, Training Loss= 2.438068, Accuracy Top1 = 0.4844, Top5 = 0.7578
-Iter 9150, Validation Loss= 2.389203, Accuracy Top1 = 0.3359, Top5 = 0.7266
[2017-11-05 21:14:24]:
-Iter 9200, Training Loss= 1.841977, Accuracy Top1 = 0.5000, Top5 = 0.7578
-Iter 9200, Validation Loss= 2.703607, Accuracy Top1 = 0.3359, Top5 = 0.6016
[2017-11-05 21:15:34]:
-Iter 9250, Training Loss= 1.739374, Accuracy Top1 = 0.5469, Top5 = 0.8047
-Iter 9250, Validation Loss= 2.218175, Accuracy Top1 = 0.4766, Top5 = 0.7266
[2017-11-05 21:16:44]:
-Iter 9300, Training Loss= 1.596768, Accuracy Top1 = 0.5703, Top5 = 0.8516
-Iter 9300, Validation Loss= 2.423723, Accuracy Top1 = 0.4062, Top5 = 0.6797
[2017-11-05 21:17:54]:
-Iter 9350, Training Loss= 1.798651, Accuracy Top1 = 0.5156, Top5 = 0.8281
-Iter 9350, Validation Loss= 2.346292, Accuracy Top1 = 0.3672, Top5 = 0.7031
[2017-11-05 21:19:04]:
-Iter 9400, Training Loss= 1.894553, Accuracy Top1 = 0.4922, Top5 = 0.8047
-Iter 9400, Validation Loss= 2.358689, Accuracy Top1 = 0.3672, Top5 = 0.7188
[2017-11-05 21:20:14]:
-Iter 9450, Training Loss= 1.636461, Accuracy Top1 = 0.5703, Top5 = 0.8516
-Iter 9450, Validation Loss= 2.603295, Accuracy Top1 = 0.3984, Top5 = 0.6562
[2017-11-05 21:21:24]:
-Iter 9500, Training Loss= 1.709353, Accuracy Top1 = 0.5312, Top5 = 0.8359
-Iter 9500, Validation Loss= 2.089473, Accuracy Top1 = 0.4688, Top5 = 0.7734
[2017-11-05 21:22:34]:
-Iter 9550, Training Loss= 1.673878, Accuracy Top1 = 0.5547, Top5 = 0.8281
-Iter 9550, Validation Loss= 2.599604, Accuracy Top1 = 0.3438, Top5 = 0.6953
[2017-11-05 21:23:44]:
-Iter 9600, Training Loss= 2.009238, Accuracy Top1 = 0.4688, Top5 = 0.7422
-Iter 9600, Validation Loss= 2.912557, Accuracy Top1 = 0.3672, Top5 = 0.6484
[2017-11-05 21:24:54]:
-Iter 9650, Training Loss= 1.785518, Accuracy Top1 = 0.4922, Top5 = 0.8203
-Iter 9650, Validation Loss= 2.423762, Accuracy Top1 = 0.4219, Top5 = 0.6719
[2017-11-05 21:26:04]:
-Iter 9700, Training Loss= 1.789016, Accuracy Top1 = 0.4766, Top5 = 0.8125
-Iter 9700, Validation Loss= 2.624119, Accuracy Top1 = 0.3438, Top5 = 0.6484
[2017-11-05 21:27:14]:
-Iter 9750, Training Loss= 1.763072, Accuracy Top1 = 0.5078, Top5 = 0.8203
-Iter 9750, Validation Loss= 2.616119, Accuracy Top1 = 0.2891, Top5 = 0.6562
[2017-11-05 21:28:24]:
-Iter 9800, Training Loss= 1.871247, Accuracy Top1 = 0.5234, Top5 = 0.7969
-Iter 9800, Validation Loss= 2.621046, Accuracy Top1 = 0.3906, Top5 = 0.6641
[2017-11-05 21:29:34]:
-Iter 9850, Training Loss= 1.679346, Accuracy Top1 = 0.4844, Top5 = 0.8672
-Iter 9850, Validation Loss= 2.056830, Accuracy Top1 = 0.4844, Top5 = 0.7578
[2017-11-05 21:30:44]:
-Iter 9900, Training Loss= 1.883319, Accuracy Top1 = 0.5156, Top5 = 0.7812
-Iter 9900, Validation Loss= 2.390551, Accuracy Top1 = 0.3438, Top5 = 0.7422
[2017-11-05 21:31:54]:
-Iter 9950, Training Loss= 1.771599, Accuracy Top1 = 0.5078, Top5 = 0.7734
-Iter 9950, Validation Loss= 2.328351, Accuracy Top1 = 0.3984, Top5 = 0.7031
Model saved at Iter 10000 !
[2017-11-05 21:33:06]:
-Iter 10000, Training Loss= 1.569659, Accuracy Top1 = 0.5547, Top5 = 0.8281
-Iter 10000, Validation Loss= 2.297206, Accuracy Top1 = 0.3828, Top5 = 0.6953
[2017-11-05 21:34:16]:
-Iter 10050, Training Loss= 1.565612, Accuracy Top1 = 0.5469, Top5 = 0.8516
-Iter 10050, Validation Loss= 2.344630, Accuracy Top1 = 0.3516, Top5 = 0.6797
[2017-11-05 21:35:25]:
-Iter 10100, Training Loss= 1.412635, Accuracy Top1 = 0.6016, Top5 = 0.9062
-Iter 10100, Validation Loss= 2.439492, Accuracy Top1 = 0.3594, Top5 = 0.6641
[2017-11-05 21:36:35]:
-Iter 10150, Training Loss= 1.855506, Accuracy Top1 = 0.5156, Top5 = 0.8047
-Iter 10150, Validation Loss= 2.814940, Accuracy Top1 = 0.2812, Top5 = 0.6406
[2017-11-05 21:37:45]:
-Iter 10200, Training Loss= 1.816479, Accuracy Top1 = 0.4688, Top5 = 0.7891
-Iter 10200, Validation Loss= 2.552067, Accuracy Top1 = 0.3594, Top5 = 0.6719
[2017-11-05 21:38:54]:
-Iter 10250, Training Loss= 1.578529, Accuracy Top1 = 0.5859, Top5 = 0.8750
-Iter 10250, Validation Loss= 2.211206, Accuracy Top1 = 0.4609, Top5 = 0.7578
[2017-11-05 21:40:04]:
-Iter 10300, Training Loss= 1.742610, Accuracy Top1 = 0.5156, Top5 = 0.8281
-Iter 10300, Validation Loss= 2.299591, Accuracy Top1 = 0.3828, Top5 = 0.7188
[2017-11-05 21:41:14]:
-Iter 10350, Training Loss= 1.428467, Accuracy Top1 = 0.6172, Top5 = 0.8750
-Iter 10350, Validation Loss= 2.437678, Accuracy Top1 = 0.4453, Top5 = 0.6562
[2017-11-05 21:42:23]:
-Iter 10400, Training Loss= 1.558589, Accuracy Top1 = 0.5469, Top5 = 0.8203
-Iter 10400, Validation Loss= 2.515565, Accuracy Top1 = 0.3672, Top5 = 0.6719
[2017-11-05 21:43:33]:
-Iter 10450, Training Loss= 1.534142, Accuracy Top1 = 0.5703, Top5 = 0.8672
-Iter 10450, Validation Loss= 2.401099, Accuracy Top1 = 0.3984, Top5 = 0.7188
[2017-11-05 21:44:43]:
-Iter 10500, Training Loss= 1.627537, Accuracy Top1 = 0.5391, Top5 = 0.8281
-Iter 10500, Validation Loss= 2.438188, Accuracy Top1 = 0.4062, Top5 = 0.6953
[2017-11-05 21:45:52]:
-Iter 10550, Training Loss= 1.533697, Accuracy Top1 = 0.5703, Top5 = 0.8516
-Iter 10550, Validation Loss= 2.436603, Accuracy Top1 = 0.3516, Top5 = 0.6953
[2017-11-05 21:47:02]:
-Iter 10600, Training Loss= 1.371387, Accuracy Top1 = 0.6250, Top5 = 0.8594
-Iter 10600, Validation Loss= 2.446970, Accuracy Top1 = 0.3516, Top5 = 0.6875
[2017-11-05 21:48:12]:
-Iter 10650, Training Loss= 1.694284, Accuracy Top1 = 0.5000, Top5 = 0.8828
-Iter 10650, Validation Loss= 2.051857, Accuracy Top1 = 0.4844, Top5 = 0.7500
[2017-11-05 21:49:21]:
-Iter 10700, Training Loss= 1.581511, Accuracy Top1 = 0.5469, Top5 = 0.8594
-Iter 10700, Validation Loss= 2.341913, Accuracy Top1 = 0.4062, Top5 = 0.7188
[2017-11-05 21:50:31]:
-Iter 10750, Training Loss= 1.550747, Accuracy Top1 = 0.6016, Top5 = 0.8672
-Iter 10750, Validation Loss= 2.168032, Accuracy Top1 = 0.4141, Top5 = 0.7031
[2017-11-05 21:51:41]:
-Iter 10800, Training Loss= 1.515045, Accuracy Top1 = 0.5625, Top5 = 0.8984
-Iter 10800, Validation Loss= 2.651849, Accuracy Top1 = 0.3828, Top5 = 0.6328
[2017-11-05 21:52:50]:
-Iter 10850, Training Loss= 1.502009, Accuracy Top1 = 0.5938, Top5 = 0.8594
-Iter 10850, Validation Loss= 2.487631, Accuracy Top1 = 0.3750, Top5 = 0.6797
[2017-11-05 21:54:00]:
-Iter 10900, Training Loss= 1.826217, Accuracy Top1 = 0.5781, Top5 = 0.8047
-Iter 10900, Validation Loss= 2.810156, Accuracy Top1 = 0.3047, Top5 = 0.6328
[2017-11-05 21:55:10]:
-Iter 10950, Training Loss= 1.528117, Accuracy Top1 = 0.5859, Top5 = 0.8906
-Iter 10950, Validation Loss= 2.262686, Accuracy Top1 = 0.4688, Top5 = 0.6719
[2017-11-05 21:56:19]:
-Iter 11000, Training Loss= 1.494063, Accuracy Top1 = 0.5781, Top5 = 0.8594
-Iter 11000, Validation Loss= 2.191769, Accuracy Top1 = 0.4531, Top5 = 0.6875
[2017-11-05 21:57:29]:
-Iter 11050, Training Loss= 1.577666, Accuracy Top1 = 0.6016, Top5 = 0.8594
-Iter 11050, Validation Loss= 2.435511, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-05 21:58:39]:
-Iter 11100, Training Loss= 1.257692, Accuracy Top1 = 0.6641, Top5 = 0.9141
-Iter 11100, Validation Loss= 2.249678, Accuracy Top1 = 0.4453, Top5 = 0.7266
[2017-11-05 21:59:49]:
-Iter 11150, Training Loss= 1.301526, Accuracy Top1 = 0.6172, Top5 = 0.8984
-Iter 11150, Validation Loss= 2.549968, Accuracy Top1 = 0.3906, Top5 = 0.7031
[2017-11-05 22:00:58]:
-Iter 11200, Training Loss= 1.246590, Accuracy Top1 = 0.6484, Top5 = 0.8984
-Iter 11200, Validation Loss= 2.263093, Accuracy Top1 = 0.4453, Top5 = 0.7188
[2017-11-05 22:02:08]:
-Iter 11250, Training Loss= 1.556594, Accuracy Top1 = 0.5469, Top5 = 0.8125
-Iter 11250, Validation Loss= 2.329893, Accuracy Top1 = 0.4219, Top5 = 0.6953
[2017-11-05 22:03:18]:
-Iter 11300, Training Loss= 1.469758, Accuracy Top1 = 0.6016, Top5 = 0.8750
-Iter 11300, Validation Loss= 2.223434, Accuracy Top1 = 0.4531, Top5 = 0.7188
[2017-11-05 22:04:27]:
-Iter 11350, Training Loss= 1.436531, Accuracy Top1 = 0.5859, Top5 = 0.8828
-Iter 11350, Validation Loss= 2.502526, Accuracy Top1 = 0.3906, Top5 = 0.6953
[2017-11-05 22:05:37]:
-Iter 11400, Training Loss= 1.335788, Accuracy Top1 = 0.6250, Top5 = 0.8750
-Iter 11400, Validation Loss= 2.210733, Accuracy Top1 = 0.4609, Top5 = 0.7969
[2017-11-05 22:06:47]:
-Iter 11450, Training Loss= 1.622377, Accuracy Top1 = 0.5391, Top5 = 0.8359
-Iter 11450, Validation Loss= 2.678710, Accuracy Top1 = 0.3828, Top5 = 0.6172
[2017-11-05 22:07:57]:
-Iter 11500, Training Loss= 1.451125, Accuracy Top1 = 0.6328, Top5 = 0.8672
-Iter 11500, Validation Loss= 2.636765, Accuracy Top1 = 0.3828, Top5 = 0.6172
[2017-11-05 22:09:06]:
-Iter 11550, Training Loss= 1.395230, Accuracy Top1 = 0.6094, Top5 = 0.8984
-Iter 11550, Validation Loss= 2.364268, Accuracy Top1 = 0.3594, Top5 = 0.7266
[2017-11-05 22:10:16]:
-Iter 11600, Training Loss= 1.335024, Accuracy Top1 = 0.6641, Top5 = 0.8594
-Iter 11600, Validation Loss= 2.371559, Accuracy Top1 = 0.4453, Top5 = 0.7031
[2017-11-05 22:11:26]:
-Iter 11650, Training Loss= 1.385782, Accuracy Top1 = 0.6250, Top5 = 0.9141
-Iter 11650, Validation Loss= 2.122551, Accuracy Top1 = 0.4766, Top5 = 0.7578
[2017-11-05 22:12:35]:
-Iter 11700, Training Loss= 1.276267, Accuracy Top1 = 0.6250, Top5 = 0.8828
-Iter 11700, Validation Loss= 2.488590, Accuracy Top1 = 0.3750, Top5 = 0.6797
[2017-11-05 22:13:45]:
-Iter 11750, Training Loss= 1.442435, Accuracy Top1 = 0.6016, Top5 = 0.8594
-Iter 11750, Validation Loss= 2.600620, Accuracy Top1 = 0.3906, Top5 = 0.6484
[2017-11-05 22:14:55]:
-Iter 11800, Training Loss= 1.131323, Accuracy Top1 = 0.6641, Top5 = 0.9141
-Iter 11800, Validation Loss= 2.724957, Accuracy Top1 = 0.3359, Top5 = 0.6172
[2017-11-05 22:16:04]:
-Iter 11850, Training Loss= 1.352689, Accuracy Top1 = 0.6094, Top5 = 0.9141
-Iter 11850, Validation Loss= 2.563150, Accuracy Top1 = 0.3984, Top5 = 0.7266
[2017-11-05 22:17:14]:
-Iter 11900, Training Loss= 1.367153, Accuracy Top1 = 0.6250, Top5 = 0.8672
-Iter 11900, Validation Loss= 2.318612, Accuracy Top1 = 0.3984, Top5 = 0.7266
[2017-11-05 22:18:23]:
-Iter 11950, Training Loss= 1.484600, Accuracy Top1 = 0.6250, Top5 = 0.8672
-Iter 11950, Validation Loss= 2.885157, Accuracy Top1 = 0.2891, Top5 = 0.6250
[2017-11-05 22:19:33]:
-Iter 12000, Training Loss= 1.006509, Accuracy Top1 = 0.7266, Top5 = 0.9453
-Iter 12000, Validation Loss= 2.261334, Accuracy Top1 = 0.4922, Top5 = 0.7188
[2017-11-05 22:20:42]:
-Iter 12050, Training Loss= 1.618005, Accuracy Top1 = 0.4922, Top5 = 0.8125
-Iter 12050, Validation Loss= 2.399839, Accuracy Top1 = 0.3672, Top5 = 0.7344
[2017-11-05 22:21:52]:
-Iter 12100, Training Loss= 1.612265, Accuracy Top1 = 0.5938, Top5 = 0.8125
-Iter 12100, Validation Loss= 2.517164, Accuracy Top1 = 0.4453, Top5 = 0.6797
[2017-11-05 22:23:02]:
-Iter 12150, Training Loss= 1.436691, Accuracy Top1 = 0.5938, Top5 = 0.8516
-Iter 12150, Validation Loss= 2.353208, Accuracy Top1 = 0.4297, Top5 = 0.7188
[2017-11-05 22:24:11]:
-Iter 12200, Training Loss= 1.102969, Accuracy Top1 = 0.6719, Top5 = 0.9375
-Iter 12200, Validation Loss= 2.347555, Accuracy Top1 = 0.4219, Top5 = 0.7500
[2017-11-05 22:25:21]:
-Iter 12250, Training Loss= 1.355699, Accuracy Top1 = 0.6328, Top5 = 0.8828
-Iter 12250, Validation Loss= 2.536361, Accuracy Top1 = 0.3828, Top5 = 0.7500
[2017-11-05 22:26:31]:
-Iter 12300, Training Loss= 1.289236, Accuracy Top1 = 0.6328, Top5 = 0.8906
-Iter 12300, Validation Loss= 2.374511, Accuracy Top1 = 0.3594, Top5 = 0.7656
[2017-11-05 22:27:40]:
-Iter 12350, Training Loss= 1.165715, Accuracy Top1 = 0.6484, Top5 = 0.8750
-Iter 12350, Validation Loss= 2.408696, Accuracy Top1 = 0.3672, Top5 = 0.6875
[2017-11-05 22:28:50]:
-Iter 12400, Training Loss= 1.166149, Accuracy Top1 = 0.6797, Top5 = 0.9141
-Iter 12400, Validation Loss= 2.067460, Accuracy Top1 = 0.4375, Top5 = 0.7500
[2017-11-05 22:30:00]:
-Iter 12450, Training Loss= 1.613196, Accuracy Top1 = 0.5703, Top5 = 0.8125
-Iter 12450, Validation Loss= 3.221344, Accuracy Top1 = 0.3125, Top5 = 0.5703
[2017-11-05 22:31:09]:
-Iter 12500, Training Loss= 1.595184, Accuracy Top1 = 0.5391, Top5 = 0.8047
-Iter 12500, Validation Loss= 2.725101, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-05 22:32:19]:
-Iter 12550, Training Loss= 1.266468, Accuracy Top1 = 0.6484, Top5 = 0.9219
-Iter 12550, Validation Loss= 2.284435, Accuracy Top1 = 0.4141, Top5 = 0.7422
[2017-11-05 22:33:29]:
-Iter 12600, Training Loss= 1.146142, Accuracy Top1 = 0.6484, Top5 = 0.9609
-Iter 12600, Validation Loss= 2.601852, Accuracy Top1 = 0.3672, Top5 = 0.6719
[2017-11-05 22:34:38]:
-Iter 12650, Training Loss= 1.328325, Accuracy Top1 = 0.5859, Top5 = 0.8906
-Iter 12650, Validation Loss= 2.448339, Accuracy Top1 = 0.3516, Top5 = 0.7109
[2017-11-05 22:35:48]:
-Iter 12700, Training Loss= 1.120337, Accuracy Top1 = 0.7344, Top5 = 0.9219
-Iter 12700, Validation Loss= 2.126228, Accuracy Top1 = 0.4922, Top5 = 0.7734
[2017-11-05 22:36:58]:
-Iter 12750, Training Loss= 1.494373, Accuracy Top1 = 0.5781, Top5 = 0.8750
-Iter 12750, Validation Loss= 2.651650, Accuracy Top1 = 0.4219, Top5 = 0.7109
[2017-11-05 22:38:07]:
-Iter 12800, Training Loss= 1.227204, Accuracy Top1 = 0.6172, Top5 = 0.9141
-Iter 12800, Validation Loss= 2.349401, Accuracy Top1 = 0.3984, Top5 = 0.7109
[2017-11-05 22:39:17]:
-Iter 12850, Training Loss= 1.339310, Accuracy Top1 = 0.6094, Top5 = 0.8984
-Iter 12850, Validation Loss= 2.423979, Accuracy Top1 = 0.3984, Top5 = 0.7188
[2017-11-05 22:40:27]:
-Iter 12900, Training Loss= 1.142570, Accuracy Top1 = 0.6797, Top5 = 0.9297
-Iter 12900, Validation Loss= 2.595854, Accuracy Top1 = 0.3594, Top5 = 0.6953
[2017-11-05 22:41:36]:
-Iter 12950, Training Loss= 1.204579, Accuracy Top1 = 0.6406, Top5 = 0.9297
-Iter 12950, Validation Loss= 2.561064, Accuracy Top1 = 0.4219, Top5 = 0.7031
[2017-11-05 22:42:46]:
-Iter 13000, Training Loss= 1.113121, Accuracy Top1 = 0.6719, Top5 = 0.9141
-Iter 13000, Validation Loss= 2.565633, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-05 22:43:56]:
-Iter 13050, Training Loss= 1.255934, Accuracy Top1 = 0.6484, Top5 = 0.8906
-Iter 13050, Validation Loss= 2.561191, Accuracy Top1 = 0.3516, Top5 = 0.6797
[2017-11-05 22:45:05]:
-Iter 13100, Training Loss= 1.079194, Accuracy Top1 = 0.6719, Top5 = 0.9375
-Iter 13100, Validation Loss= 2.776362, Accuracy Top1 = 0.3750, Top5 = 0.6250
[2017-11-05 22:46:15]:
-Iter 13150, Training Loss= 1.160426, Accuracy Top1 = 0.6562, Top5 = 0.9531
-Iter 13150, Validation Loss= 2.259347, Accuracy Top1 = 0.4453, Top5 = 0.7031
[2017-11-05 22:47:25]:
-Iter 13200, Training Loss= 1.252389, Accuracy Top1 = 0.6250, Top5 = 0.8828
-Iter 13200, Validation Loss= 2.418116, Accuracy Top1 = 0.4219, Top5 = 0.6641
[2017-11-05 22:48:34]:
-Iter 13250, Training Loss= 1.225200, Accuracy Top1 = 0.6641, Top5 = 0.8828
-Iter 13250, Validation Loss= 2.251662, Accuracy Top1 = 0.4062, Top5 = 0.6953
[2017-11-05 22:49:44]:
-Iter 13300, Training Loss= 1.210733, Accuracy Top1 = 0.6641, Top5 = 0.9297
-Iter 13300, Validation Loss= 2.453807, Accuracy Top1 = 0.4062, Top5 = 0.6875
[2017-11-05 22:50:54]:
-Iter 13350, Training Loss= 0.932046, Accuracy Top1 = 0.7500, Top5 = 0.9375
-Iter 13350, Validation Loss= 2.313200, Accuracy Top1 = 0.4766, Top5 = 0.7188
[2017-11-05 22:52:03]:
-Iter 13400, Training Loss= 1.204897, Accuracy Top1 = 0.6250, Top5 = 0.8984
-Iter 13400, Validation Loss= 2.236925, Accuracy Top1 = 0.4453, Top5 = 0.7578
[2017-11-05 22:53:13]:
-Iter 13450, Training Loss= 1.206591, Accuracy Top1 = 0.6094, Top5 = 0.8828
-Iter 13450, Validation Loss= 2.243445, Accuracy Top1 = 0.4531, Top5 = 0.7188
[2017-11-05 22:54:23]:
-Iter 13500, Training Loss= 0.968837, Accuracy Top1 = 0.7188, Top5 = 0.9375
-Iter 13500, Validation Loss= 2.783756, Accuracy Top1 = 0.4531, Top5 = 0.6953
[2017-11-05 22:55:32]:
-Iter 13550, Training Loss= 1.313383, Accuracy Top1 = 0.6328, Top5 = 0.9141
-Iter 13550, Validation Loss= 2.912321, Accuracy Top1 = 0.2969, Top5 = 0.6094
[2017-11-05 22:56:42]:
-Iter 13600, Training Loss= 1.201713, Accuracy Top1 = 0.6172, Top5 = 0.9062
-Iter 13600, Validation Loss= 2.557302, Accuracy Top1 = 0.4062, Top5 = 0.7188
[2017-11-05 22:57:52]:
-Iter 13650, Training Loss= 1.039684, Accuracy Top1 = 0.7109, Top5 = 0.9297
-Iter 13650, Validation Loss= 2.525833, Accuracy Top1 = 0.3984, Top5 = 0.6875
[2017-11-05 22:59:01]:
-Iter 13700, Training Loss= 1.202394, Accuracy Top1 = 0.6875, Top5 = 0.8984
-Iter 13700, Validation Loss= 2.406193, Accuracy Top1 = 0.4219, Top5 = 0.7109
[2017-11-05 23:00:11]:
-Iter 13750, Training Loss= 1.155219, Accuracy Top1 = 0.7656, Top5 = 0.9375
-Iter 13750, Validation Loss= 2.091602, Accuracy Top1 = 0.4688, Top5 = 0.7734
[2017-11-05 23:01:21]:
-Iter 13800, Training Loss= 1.039253, Accuracy Top1 = 0.7031, Top5 = 0.9375
-Iter 13800, Validation Loss= 2.301307, Accuracy Top1 = 0.3906, Top5 = 0.7266
[2017-11-05 23:02:30]:
-Iter 13850, Training Loss= 1.109987, Accuracy Top1 = 0.6562, Top5 = 0.9375
-Iter 13850, Validation Loss= 2.336977, Accuracy Top1 = 0.4062, Top5 = 0.6875
[2017-11-05 23:03:40]:
-Iter 13900, Training Loss= 1.279115, Accuracy Top1 = 0.6562, Top5 = 0.8828
-Iter 13900, Validation Loss= 2.077478, Accuracy Top1 = 0.4219, Top5 = 0.7656
[2017-11-05 23:04:50]:
-Iter 13950, Training Loss= 1.117400, Accuracy Top1 = 0.7109, Top5 = 0.9062
-Iter 13950, Validation Loss= 2.520247, Accuracy Top1 = 0.3906, Top5 = 0.7188
[2017-11-05 23:05:59]:
-Iter 14000, Training Loss= 1.003940, Accuracy Top1 = 0.7422, Top5 = 0.9141
-Iter 14000, Validation Loss= 2.495217, Accuracy Top1 = 0.4141, Top5 = 0.7031
[2017-11-05 23:07:09]:
-Iter 14050, Training Loss= 1.068258, Accuracy Top1 = 0.6641, Top5 = 0.9375
-Iter 14050, Validation Loss= 2.616717, Accuracy Top1 = 0.3516, Top5 = 0.6797
[2017-11-05 23:08:18]:
-Iter 14100, Training Loss= 1.073799, Accuracy Top1 = 0.6797, Top5 = 0.9375
-Iter 14100, Validation Loss= 2.653134, Accuracy Top1 = 0.3750, Top5 = 0.6797
[2017-11-05 23:09:28]:
-Iter 14150, Training Loss= 1.129569, Accuracy Top1 = 0.6328, Top5 = 0.9062
-Iter 14150, Validation Loss= 2.666548, Accuracy Top1 = 0.3906, Top5 = 0.6562
[2017-11-05 23:10:38]:
-Iter 14200, Training Loss= 0.954867, Accuracy Top1 = 0.7109, Top5 = 0.9453
-Iter 14200, Validation Loss= 2.282054, Accuracy Top1 = 0.4219, Top5 = 0.7266
[2017-11-05 23:11:47]:
-Iter 14250, Training Loss= 1.256933, Accuracy Top1 = 0.6641, Top5 = 0.8750
-Iter 14250, Validation Loss= 2.845966, Accuracy Top1 = 0.3984, Top5 = 0.6719
[2017-11-05 23:13:05]:
-Iter 14300, Training Loss= 0.918741, Accuracy Top1 = 0.7500, Top5 = 0.9375
-Iter 14300, Validation Loss= 2.959656, Accuracy Top1 = 0.3516, Top5 = 0.6406
[2017-11-05 23:14:27]:
-Iter 14350, Training Loss= 0.986440, Accuracy Top1 = 0.6875, Top5 = 0.9609
-Iter 14350, Validation Loss= 3.037485, Accuracy Top1 = 0.3906, Top5 = 0.6406
[2017-11-05 23:15:40]:
-Iter 14400, Training Loss= 1.072095, Accuracy Top1 = 0.6953, Top5 = 0.9297
-Iter 14400, Validation Loss= 2.419886, Accuracy Top1 = 0.4141, Top5 = 0.7344
[2017-11-05 23:16:56]:
-Iter 14450, Training Loss= 1.193873, Accuracy Top1 = 0.6328, Top5 = 0.9297
-Iter 14450, Validation Loss= 2.351933, Accuracy Top1 = 0.3281, Top5 = 0.6953
[2017-11-05 23:18:07]:
-Iter 14500, Training Loss= 0.998517, Accuracy Top1 = 0.7266, Top5 = 0.9453
-Iter 14500, Validation Loss= 2.553429, Accuracy Top1 = 0.4141, Top5 = 0.7109
[2017-11-05 23:19:19]:
-Iter 14550, Training Loss= 1.033672, Accuracy Top1 = 0.6953, Top5 = 0.9297
-Iter 14550, Validation Loss= 1.954873, Accuracy Top1 = 0.5469, Top5 = 0.7734
[2017-11-05 23:20:33]:
-Iter 14600, Training Loss= 1.106044, Accuracy Top1 = 0.6875, Top5 = 0.9219
-Iter 14600, Validation Loss= 2.609347, Accuracy Top1 = 0.4141, Top5 = 0.7344
[2017-11-05 23:21:49]:
-Iter 14650, Training Loss= 0.950670, Accuracy Top1 = 0.7500, Top5 = 0.9297
-Iter 14650, Validation Loss= 2.309010, Accuracy Top1 = 0.4297, Top5 = 0.7031
[2017-11-05 23:23:05]:
-Iter 14700, Training Loss= 1.061487, Accuracy Top1 = 0.6719, Top5 = 0.9375
-Iter 14700, Validation Loss= 2.642496, Accuracy Top1 = 0.3906, Top5 = 0.6719
[2017-11-05 23:24:18]:
-Iter 14750, Training Loss= 0.934343, Accuracy Top1 = 0.7656, Top5 = 0.9531
-Iter 14750, Validation Loss= 2.531524, Accuracy Top1 = 0.3828, Top5 = 0.7422
[2017-11-05 23:25:36]:
-Iter 14800, Training Loss= 0.937926, Accuracy Top1 = 0.7578, Top5 = 0.9141
-Iter 14800, Validation Loss= 2.618137, Accuracy Top1 = 0.3594, Top5 = 0.6953
[2017-11-05 23:26:53]:
-Iter 14850, Training Loss= 0.999613, Accuracy Top1 = 0.7188, Top5 = 0.9531
-Iter 14850, Validation Loss= 2.420105, Accuracy Top1 = 0.4141, Top5 = 0.6875
[2017-11-05 23:28:16]:
-Iter 14900, Training Loss= 0.912771, Accuracy Top1 = 0.7266, Top5 = 0.9375
-Iter 14900, Validation Loss= 2.384310, Accuracy Top1 = 0.4297, Top5 = 0.6953
[2017-11-05 23:29:30]:
-Iter 14950, Training Loss= 0.970793, Accuracy Top1 = 0.7109, Top5 = 0.9375
-Iter 14950, Validation Loss= 2.531287, Accuracy Top1 = 0.4219, Top5 = 0.7422
[2017-11-05 23:30:46]:
-Iter 15000, Training Loss= 1.094681, Accuracy Top1 = 0.6797, Top5 = 0.9297
-Iter 15000, Validation Loss= 2.726111, Accuracy Top1 = 0.3125, Top5 = 0.6719
[2017-11-05 23:32:07]:
-Iter 15050, Training Loss= 0.903489, Accuracy Top1 = 0.7891, Top5 = 0.9297
-Iter 15050, Validation Loss= 2.694874, Accuracy Top1 = 0.3828, Top5 = 0.6875
[2017-11-05 23:33:22]:
-Iter 15100, Training Loss= 1.132467, Accuracy Top1 = 0.7188, Top5 = 0.9375
-Iter 15100, Validation Loss= 2.471829, Accuracy Top1 = 0.4531, Top5 = 0.7109
[2017-11-05 23:34:38]:
-Iter 15150, Training Loss= 1.026103, Accuracy Top1 = 0.6875, Top5 = 0.9453
-Iter 15150, Validation Loss= 2.456425, Accuracy Top1 = 0.4062, Top5 = 0.7344
[2017-11-05 23:35:51]:
-Iter 15200, Training Loss= 1.059436, Accuracy Top1 = 0.7031, Top5 = 0.9375
-Iter 15200, Validation Loss= 2.437264, Accuracy Top1 = 0.4141, Top5 = 0.7266
[2017-11-05 23:37:03]:
-Iter 15250, Training Loss= 1.023086, Accuracy Top1 = 0.7266, Top5 = 0.9375
-Iter 15250, Validation Loss= 2.352103, Accuracy Top1 = 0.4062, Top5 = 0.7266
[2017-11-05 23:38:15]:
-Iter 15300, Training Loss= 0.992709, Accuracy Top1 = 0.7422, Top5 = 0.9297
-Iter 15300, Validation Loss= 2.330599, Accuracy Top1 = 0.4531, Top5 = 0.7500
[2017-11-05 23:39:28]:
-Iter 15350, Training Loss= 0.882762, Accuracy Top1 = 0.7891, Top5 = 0.9453
-Iter 15350, Validation Loss= 2.726922, Accuracy Top1 = 0.3672, Top5 = 0.6719
[2017-11-05 23:40:40]:
-Iter 15400, Training Loss= 0.946217, Accuracy Top1 = 0.7422, Top5 = 0.9375
-Iter 15400, Validation Loss= 3.005236, Accuracy Top1 = 0.4062, Top5 = 0.6094
[2017-11-05 23:41:53]:
-Iter 15450, Training Loss= 1.060613, Accuracy Top1 = 0.7188, Top5 = 0.9219
-Iter 15450, Validation Loss= 2.765366, Accuracy Top1 = 0.3438, Top5 = 0.7188
[2017-11-05 23:43:06]:
-Iter 15500, Training Loss= 1.006989, Accuracy Top1 = 0.6953, Top5 = 0.9219
-Iter 15500, Validation Loss= 2.847993, Accuracy Top1 = 0.3906, Top5 = 0.6797
[2017-11-05 23:44:18]:
-Iter 15550, Training Loss= 0.838161, Accuracy Top1 = 0.7734, Top5 = 0.9766
-Iter 15550, Validation Loss= 2.165923, Accuracy Top1 = 0.5000, Top5 = 0.7578
[2017-11-05 23:45:31]:
-Iter 15600, Training Loss= 1.053405, Accuracy Top1 = 0.7109, Top5 = 0.9141
-Iter 15600, Validation Loss= 2.666879, Accuracy Top1 = 0.4219, Top5 = 0.6484
[2017-11-05 23:46:44]:
-Iter 15650, Training Loss= 1.022618, Accuracy Top1 = 0.7109, Top5 = 0.9141
-Iter 15650, Validation Loss= 2.921967, Accuracy Top1 = 0.3594, Top5 = 0.6641
[2017-11-05 23:47:56]:
-Iter 15700, Training Loss= 0.743824, Accuracy Top1 = 0.8047, Top5 = 0.9453
-Iter 15700, Validation Loss= 2.750413, Accuracy Top1 = 0.4141, Top5 = 0.6484
[2017-11-05 23:49:09]:
-Iter 15750, Training Loss= 1.136170, Accuracy Top1 = 0.6562, Top5 = 0.9062
-Iter 15750, Validation Loss= 2.447311, Accuracy Top1 = 0.4453, Top5 = 0.7812
[2017-11-05 23:50:22]:
-Iter 15800, Training Loss= 1.032432, Accuracy Top1 = 0.6953, Top5 = 0.9453
-Iter 15800, Validation Loss= 2.493305, Accuracy Top1 = 0.4062, Top5 = 0.7188
[2017-11-05 23:51:34]:
-Iter 15850, Training Loss= 1.035019, Accuracy Top1 = 0.6875, Top5 = 0.9453
-Iter 15850, Validation Loss= 2.745868, Accuracy Top1 = 0.3281, Top5 = 0.7031
[2017-11-05 23:52:47]:
-Iter 15900, Training Loss= 0.996527, Accuracy Top1 = 0.7344, Top5 = 0.9375
-Iter 15900, Validation Loss= 2.816870, Accuracy Top1 = 0.3828, Top5 = 0.6719
[2017-11-05 23:53:59]:
-Iter 15950, Training Loss= 0.922014, Accuracy Top1 = 0.7266, Top5 = 0.9531
-Iter 15950, Validation Loss= 2.740222, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-05 23:55:12]:
-Iter 16000, Training Loss= 1.050591, Accuracy Top1 = 0.6641, Top5 = 0.9297
-Iter 16000, Validation Loss= 2.678411, Accuracy Top1 = 0.4219, Top5 = 0.7031
[2017-11-05 23:56:25]:
-Iter 16050, Training Loss= 0.892523, Accuracy Top1 = 0.7188, Top5 = 0.9531
-Iter 16050, Validation Loss= 2.293223, Accuracy Top1 = 0.4141, Top5 = 0.6875
[2017-11-05 23:57:38]:
-Iter 16100, Training Loss= 0.910570, Accuracy Top1 = 0.7344, Top5 = 0.9531
-Iter 16100, Validation Loss= 2.218745, Accuracy Top1 = 0.4531, Top5 = 0.7656
[2017-11-05 23:58:50]:
-Iter 16150, Training Loss= 1.020164, Accuracy Top1 = 0.6953, Top5 = 0.9609
-Iter 16150, Validation Loss= 2.961220, Accuracy Top1 = 0.3594, Top5 = 0.6484
[2017-11-06 00:00:03]:
-Iter 16200, Training Loss= 0.878158, Accuracy Top1 = 0.7578, Top5 = 0.9453
-Iter 16200, Validation Loss= 2.555310, Accuracy Top1 = 0.3281, Top5 = 0.7188
[2017-11-06 00:01:16]:
-Iter 16250, Training Loss= 1.016787, Accuracy Top1 = 0.7109, Top5 = 0.9453
-Iter 16250, Validation Loss= 2.552917, Accuracy Top1 = 0.3359, Top5 = 0.6953
[2017-11-06 00:02:28]:
-Iter 16300, Training Loss= 0.717544, Accuracy Top1 = 0.7891, Top5 = 0.9844
-Iter 16300, Validation Loss= 2.028268, Accuracy Top1 = 0.5078, Top5 = 0.7734
[2017-11-06 00:03:42]:
-Iter 16350, Training Loss= 0.717076, Accuracy Top1 = 0.7969, Top5 = 0.9688
-Iter 16350, Validation Loss= 3.086981, Accuracy Top1 = 0.3047, Top5 = 0.6172
[2017-11-06 00:04:54]:
-Iter 16400, Training Loss= 0.828097, Accuracy Top1 = 0.7734, Top5 = 0.9609
-Iter 16400, Validation Loss= 2.861249, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-06 00:06:07]:
-Iter 16450, Training Loss= 1.128136, Accuracy Top1 = 0.6562, Top5 = 0.9688
-Iter 16450, Validation Loss= 2.412735, Accuracy Top1 = 0.4141, Top5 = 0.7656
[2017-11-06 00:07:19]:
-Iter 16500, Training Loss= 0.948701, Accuracy Top1 = 0.7266, Top5 = 0.9453
-Iter 16500, Validation Loss= 2.643308, Accuracy Top1 = 0.4219, Top5 = 0.6719
[2017-11-06 00:08:32]:
-Iter 16550, Training Loss= 1.013100, Accuracy Top1 = 0.6875, Top5 = 0.9297
-Iter 16550, Validation Loss= 2.547775, Accuracy Top1 = 0.3203, Top5 = 0.7266
[2017-11-06 00:09:45]:
-Iter 16600, Training Loss= 0.693634, Accuracy Top1 = 0.7812, Top5 = 0.9766
-Iter 16600, Validation Loss= 2.450189, Accuracy Top1 = 0.4531, Top5 = 0.7109
[2017-11-06 00:10:57]:
-Iter 16650, Training Loss= 0.847331, Accuracy Top1 = 0.7500, Top5 = 0.9453
-Iter 16650, Validation Loss= 2.506989, Accuracy Top1 = 0.4766, Top5 = 0.7500
[2017-11-06 00:12:10]:
-Iter 16700, Training Loss= 0.719419, Accuracy Top1 = 0.7812, Top5 = 0.9688
-Iter 16700, Validation Loss= 2.738506, Accuracy Top1 = 0.3828, Top5 = 0.7031
[2017-11-06 00:13:23]:
-Iter 16750, Training Loss= 0.707099, Accuracy Top1 = 0.7578, Top5 = 0.9922
-Iter 16750, Validation Loss= 2.407207, Accuracy Top1 = 0.4219, Top5 = 0.7031
[2017-11-06 00:14:35]:
-Iter 16800, Training Loss= 0.789839, Accuracy Top1 = 0.7891, Top5 = 0.9375
-Iter 16800, Validation Loss= 2.592812, Accuracy Top1 = 0.3203, Top5 = 0.7109
[2017-11-06 00:15:48]:
-Iter 16850, Training Loss= 0.604516, Accuracy Top1 = 0.8750, Top5 = 0.9766
-Iter 16850, Validation Loss= 3.009683, Accuracy Top1 = 0.3672, Top5 = 0.6484
[2017-11-06 00:17:00]:
-Iter 16900, Training Loss= 0.825739, Accuracy Top1 = 0.7266, Top5 = 0.9531
-Iter 16900, Validation Loss= 2.715645, Accuracy Top1 = 0.4375, Top5 = 0.7109
[2017-11-06 00:18:13]:
-Iter 16950, Training Loss= 0.636482, Accuracy Top1 = 0.8125, Top5 = 0.9766
-Iter 16950, Validation Loss= 2.689291, Accuracy Top1 = 0.4219, Top5 = 0.6875
[2017-11-06 00:19:26]:
-Iter 17000, Training Loss= 0.717358, Accuracy Top1 = 0.7656, Top5 = 0.9688
-Iter 17000, Validation Loss= 3.102858, Accuracy Top1 = 0.2969, Top5 = 0.5781
[2017-11-06 00:20:39]:
-Iter 17050, Training Loss= 0.791429, Accuracy Top1 = 0.7500, Top5 = 0.9844
-Iter 17050, Validation Loss= 2.714820, Accuracy Top1 = 0.4141, Top5 = 0.7109
[2017-11-06 00:21:51]:
-Iter 17100, Training Loss= 0.705653, Accuracy Top1 = 0.8125, Top5 = 0.9688
-Iter 17100, Validation Loss= 2.562581, Accuracy Top1 = 0.4062, Top5 = 0.7344
[2017-11-06 00:23:04]:
-Iter 17150, Training Loss= 1.034006, Accuracy Top1 = 0.6875, Top5 = 0.9375
-Iter 17150, Validation Loss= 2.551552, Accuracy Top1 = 0.3594, Top5 = 0.7031
[2017-11-06 00:24:17]:
-Iter 17200, Training Loss= 0.924471, Accuracy Top1 = 0.7500, Top5 = 0.9375
-Iter 17200, Validation Loss= 2.468374, Accuracy Top1 = 0.4062, Top5 = 0.7031
[2017-11-06 00:25:29]:
-Iter 17250, Training Loss= 0.589226, Accuracy Top1 = 0.8438, Top5 = 1.0000
-Iter 17250, Validation Loss= 2.549742, Accuracy Top1 = 0.4141, Top5 = 0.7031
[2017-11-06 00:26:42]:
-Iter 17300, Training Loss= 0.774329, Accuracy Top1 = 0.7656, Top5 = 0.9766
-Iter 17300, Validation Loss= 2.570623, Accuracy Top1 = 0.4375, Top5 = 0.7031
[2017-11-06 00:27:55]:
-Iter 17350, Training Loss= 0.773625, Accuracy Top1 = 0.7734, Top5 = 0.9609
-Iter 17350, Validation Loss= 2.416804, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-06 00:29:07]:
-Iter 17400, Training Loss= 0.628931, Accuracy Top1 = 0.8281, Top5 = 0.9766
-Iter 17400, Validation Loss= 2.684685, Accuracy Top1 = 0.4375, Top5 = 0.7578
[2017-11-06 00:30:20]:
-Iter 17450, Training Loss= 0.693184, Accuracy Top1 = 0.8203, Top5 = 0.9531
-Iter 17450, Validation Loss= 3.018171, Accuracy Top1 = 0.3516, Top5 = 0.6406
[2017-11-06 00:31:33]:
-Iter 17500, Training Loss= 0.854019, Accuracy Top1 = 0.7734, Top5 = 0.9531
-Iter 17500, Validation Loss= 2.966638, Accuracy Top1 = 0.4375, Top5 = 0.6719
[2017-11-06 00:32:45]:
-Iter 17550, Training Loss= 0.896416, Accuracy Top1 = 0.7578, Top5 = 0.9297
-Iter 17550, Validation Loss= 2.533202, Accuracy Top1 = 0.4297, Top5 = 0.6797
[2017-11-06 00:33:58]:
-Iter 17600, Training Loss= 0.713642, Accuracy Top1 = 0.7891, Top5 = 1.0000
-Iter 17600, Validation Loss= 2.639642, Accuracy Top1 = 0.4219, Top5 = 0.6719
[2017-11-06 00:35:10]:
-Iter 17650, Training Loss= 0.579785, Accuracy Top1 = 0.8438, Top5 = 0.9766
-Iter 17650, Validation Loss= 2.324403, Accuracy Top1 = 0.4453, Top5 = 0.7188
[2017-11-06 00:36:23]:
-Iter 17700, Training Loss= 0.935072, Accuracy Top1 = 0.7422, Top5 = 0.9375
-Iter 17700, Validation Loss= 2.578096, Accuracy Top1 = 0.3828, Top5 = 0.7344
[2017-11-06 00:37:35]:
-Iter 17750, Training Loss= 0.751668, Accuracy Top1 = 0.7969, Top5 = 0.9844
-Iter 17750, Validation Loss= 2.575237, Accuracy Top1 = 0.4375, Top5 = 0.7422
[2017-11-06 00:38:48]:
-Iter 17800, Training Loss= 0.800390, Accuracy Top1 = 0.7656, Top5 = 0.9453
-Iter 17800, Validation Loss= 2.390152, Accuracy Top1 = 0.4141, Top5 = 0.7422
[2017-11-06 00:40:00]:
-Iter 17850, Training Loss= 0.775775, Accuracy Top1 = 0.7266, Top5 = 0.9609
-Iter 17850, Validation Loss= 2.414326, Accuracy Top1 = 0.4141, Top5 = 0.7578
[2017-11-06 00:41:13]:
-Iter 17900, Training Loss= 0.692203, Accuracy Top1 = 0.8672, Top5 = 0.9844
-Iter 17900, Validation Loss= 2.599430, Accuracy Top1 = 0.4453, Top5 = 0.6953
[2017-11-06 00:42:26]:
-Iter 17950, Training Loss= 0.721718, Accuracy Top1 = 0.7969, Top5 = 0.9609
-Iter 17950, Validation Loss= 2.563348, Accuracy Top1 = 0.4219, Top5 = 0.7031
[2017-11-06 00:43:38]:
-Iter 18000, Training Loss= 0.831313, Accuracy Top1 = 0.7734, Top5 = 0.9453
-Iter 18000, Validation Loss= 3.046048, Accuracy Top1 = 0.3516, Top5 = 0.6328
[2017-11-06 00:44:51]:
-Iter 18050, Training Loss= 0.552950, Accuracy Top1 = 0.8516, Top5 = 0.9844
-Iter 18050, Validation Loss= 2.521442, Accuracy Top1 = 0.4062, Top5 = 0.6953
[2017-11-06 00:46:04]:
-Iter 18100, Training Loss= 0.728430, Accuracy Top1 = 0.8125, Top5 = 0.9531
-Iter 18100, Validation Loss= 2.776445, Accuracy Top1 = 0.4219, Top5 = 0.6641
[2017-11-06 00:47:16]:
-Iter 18150, Training Loss= 0.813115, Accuracy Top1 = 0.7578, Top5 = 0.9453
-Iter 18150, Validation Loss= 2.692588, Accuracy Top1 = 0.4219, Top5 = 0.6953
[2017-11-06 00:48:29]:
-Iter 18200, Training Loss= 0.644693, Accuracy Top1 = 0.8125, Top5 = 0.9844
-Iter 18200, Validation Loss= 3.093591, Accuracy Top1 = 0.3359, Top5 = 0.6719
[2017-11-06 00:49:42]:
-Iter 18250, Training Loss= 0.645808, Accuracy Top1 = 0.8281, Top5 = 0.9531
-Iter 18250, Validation Loss= 2.847485, Accuracy Top1 = 0.3672, Top5 = 0.7266
[2017-11-06 00:50:55]:
-Iter 18300, Training Loss= 0.818214, Accuracy Top1 = 0.7422, Top5 = 0.9609
-Iter 18300, Validation Loss= 2.558626, Accuracy Top1 = 0.4062, Top5 = 0.7031
[2017-11-06 00:52:07]:
-Iter 18350, Training Loss= 0.851561, Accuracy Top1 = 0.7500, Top5 = 0.9609
-Iter 18350, Validation Loss= 2.899046, Accuracy Top1 = 0.3750, Top5 = 0.5938
[2017-11-06 00:53:20]:
-Iter 18400, Training Loss= 0.650984, Accuracy Top1 = 0.8047, Top5 = 0.9766
-Iter 18400, Validation Loss= 2.546518, Accuracy Top1 = 0.4141, Top5 = 0.7578
[2017-11-06 00:54:32]:
-Iter 18450, Training Loss= 0.432303, Accuracy Top1 = 0.8828, Top5 = 1.0000
-Iter 18450, Validation Loss= 2.339681, Accuracy Top1 = 0.4453, Top5 = 0.7656
[2017-11-06 00:55:45]:
-Iter 18500, Training Loss= 0.785750, Accuracy Top1 = 0.7578, Top5 = 0.9766
-Iter 18500, Validation Loss= 2.349544, Accuracy Top1 = 0.4375, Top5 = 0.7734
[2017-11-06 00:56:58]:
-Iter 18550, Training Loss= 0.659580, Accuracy Top1 = 0.7812, Top5 = 0.9766
-Iter 18550, Validation Loss= 2.488207, Accuracy Top1 = 0.4375, Top5 = 0.6797
[2017-11-06 00:58:10]:
-Iter 18600, Training Loss= 0.682259, Accuracy Top1 = 0.8047, Top5 = 0.9688
-Iter 18600, Validation Loss= 2.616816, Accuracy Top1 = 0.3672, Top5 = 0.7109
[2017-11-06 00:59:23]:
-Iter 18650, Training Loss= 0.924136, Accuracy Top1 = 0.7344, Top5 = 0.9531
-Iter 18650, Validation Loss= 3.079439, Accuracy Top1 = 0.3594, Top5 = 0.6562
[2017-11-06 01:00:36]:
-Iter 18700, Training Loss= 0.563567, Accuracy Top1 = 0.8359, Top5 = 0.9766
-Iter 18700, Validation Loss= 2.786318, Accuracy Top1 = 0.3984, Top5 = 0.6953
[2017-11-06 01:01:49]:
-Iter 18750, Training Loss= 0.732564, Accuracy Top1 = 0.8125, Top5 = 0.9766
-Iter 18750, Validation Loss= 2.632446, Accuracy Top1 = 0.3906, Top5 = 0.6719
[2017-11-06 01:03:01]:
-Iter 18800, Training Loss= 0.701835, Accuracy Top1 = 0.8359, Top5 = 0.9688
-Iter 18800, Validation Loss= 2.128133, Accuracy Top1 = 0.4844, Top5 = 0.7422
[2017-11-06 01:04:14]:
-Iter 18850, Training Loss= 0.484161, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 18850, Validation Loss= 2.777310, Accuracy Top1 = 0.3750, Top5 = 0.6641
[2017-11-06 01:05:27]:
-Iter 18900, Training Loss= 0.646028, Accuracy Top1 = 0.8438, Top5 = 0.9844
-Iter 18900, Validation Loss= 2.467479, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-06 01:06:39]:
-Iter 18950, Training Loss= 0.660031, Accuracy Top1 = 0.7500, Top5 = 0.9766
-Iter 18950, Validation Loss= 2.627988, Accuracy Top1 = 0.4375, Top5 = 0.6953
[2017-11-06 01:07:52]:
-Iter 19000, Training Loss= 0.699856, Accuracy Top1 = 0.8125, Top5 = 0.9688
-Iter 19000, Validation Loss= 2.274467, Accuracy Top1 = 0.4453, Top5 = 0.7500
[2017-11-06 01:09:05]:
-Iter 19050, Training Loss= 0.627041, Accuracy Top1 = 0.8281, Top5 = 0.9688
-Iter 19050, Validation Loss= 2.570451, Accuracy Top1 = 0.4453, Top5 = 0.7188
[2017-11-06 01:10:17]:
-Iter 19100, Training Loss= 0.547360, Accuracy Top1 = 0.8828, Top5 = 0.9766
-Iter 19100, Validation Loss= 2.693298, Accuracy Top1 = 0.4062, Top5 = 0.6641
[2017-11-06 01:11:30]:
-Iter 19150, Training Loss= 0.647751, Accuracy Top1 = 0.8047, Top5 = 0.9844
-Iter 19150, Validation Loss= 2.666805, Accuracy Top1 = 0.4297, Top5 = 0.7031
[2017-11-06 01:12:42]:
-Iter 19200, Training Loss= 0.536915, Accuracy Top1 = 0.8594, Top5 = 0.9844
-Iter 19200, Validation Loss= 2.397047, Accuracy Top1 = 0.3984, Top5 = 0.7578
[2017-11-06 01:13:55]:
-Iter 19250, Training Loss= 0.711192, Accuracy Top1 = 0.7578, Top5 = 0.9688
-Iter 19250, Validation Loss= 2.773130, Accuracy Top1 = 0.3594, Top5 = 0.6875
[2017-11-06 01:15:08]:
-Iter 19300, Training Loss= 0.551191, Accuracy Top1 = 0.8047, Top5 = 0.9844
-Iter 19300, Validation Loss= 3.202024, Accuracy Top1 = 0.3906, Top5 = 0.6016
[2017-11-06 01:16:21]:
-Iter 19350, Training Loss= 0.723734, Accuracy Top1 = 0.7891, Top5 = 0.9609
-Iter 19350, Validation Loss= 2.367707, Accuracy Top1 = 0.3828, Top5 = 0.6953
[2017-11-06 01:17:33]:
-Iter 19400, Training Loss= 0.748882, Accuracy Top1 = 0.7734, Top5 = 0.9844
-Iter 19400, Validation Loss= 3.037852, Accuracy Top1 = 0.3203, Top5 = 0.6641
[2017-11-06 01:18:46]:
-Iter 19450, Training Loss= 0.622405, Accuracy Top1 = 0.8047, Top5 = 0.9766
-Iter 19450, Validation Loss= 2.311624, Accuracy Top1 = 0.4688, Top5 = 0.7734
[2017-11-06 01:19:58]:
-Iter 19500, Training Loss= 0.557301, Accuracy Top1 = 0.8359, Top5 = 0.9766
-Iter 19500, Validation Loss= 2.711903, Accuracy Top1 = 0.3672, Top5 = 0.7188
[2017-11-06 01:21:11]:
-Iter 19550, Training Loss= 0.554396, Accuracy Top1 = 0.8672, Top5 = 0.9766
-Iter 19550, Validation Loss= 2.867666, Accuracy Top1 = 0.3672, Top5 = 0.7031
[2017-11-06 01:22:23]:
-Iter 19600, Training Loss= 0.489798, Accuracy Top1 = 0.8750, Top5 = 0.9922
-Iter 19600, Validation Loss= 3.082184, Accuracy Top1 = 0.3359, Top5 = 0.6406
[2017-11-06 01:23:36]:
-Iter 19650, Training Loss= 0.617920, Accuracy Top1 = 0.8125, Top5 = 0.9844
-Iter 19650, Validation Loss= 2.779240, Accuracy Top1 = 0.3828, Top5 = 0.7422
[2017-11-06 01:24:49]:
-Iter 19700, Training Loss= 0.726331, Accuracy Top1 = 0.8047, Top5 = 0.9453
-Iter 19700, Validation Loss= 2.730587, Accuracy Top1 = 0.4531, Top5 = 0.6719
[2017-11-06 01:26:01]:
-Iter 19750, Training Loss= 0.462683, Accuracy Top1 = 0.8750, Top5 = 0.9688
-Iter 19750, Validation Loss= 2.706508, Accuracy Top1 = 0.3906, Top5 = 0.7266
[2017-11-06 01:27:14]:
-Iter 19800, Training Loss= 0.638644, Accuracy Top1 = 0.8281, Top5 = 0.9609
-Iter 19800, Validation Loss= 3.152019, Accuracy Top1 = 0.3594, Top5 = 0.6641
[2017-11-06 01:28:27]:
-Iter 19850, Training Loss= 0.765961, Accuracy Top1 = 0.8125, Top5 = 0.9688
-Iter 19850, Validation Loss= 2.821116, Accuracy Top1 = 0.3672, Top5 = 0.7344
[2017-11-06 01:29:40]:
-Iter 19900, Training Loss= 0.605113, Accuracy Top1 = 0.8594, Top5 = 0.9531
-Iter 19900, Validation Loss= 2.816815, Accuracy Top1 = 0.4141, Top5 = 0.6875
[2017-11-06 01:30:52]:
-Iter 19950, Training Loss= 0.579457, Accuracy Top1 = 0.8359, Top5 = 0.9922
-Iter 19950, Validation Loss= 2.592652, Accuracy Top1 = 0.4219, Top5 = 0.6875
Model saved at Iter 20000 !
[2017-11-06 01:32:05]:
-Iter 20000, Training Loss= 0.878258, Accuracy Top1 = 0.8984, Top5 = 0.9766
-Iter 20000, Validation Loss= 2.282935, Accuracy Top1 = 0.4922, Top5 = 0.7422
[2017-11-06 01:33:19]:
-Iter 20050, Training Loss= 0.441553, Accuracy Top1 = 0.8672, Top5 = 1.0000
-Iter 20050, Validation Loss= 3.243182, Accuracy Top1 = 0.4062, Top5 = 0.6797
[2017-11-06 01:34:32]:
-Iter 20100, Training Loss= 0.548364, Accuracy Top1 = 0.8516, Top5 = 1.0000
-Iter 20100, Validation Loss= 2.813015, Accuracy Top1 = 0.3750, Top5 = 0.7031
[2017-11-06 01:35:44]:
-Iter 20150, Training Loss= 0.530216, Accuracy Top1 = 0.8516, Top5 = 0.9844
-Iter 20150, Validation Loss= 2.862967, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-06 01:36:57]:
-Iter 20200, Training Loss= 0.598669, Accuracy Top1 = 0.8438, Top5 = 0.9766
-Iter 20200, Validation Loss= 2.259266, Accuracy Top1 = 0.5078, Top5 = 0.7578
[2017-11-06 01:38:10]:
-Iter 20250, Training Loss= 0.632526, Accuracy Top1 = 0.8203, Top5 = 0.9531
-Iter 20250, Validation Loss= 3.338897, Accuracy Top1 = 0.2891, Top5 = 0.6328
[2017-11-06 01:39:22]:
-Iter 20300, Training Loss= 0.580733, Accuracy Top1 = 0.8203, Top5 = 0.9766
-Iter 20300, Validation Loss= 2.840322, Accuracy Top1 = 0.4453, Top5 = 0.6797
[2017-11-06 01:40:35]:
-Iter 20350, Training Loss= 0.514690, Accuracy Top1 = 0.8672, Top5 = 0.9844
-Iter 20350, Validation Loss= 2.726033, Accuracy Top1 = 0.4297, Top5 = 0.6875
[2017-11-06 01:41:48]:
-Iter 20400, Training Loss= 0.481323, Accuracy Top1 = 0.8359, Top5 = 1.0000
-Iter 20400, Validation Loss= 2.523512, Accuracy Top1 = 0.4609, Top5 = 0.7266
[2017-11-06 01:43:00]:
-Iter 20450, Training Loss= 0.611906, Accuracy Top1 = 0.8281, Top5 = 0.9531
-Iter 20450, Validation Loss= 2.855948, Accuracy Top1 = 0.4297, Top5 = 0.7031
[2017-11-06 01:44:13]:
-Iter 20500, Training Loss= 0.701810, Accuracy Top1 = 0.7656, Top5 = 0.9453
-Iter 20500, Validation Loss= 2.534230, Accuracy Top1 = 0.4609, Top5 = 0.6953
[2017-11-06 01:45:26]:
-Iter 20550, Training Loss= 0.419780, Accuracy Top1 = 0.9062, Top5 = 0.9766
-Iter 20550, Validation Loss= 2.471533, Accuracy Top1 = 0.4375, Top5 = 0.7656
[2017-11-06 01:46:39]:
-Iter 20600, Training Loss= 0.557248, Accuracy Top1 = 0.8203, Top5 = 0.9688
-Iter 20600, Validation Loss= 2.893724, Accuracy Top1 = 0.3828, Top5 = 0.7188
[2017-11-06 01:47:51]:
-Iter 20650, Training Loss= 0.700526, Accuracy Top1 = 0.7578, Top5 = 0.9922
-Iter 20650, Validation Loss= 2.725122, Accuracy Top1 = 0.4062, Top5 = 0.6875
[2017-11-06 01:49:04]:
-Iter 20700, Training Loss= 0.572382, Accuracy Top1 = 0.8281, Top5 = 0.9922
-Iter 20700, Validation Loss= 2.661606, Accuracy Top1 = 0.4062, Top5 = 0.7422
[2017-11-06 01:50:16]:
-Iter 20750, Training Loss= 0.466931, Accuracy Top1 = 0.8984, Top5 = 0.9766
-Iter 20750, Validation Loss= 3.189745, Accuracy Top1 = 0.3281, Top5 = 0.6328
[2017-11-06 01:51:29]:
-Iter 20800, Training Loss= 0.548529, Accuracy Top1 = 0.8672, Top5 = 0.9766
-Iter 20800, Validation Loss= 2.755312, Accuracy Top1 = 0.3672, Top5 = 0.7422
[2017-11-06 01:52:42]:
-Iter 20850, Training Loss= 0.447019, Accuracy Top1 = 0.8750, Top5 = 0.9844
-Iter 20850, Validation Loss= 2.952247, Accuracy Top1 = 0.3750, Top5 = 0.7031
[2017-11-06 01:53:54]:
-Iter 20900, Training Loss= 0.412738, Accuracy Top1 = 0.9062, Top5 = 0.9844
-Iter 20900, Validation Loss= 3.259847, Accuracy Top1 = 0.2969, Top5 = 0.6094
[2017-11-06 01:55:07]:
-Iter 20950, Training Loss= 0.598793, Accuracy Top1 = 0.8359, Top5 = 0.9766
-Iter 20950, Validation Loss= 2.559685, Accuracy Top1 = 0.4531, Top5 = 0.6797
[2017-11-06 01:56:20]:
-Iter 21000, Training Loss= 0.499385, Accuracy Top1 = 0.8750, Top5 = 0.9844
-Iter 21000, Validation Loss= 2.993349, Accuracy Top1 = 0.4297, Top5 = 0.6641
[2017-11-06 01:57:33]:
-Iter 21050, Training Loss= 0.419162, Accuracy Top1 = 0.8828, Top5 = 0.9922
-Iter 21050, Validation Loss= 2.349818, Accuracy Top1 = 0.4375, Top5 = 0.7578
[2017-11-06 01:58:45]:
-Iter 21100, Training Loss= 0.602369, Accuracy Top1 = 0.8516, Top5 = 0.9688
-Iter 21100, Validation Loss= 2.665580, Accuracy Top1 = 0.3594, Top5 = 0.7188
[2017-11-06 01:59:58]:
-Iter 21150, Training Loss= 0.453807, Accuracy Top1 = 0.8750, Top5 = 0.9922
-Iter 21150, Validation Loss= 2.935637, Accuracy Top1 = 0.4062, Top5 = 0.6719
[2017-11-06 02:01:11]:
-Iter 21200, Training Loss= 0.507915, Accuracy Top1 = 0.8594, Top5 = 0.9844
-Iter 21200, Validation Loss= 2.706389, Accuracy Top1 = 0.4766, Top5 = 0.7500
[2017-11-06 02:02:24]:
-Iter 21250, Training Loss= 0.534719, Accuracy Top1 = 0.8906, Top5 = 0.9766
-Iter 21250, Validation Loss= 2.655369, Accuracy Top1 = 0.4062, Top5 = 0.7109
[2017-11-06 02:03:37]:
-Iter 21300, Training Loss= 0.355071, Accuracy Top1 = 0.9062, Top5 = 0.9844
-Iter 21300, Validation Loss= 3.119270, Accuracy Top1 = 0.4219, Top5 = 0.7344
[2017-11-06 02:04:50]:
-Iter 21350, Training Loss= 0.545446, Accuracy Top1 = 0.8203, Top5 = 0.9766
-Iter 21350, Validation Loss= 3.207305, Accuracy Top1 = 0.3594, Top5 = 0.6172
[2017-11-06 02:06:03]:
-Iter 21400, Training Loss= 0.647595, Accuracy Top1 = 0.8516, Top5 = 0.9688
-Iter 21400, Validation Loss= 3.148189, Accuracy Top1 = 0.3516, Top5 = 0.6719
[2017-11-06 02:07:16]:
-Iter 21450, Training Loss= 0.624291, Accuracy Top1 = 0.8281, Top5 = 0.9766
-Iter 21450, Validation Loss= 2.687377, Accuracy Top1 = 0.4453, Top5 = 0.6719
[2017-11-06 02:08:29]:
-Iter 21500, Training Loss= 0.520009, Accuracy Top1 = 0.8750, Top5 = 0.9766
-Iter 21500, Validation Loss= 2.727214, Accuracy Top1 = 0.3906, Top5 = 0.7266
[2017-11-06 02:09:41]:
-Iter 21550, Training Loss= 0.603568, Accuracy Top1 = 0.8047, Top5 = 0.9844
-Iter 21550, Validation Loss= 2.509373, Accuracy Top1 = 0.3984, Top5 = 0.7500
[2017-11-06 02:10:53]:
-Iter 21600, Training Loss= 0.503315, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 21600, Validation Loss= 2.305104, Accuracy Top1 = 0.4453, Top5 = 0.7344
[2017-11-06 02:12:06]:
-Iter 21650, Training Loss= 0.987610, Accuracy Top1 = 0.8516, Top5 = 0.9688
-Iter 21650, Validation Loss= 2.456641, Accuracy Top1 = 0.3984, Top5 = 0.7266
[2017-11-06 02:13:19]:
-Iter 21700, Training Loss= 0.538667, Accuracy Top1 = 0.8828, Top5 = 0.9688
-Iter 21700, Validation Loss= 2.630087, Accuracy Top1 = 0.4297, Top5 = 0.7422
[2017-11-06 02:14:31]:
-Iter 21750, Training Loss= 0.527188, Accuracy Top1 = 0.8516, Top5 = 0.9609
-Iter 21750, Validation Loss= 2.589848, Accuracy Top1 = 0.4688, Top5 = 0.7188
[2017-11-06 02:15:44]:
-Iter 21800, Training Loss= 0.351106, Accuracy Top1 = 0.9453, Top5 = 0.9922
-Iter 21800, Validation Loss= 2.840323, Accuracy Top1 = 0.4297, Top5 = 0.7266
[2017-11-06 02:16:56]:
-Iter 21850, Training Loss= 0.385334, Accuracy Top1 = 0.8984, Top5 = 1.0000
-Iter 21850, Validation Loss= 2.784272, Accuracy Top1 = 0.4062, Top5 = 0.7188
[2017-11-06 02:18:09]:
-Iter 21900, Training Loss= 0.433983, Accuracy Top1 = 0.8672, Top5 = 0.9844
-Iter 21900, Validation Loss= 3.023007, Accuracy Top1 = 0.3438, Top5 = 0.6797
[2017-11-06 02:19:22]:
-Iter 21950, Training Loss= 0.428709, Accuracy Top1 = 0.8516, Top5 = 0.9844
-Iter 21950, Validation Loss= 2.485550, Accuracy Top1 = 0.4453, Top5 = 0.7344
[2017-11-06 02:20:35]:
-Iter 22000, Training Loss= 0.741993, Accuracy Top1 = 0.7656, Top5 = 0.9766
-Iter 22000, Validation Loss= 3.051884, Accuracy Top1 = 0.3984, Top5 = 0.6484
[2017-11-06 02:21:48]:
-Iter 22050, Training Loss= 0.604998, Accuracy Top1 = 0.8281, Top5 = 0.9688
-Iter 22050, Validation Loss= 2.641790, Accuracy Top1 = 0.4375, Top5 = 0.6797
[2017-11-06 02:23:00]:
-Iter 22100, Training Loss= 0.415605, Accuracy Top1 = 0.8828, Top5 = 0.9766
-Iter 22100, Validation Loss= 3.045584, Accuracy Top1 = 0.3906, Top5 = 0.7188
[2017-11-06 02:24:13]:
-Iter 22150, Training Loss= 0.492227, Accuracy Top1 = 0.8516, Top5 = 0.9922
-Iter 22150, Validation Loss= 3.188738, Accuracy Top1 = 0.3203, Top5 = 0.6094
[2017-11-06 02:25:26]:
-Iter 22200, Training Loss= 0.653466, Accuracy Top1 = 0.8359, Top5 = 0.9609
-Iter 22200, Validation Loss= 2.803832, Accuracy Top1 = 0.3672, Top5 = 0.7031
[2017-11-06 02:26:39]:
-Iter 22250, Training Loss= 0.457719, Accuracy Top1 = 0.8438, Top5 = 1.0000
-Iter 22250, Validation Loss= 3.085487, Accuracy Top1 = 0.3359, Top5 = 0.6484
[2017-11-06 02:27:51]:
-Iter 22300, Training Loss= 0.559496, Accuracy Top1 = 0.8438, Top5 = 0.9609
-Iter 22300, Validation Loss= 2.695470, Accuracy Top1 = 0.4219, Top5 = 0.7656
[2017-11-06 02:29:04]:
-Iter 22350, Training Loss= 0.474883, Accuracy Top1 = 0.8594, Top5 = 0.9844
-Iter 22350, Validation Loss= 2.446422, Accuracy Top1 = 0.4609, Top5 = 0.6953
[2017-11-06 02:30:17]:
-Iter 22400, Training Loss= 0.374407, Accuracy Top1 = 0.8906, Top5 = 0.9844
-Iter 22400, Validation Loss= 2.635225, Accuracy Top1 = 0.4062, Top5 = 0.7188
[2017-11-06 02:31:29]:
-Iter 22450, Training Loss= 0.515596, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 22450, Validation Loss= 2.582864, Accuracy Top1 = 0.4219, Top5 = 0.7188
[2017-11-06 02:32:42]:
-Iter 22500, Training Loss= 0.540235, Accuracy Top1 = 0.8359, Top5 = 0.9844
-Iter 22500, Validation Loss= 2.485403, Accuracy Top1 = 0.4297, Top5 = 0.7188
[2017-11-06 02:33:55]:
-Iter 22550, Training Loss= 0.434163, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 22550, Validation Loss= 3.104335, Accuracy Top1 = 0.3359, Top5 = 0.6406
[2017-11-06 02:35:08]:
-Iter 22600, Training Loss= 0.471595, Accuracy Top1 = 0.8750, Top5 = 0.9844
-Iter 22600, Validation Loss= 2.955436, Accuracy Top1 = 0.3672, Top5 = 0.6875
[2017-11-06 02:36:20]:
-Iter 22650, Training Loss= 0.492618, Accuracy Top1 = 0.8672, Top5 = 0.9844
-Iter 22650, Validation Loss= 2.661302, Accuracy Top1 = 0.3828, Top5 = 0.6719
[2017-11-06 02:37:33]:
-Iter 22700, Training Loss= 0.320474, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 22700, Validation Loss= 2.468467, Accuracy Top1 = 0.5156, Top5 = 0.7188
[2017-11-06 02:38:45]:
-Iter 22750, Training Loss= 0.466591, Accuracy Top1 = 0.8828, Top5 = 0.9844
-Iter 22750, Validation Loss= 2.897204, Accuracy Top1 = 0.3672, Top5 = 0.6719
[2017-11-06 02:39:59]:
-Iter 22800, Training Loss= 0.658109, Accuracy Top1 = 0.8203, Top5 = 0.9688
-Iter 22800, Validation Loss= 2.715250, Accuracy Top1 = 0.3438, Top5 = 0.7109
[2017-11-06 02:41:12]:
-Iter 22850, Training Loss= 0.492603, Accuracy Top1 = 0.8672, Top5 = 0.9766
-Iter 22850, Validation Loss= 2.793052, Accuracy Top1 = 0.4453, Top5 = 0.7109
[2017-11-06 02:42:24]:
-Iter 22900, Training Loss= 0.372214, Accuracy Top1 = 0.8906, Top5 = 0.9844
-Iter 22900, Validation Loss= 2.616848, Accuracy Top1 = 0.4609, Top5 = 0.7188
[2017-11-06 02:43:37]:
-Iter 22950, Training Loss= 0.566565, Accuracy Top1 = 0.8516, Top5 = 0.9766
-Iter 22950, Validation Loss= 2.975623, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-06 02:44:50]:
-Iter 23000, Training Loss= 0.555317, Accuracy Top1 = 0.8359, Top5 = 0.9766
-Iter 23000, Validation Loss= 3.047169, Accuracy Top1 = 0.3906, Top5 = 0.6719
[2017-11-06 02:46:03]:
-Iter 23050, Training Loss= 0.458172, Accuracy Top1 = 0.8750, Top5 = 0.9766
-Iter 23050, Validation Loss= 2.764754, Accuracy Top1 = 0.4141, Top5 = 0.7578
[2017-11-06 02:47:15]:
-Iter 23100, Training Loss= 0.469925, Accuracy Top1 = 0.8516, Top5 = 0.9844
-Iter 23100, Validation Loss= 2.555949, Accuracy Top1 = 0.4219, Top5 = 0.7266
[2017-11-06 02:48:27]:
-Iter 23150, Training Loss= 0.340987, Accuracy Top1 = 0.9219, Top5 = 0.9844
-Iter 23150, Validation Loss= 2.954030, Accuracy Top1 = 0.3750, Top5 = 0.7031
[2017-11-06 02:49:40]:
-Iter 23200, Training Loss= 0.271898, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 23200, Validation Loss= 3.276513, Accuracy Top1 = 0.4062, Top5 = 0.6250
[2017-11-06 02:50:53]:
-Iter 23250, Training Loss= 0.412106, Accuracy Top1 = 0.8984, Top5 = 0.9844
-Iter 23250, Validation Loss= 2.922465, Accuracy Top1 = 0.4375, Top5 = 0.7109
[2017-11-06 02:52:06]:
-Iter 23300, Training Loss= 0.383160, Accuracy Top1 = 0.9062, Top5 = 1.0000
-Iter 23300, Validation Loss= 3.026469, Accuracy Top1 = 0.3828, Top5 = 0.6719
[2017-11-06 02:53:19]:
-Iter 23350, Training Loss= 0.406754, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 23350, Validation Loss= 2.657628, Accuracy Top1 = 0.5000, Top5 = 0.7578
[2017-11-06 02:54:31]:
-Iter 23400, Training Loss= 0.477985, Accuracy Top1 = 0.8750, Top5 = 0.9609
-Iter 23400, Validation Loss= 2.781107, Accuracy Top1 = 0.3750, Top5 = 0.6875
[2017-11-06 02:55:44]:
-Iter 23450, Training Loss= 0.585079, Accuracy Top1 = 0.8750, Top5 = 0.9844
-Iter 23450, Validation Loss= 2.446415, Accuracy Top1 = 0.4297, Top5 = 0.7109
[2017-11-06 02:56:57]:
-Iter 23500, Training Loss= 0.346890, Accuracy Top1 = 0.9219, Top5 = 0.9844
-Iter 23500, Validation Loss= 3.080106, Accuracy Top1 = 0.3594, Top5 = 0.6016
[2017-11-06 02:58:10]:
-Iter 23550, Training Loss= 0.435079, Accuracy Top1 = 0.8516, Top5 = 0.9922
-Iter 23550, Validation Loss= 3.063363, Accuracy Top1 = 0.4062, Top5 = 0.7266
[2017-11-06 02:59:22]:
-Iter 23600, Training Loss= 0.313965, Accuracy Top1 = 0.8906, Top5 = 1.0000
-Iter 23600, Validation Loss= 2.812279, Accuracy Top1 = 0.3828, Top5 = 0.7031
[2017-11-06 03:00:35]:
-Iter 23650, Training Loss= 0.278780, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 23650, Validation Loss= 2.984116, Accuracy Top1 = 0.3828, Top5 = 0.6641
[2017-11-06 03:01:48]:
-Iter 23700, Training Loss= 0.379449, Accuracy Top1 = 0.9062, Top5 = 1.0000
-Iter 23700, Validation Loss= 2.558538, Accuracy Top1 = 0.3984, Top5 = 0.7266
[2017-11-06 03:03:00]:
-Iter 23750, Training Loss= 0.396282, Accuracy Top1 = 0.8828, Top5 = 0.9844
-Iter 23750, Validation Loss= 2.809783, Accuracy Top1 = 0.3984, Top5 = 0.6719
[2017-11-06 03:04:13]:
-Iter 23800, Training Loss= 0.471277, Accuracy Top1 = 0.8828, Top5 = 0.9766
-Iter 23800, Validation Loss= 2.888560, Accuracy Top1 = 0.4219, Top5 = 0.7266
[2017-11-06 03:05:26]:
-Iter 23850, Training Loss= 0.355632, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 23850, Validation Loss= 2.984357, Accuracy Top1 = 0.4219, Top5 = 0.6484
[2017-11-06 03:06:38]:
-Iter 23900, Training Loss= 0.316187, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 23900, Validation Loss= 2.508124, Accuracy Top1 = 0.4141, Top5 = 0.7500
[2017-11-06 03:07:51]:
-Iter 23950, Training Loss= 0.354182, Accuracy Top1 = 0.9141, Top5 = 0.9844
-Iter 23950, Validation Loss= 3.053719, Accuracy Top1 = 0.3984, Top5 = 0.6875
[2017-11-06 03:09:04]:
-Iter 24000, Training Loss= 0.359182, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 24000, Validation Loss= 2.840110, Accuracy Top1 = 0.3828, Top5 = 0.7656
[2017-11-06 03:10:17]:
-Iter 24050, Training Loss= 0.358191, Accuracy Top1 = 0.8984, Top5 = 1.0000
-Iter 24050, Validation Loss= 2.846255, Accuracy Top1 = 0.3359, Top5 = 0.6953
[2017-11-06 03:11:30]:
-Iter 24100, Training Loss= 0.369780, Accuracy Top1 = 0.8906, Top5 = 0.9844
-Iter 24100, Validation Loss= 2.750827, Accuracy Top1 = 0.4453, Top5 = 0.7344
[2017-11-06 03:12:42]:
-Iter 24150, Training Loss= 0.411556, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 24150, Validation Loss= 3.302486, Accuracy Top1 = 0.3828, Top5 = 0.6484
[2017-11-06 03:13:54]:
-Iter 24200, Training Loss= 0.468949, Accuracy Top1 = 0.8828, Top5 = 0.9688
-Iter 24200, Validation Loss= 3.107167, Accuracy Top1 = 0.4062, Top5 = 0.6484
[2017-11-06 03:15:07]:
-Iter 24250, Training Loss= 0.518161, Accuracy Top1 = 0.8516, Top5 = 0.9844
-Iter 24250, Validation Loss= 2.941720, Accuracy Top1 = 0.3281, Top5 = 0.7188
[2017-11-06 03:16:20]:
-Iter 24300, Training Loss= 0.236694, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 24300, Validation Loss= 2.487352, Accuracy Top1 = 0.4844, Top5 = 0.7656
[2017-11-06 03:17:33]:
-Iter 24350, Training Loss= 0.481421, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 24350, Validation Loss= 3.047634, Accuracy Top1 = 0.3984, Top5 = 0.6641
[2017-11-06 03:18:46]:
-Iter 24400, Training Loss= 0.486636, Accuracy Top1 = 0.8516, Top5 = 1.0000
-Iter 24400, Validation Loss= 2.738987, Accuracy Top1 = 0.3438, Top5 = 0.6875
[2017-11-06 03:19:58]:
-Iter 24450, Training Loss= 0.313083, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 24450, Validation Loss= 2.226016, Accuracy Top1 = 0.4922, Top5 = 0.8125
[2017-11-06 03:21:11]:
-Iter 24500, Training Loss= 0.308341, Accuracy Top1 = 0.9219, Top5 = 0.9922
-Iter 24500, Validation Loss= 2.888103, Accuracy Top1 = 0.4297, Top5 = 0.7578
[2017-11-06 03:22:24]:
-Iter 24550, Training Loss= 0.387131, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 24550, Validation Loss= 2.837891, Accuracy Top1 = 0.4375, Top5 = 0.6953
[2017-11-06 03:23:36]:
-Iter 24600, Training Loss= 0.318184, Accuracy Top1 = 0.9297, Top5 = 0.9844
-Iter 24600, Validation Loss= 2.537058, Accuracy Top1 = 0.4375, Top5 = 0.7656
[2017-11-06 03:24:49]:
-Iter 24650, Training Loss= 0.378554, Accuracy Top1 = 0.8906, Top5 = 0.9922
-Iter 24650, Validation Loss= 3.428342, Accuracy Top1 = 0.3281, Top5 = 0.6641
[2017-11-06 03:26:01]:
-Iter 24700, Training Loss= 0.249675, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 24700, Validation Loss= 2.745392, Accuracy Top1 = 0.3750, Top5 = 0.7188
[2017-11-06 03:27:14]:
-Iter 24750, Training Loss= 0.361283, Accuracy Top1 = 0.8906, Top5 = 1.0000
-Iter 24750, Validation Loss= 3.220381, Accuracy Top1 = 0.3594, Top5 = 0.7109
[2017-11-06 03:28:27]:
-Iter 24800, Training Loss= 0.344638, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 24800, Validation Loss= 3.240014, Accuracy Top1 = 0.2812, Top5 = 0.6406
[2017-11-06 03:29:40]:
-Iter 24850, Training Loss= 0.338299, Accuracy Top1 = 0.8984, Top5 = 1.0000
-Iter 24850, Validation Loss= 3.058992, Accuracy Top1 = 0.3984, Top5 = 0.6797
[2017-11-06 03:30:52]:
-Iter 24900, Training Loss= 0.433015, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 24900, Validation Loss= 2.964673, Accuracy Top1 = 0.4141, Top5 = 0.6406
[2017-11-06 03:32:05]:
-Iter 24950, Training Loss= 0.407956, Accuracy Top1 = 0.8828, Top5 = 0.9766
-Iter 24950, Validation Loss= 2.263635, Accuracy Top1 = 0.4609, Top5 = 0.7891
[2017-11-06 03:33:18]:
-Iter 25000, Training Loss= 0.380444, Accuracy Top1 = 0.8984, Top5 = 0.9844
-Iter 25000, Validation Loss= 3.047262, Accuracy Top1 = 0.3906, Top5 = 0.6406
[2017-11-06 03:34:31]:
-Iter 25050, Training Loss= 0.339829, Accuracy Top1 = 0.8594, Top5 = 0.9844
-Iter 25050, Validation Loss= 3.086889, Accuracy Top1 = 0.4141, Top5 = 0.7188
[2017-11-06 03:35:43]:
-Iter 25100, Training Loss= 0.314489, Accuracy Top1 = 0.9062, Top5 = 1.0000
-Iter 25100, Validation Loss= 2.587028, Accuracy Top1 = 0.4609, Top5 = 0.7422
[2017-11-06 03:36:56]:
-Iter 25150, Training Loss= 0.484928, Accuracy Top1 = 0.8828, Top5 = 0.9844
-Iter 25150, Validation Loss= 2.542366, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-06 03:38:09]:
-Iter 25200, Training Loss= 0.456107, Accuracy Top1 = 0.8828, Top5 = 0.9922
-Iter 25200, Validation Loss= 3.542175, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-06 03:39:22]:
-Iter 25250, Training Loss= 0.286777, Accuracy Top1 = 0.9453, Top5 = 0.9922
-Iter 25250, Validation Loss= 2.930403, Accuracy Top1 = 0.3594, Top5 = 0.6875
[2017-11-06 03:40:35]:
-Iter 25300, Training Loss= 0.390302, Accuracy Top1 = 0.8828, Top5 = 0.9922
-Iter 25300, Validation Loss= 3.630845, Accuracy Top1 = 0.4062, Top5 = 0.6328
[2017-11-06 03:41:48]:
-Iter 25350, Training Loss= 0.416550, Accuracy Top1 = 0.8516, Top5 = 0.9922
-Iter 25350, Validation Loss= 2.715924, Accuracy Top1 = 0.4375, Top5 = 0.7266
[2017-11-06 03:43:00]:
-Iter 25400, Training Loss= 0.351306, Accuracy Top1 = 0.9141, Top5 = 0.9766
-Iter 25400, Validation Loss= 2.530650, Accuracy Top1 = 0.3984, Top5 = 0.7422
[2017-11-06 03:44:13]:
-Iter 25450, Training Loss= 0.228441, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 25450, Validation Loss= 2.572329, Accuracy Top1 = 0.4297, Top5 = 0.7578
[2017-11-06 03:45:25]:
-Iter 25500, Training Loss= 0.292656, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 25500, Validation Loss= 2.779896, Accuracy Top1 = 0.4219, Top5 = 0.7266
[2017-11-06 03:46:38]:
-Iter 25550, Training Loss= 0.325410, Accuracy Top1 = 0.9375, Top5 = 0.9844
-Iter 25550, Validation Loss= 2.391143, Accuracy Top1 = 0.4375, Top5 = 0.7734
[2017-11-06 03:47:51]:
-Iter 25600, Training Loss= 0.392707, Accuracy Top1 = 0.8594, Top5 = 1.0000
-Iter 25600, Validation Loss= 2.872272, Accuracy Top1 = 0.3984, Top5 = 0.7031
[2017-11-06 03:49:04]:
-Iter 25650, Training Loss= 0.394638, Accuracy Top1 = 0.9062, Top5 = 0.9922
-Iter 25650, Validation Loss= 2.744200, Accuracy Top1 = 0.4141, Top5 = 0.7188
[2017-11-06 03:50:17]:
-Iter 25700, Training Loss= 0.204889, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 25700, Validation Loss= 3.090063, Accuracy Top1 = 0.3828, Top5 = 0.7109
[2017-11-06 03:51:30]:
-Iter 25750, Training Loss= 0.248424, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 25750, Validation Loss= 2.768587, Accuracy Top1 = 0.3828, Top5 = 0.6797
[2017-11-06 03:52:42]:
-Iter 25800, Training Loss= 0.415127, Accuracy Top1 = 0.8984, Top5 = 0.9844
-Iter 25800, Validation Loss= 3.106434, Accuracy Top1 = 0.3906, Top5 = 0.6797
[2017-11-06 03:53:55]:
-Iter 25850, Training Loss= 0.290431, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 25850, Validation Loss= 2.679406, Accuracy Top1 = 0.3906, Top5 = 0.7266
[2017-11-06 03:55:08]:
-Iter 25900, Training Loss= 0.390746, Accuracy Top1 = 0.8984, Top5 = 0.9766
-Iter 25900, Validation Loss= 2.889066, Accuracy Top1 = 0.4141, Top5 = 0.7109
[2017-11-06 03:56:21]:
-Iter 25950, Training Loss= 0.314364, Accuracy Top1 = 0.9219, Top5 = 1.0000
-Iter 25950, Validation Loss= 2.998854, Accuracy Top1 = 0.3672, Top5 = 0.6797
[2017-11-06 03:57:33]:
-Iter 26000, Training Loss= 0.226575, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 26000, Validation Loss= 2.806441, Accuracy Top1 = 0.4531, Top5 = 0.7422
[2017-11-06 03:58:46]:
-Iter 26050, Training Loss= 0.387000, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 26050, Validation Loss= 3.362831, Accuracy Top1 = 0.3438, Top5 = 0.6016
[2017-11-06 03:59:59]:
-Iter 26100, Training Loss= 0.499831, Accuracy Top1 = 0.8984, Top5 = 0.9766
-Iter 26100, Validation Loss= 3.079880, Accuracy Top1 = 0.3672, Top5 = 0.7109
[2017-11-06 04:01:12]:
-Iter 26150, Training Loss= 0.343607, Accuracy Top1 = 0.8906, Top5 = 1.0000
-Iter 26150, Validation Loss= 2.763970, Accuracy Top1 = 0.3750, Top5 = 0.7109
[2017-11-06 04:02:24]:
-Iter 26200, Training Loss= 0.245070, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 26200, Validation Loss= 2.973096, Accuracy Top1 = 0.3984, Top5 = 0.6797
[2017-11-06 04:03:37]:
-Iter 26250, Training Loss= 0.541899, Accuracy Top1 = 0.9062, Top5 = 0.9922
-Iter 26250, Validation Loss= 2.634988, Accuracy Top1 = 0.4375, Top5 = 0.7812
[2017-11-06 04:04:50]:
-Iter 26300, Training Loss= 0.243857, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 26300, Validation Loss= 2.734895, Accuracy Top1 = 0.4062, Top5 = 0.7734
[2017-11-06 04:06:02]:
-Iter 26350, Training Loss= 0.224476, Accuracy Top1 = 0.9219, Top5 = 1.0000
-Iter 26350, Validation Loss= 2.429453, Accuracy Top1 = 0.5000, Top5 = 0.7891
[2017-11-06 04:07:15]:
-Iter 26400, Training Loss= 0.320237, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 26400, Validation Loss= 3.234020, Accuracy Top1 = 0.3828, Top5 = 0.6641
[2017-11-06 04:08:28]:
-Iter 26450, Training Loss= 0.294811, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 26450, Validation Loss= 3.102080, Accuracy Top1 = 0.3828, Top5 = 0.6953
[2017-11-06 04:09:41]:
-Iter 26500, Training Loss= 0.251329, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 26500, Validation Loss= 3.203984, Accuracy Top1 = 0.3750, Top5 = 0.6953
[2017-11-06 04:10:53]:
-Iter 26550, Training Loss= 0.268893, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 26550, Validation Loss= 2.905982, Accuracy Top1 = 0.3750, Top5 = 0.6328
[2017-11-06 04:12:06]:
-Iter 26600, Training Loss= 0.290277, Accuracy Top1 = 0.8906, Top5 = 1.0000
-Iter 26600, Validation Loss= 2.592160, Accuracy Top1 = 0.5156, Top5 = 0.7422
[2017-11-06 04:13:19]:
-Iter 26650, Training Loss= 0.182749, Accuracy Top1 = 0.9609, Top5 = 1.0000
-Iter 26650, Validation Loss= 3.207807, Accuracy Top1 = 0.3906, Top5 = 0.6953
[2017-11-06 04:14:32]:
-Iter 26700, Training Loss= 0.393127, Accuracy Top1 = 0.8672, Top5 = 1.0000
-Iter 26700, Validation Loss= 2.427958, Accuracy Top1 = 0.4141, Top5 = 0.7891
[2017-11-06 04:15:45]:
-Iter 26750, Training Loss= 0.347633, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 26750, Validation Loss= 3.020842, Accuracy Top1 = 0.4297, Top5 = 0.6406
[2017-11-06 04:16:58]:
-Iter 26800, Training Loss= 0.253554, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 26800, Validation Loss= 3.055218, Accuracy Top1 = 0.4766, Top5 = 0.6641
[2017-11-06 04:18:11]:
-Iter 26850, Training Loss= 0.395151, Accuracy Top1 = 0.8750, Top5 = 0.9922
-Iter 26850, Validation Loss= 2.717500, Accuracy Top1 = 0.4219, Top5 = 0.7500
[2017-11-06 04:19:24]:
-Iter 26900, Training Loss= 0.303455, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 26900, Validation Loss= 2.742224, Accuracy Top1 = 0.4375, Top5 = 0.7109
[2017-11-06 04:20:36]:
-Iter 26950, Training Loss= 0.301798, Accuracy Top1 = 0.8984, Top5 = 1.0000
-Iter 26950, Validation Loss= 2.788865, Accuracy Top1 = 0.4297, Top5 = 0.7188
[2017-11-06 04:21:49]:
-Iter 27000, Training Loss= 0.350871, Accuracy Top1 = 0.8984, Top5 = 0.9844
-Iter 27000, Validation Loss= 2.875680, Accuracy Top1 = 0.4141, Top5 = 0.7422
[2017-11-06 04:23:02]:
-Iter 27050, Training Loss= 0.198743, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 27050, Validation Loss= 3.294514, Accuracy Top1 = 0.3750, Top5 = 0.6719
[2017-11-06 04:24:15]:
-Iter 27100, Training Loss= 0.321034, Accuracy Top1 = 0.9297, Top5 = 0.9922
-Iter 27100, Validation Loss= 3.375290, Accuracy Top1 = 0.3516, Top5 = 0.5938
[2017-11-06 04:25:28]:
-Iter 27150, Training Loss= 0.290786, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 27150, Validation Loss= 2.739573, Accuracy Top1 = 0.4219, Top5 = 0.7031
[2017-11-06 04:26:41]:
-Iter 27200, Training Loss= 0.346445, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 27200, Validation Loss= 2.925979, Accuracy Top1 = 0.4062, Top5 = 0.6953
[2017-11-06 04:27:54]:
-Iter 27250, Training Loss= 0.307055, Accuracy Top1 = 0.9297, Top5 = 0.9844
-Iter 27250, Validation Loss= 3.106135, Accuracy Top1 = 0.4297, Top5 = 0.7109
[2017-11-06 04:29:07]:
-Iter 27300, Training Loss= 0.282926, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 27300, Validation Loss= 3.451390, Accuracy Top1 = 0.3906, Top5 = 0.6953
[2017-11-06 04:30:20]:
-Iter 27350, Training Loss= 0.341885, Accuracy Top1 = 0.8828, Top5 = 0.9844
-Iter 27350, Validation Loss= 2.869232, Accuracy Top1 = 0.3984, Top5 = 0.6875
[2017-11-06 04:31:32]:
-Iter 27400, Training Loss= 0.283087, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 27400, Validation Loss= 2.951486, Accuracy Top1 = 0.4062, Top5 = 0.6719
[2017-11-06 04:32:45]:
-Iter 27450, Training Loss= 0.261339, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 27450, Validation Loss= 3.056947, Accuracy Top1 = 0.4609, Top5 = 0.7109
[2017-11-06 04:33:58]:
-Iter 27500, Training Loss= 0.379809, Accuracy Top1 = 0.8906, Top5 = 0.9922
-Iter 27500, Validation Loss= 3.150508, Accuracy Top1 = 0.4297, Top5 = 0.6562
[2017-11-06 04:35:11]:
-Iter 27550, Training Loss= 0.194133, Accuracy Top1 = 0.9766, Top5 = 0.9922
-Iter 27550, Validation Loss= 3.152590, Accuracy Top1 = 0.3594, Top5 = 0.6484
[2017-11-06 04:36:24]:
-Iter 27600, Training Loss= 0.308198, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 27600, Validation Loss= 3.017181, Accuracy Top1 = 0.3984, Top5 = 0.6875
[2017-11-06 04:37:37]:
-Iter 27650, Training Loss= 0.243529, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 27650, Validation Loss= 2.825601, Accuracy Top1 = 0.4297, Top5 = 0.6953
[2017-11-06 04:38:50]:
-Iter 27700, Training Loss= 0.249473, Accuracy Top1 = 0.9219, Top5 = 0.9922
-Iter 27700, Validation Loss= 3.361782, Accuracy Top1 = 0.3281, Top5 = 0.6797
[2017-11-06 04:40:02]:
-Iter 27750, Training Loss= 0.240397, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 27750, Validation Loss= 2.724174, Accuracy Top1 = 0.4453, Top5 = 0.6875
[2017-11-06 04:41:15]:
-Iter 27800, Training Loss= 0.279074, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 27800, Validation Loss= 2.605978, Accuracy Top1 = 0.3984, Top5 = 0.7188
[2017-11-06 04:42:28]:
-Iter 27850, Training Loss= 0.207544, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 27850, Validation Loss= 2.856426, Accuracy Top1 = 0.4375, Top5 = 0.7188
[2017-11-06 04:43:41]:
-Iter 27900, Training Loss= 0.638797, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 27900, Validation Loss= 3.400839, Accuracy Top1 = 0.3594, Top5 = 0.6875
[2017-11-06 04:44:53]:
-Iter 27950, Training Loss= 0.273599, Accuracy Top1 = 0.9531, Top5 = 0.9844
-Iter 27950, Validation Loss= 2.537857, Accuracy Top1 = 0.4375, Top5 = 0.7891
[2017-11-06 04:46:06]:
-Iter 28000, Training Loss= 0.218977, Accuracy Top1 = 0.9688, Top5 = 0.9766
-Iter 28000, Validation Loss= 2.788649, Accuracy Top1 = 0.4219, Top5 = 0.7188
[2017-11-06 04:47:18]:
-Iter 28050, Training Loss= 0.286467, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 28050, Validation Loss= 3.072277, Accuracy Top1 = 0.3750, Top5 = 0.6719
[2017-11-06 04:48:31]:
-Iter 28100, Training Loss= 0.302766, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 28100, Validation Loss= 3.279655, Accuracy Top1 = 0.4062, Top5 = 0.6484
[2017-11-06 04:49:44]:
-Iter 28150, Training Loss= 0.293184, Accuracy Top1 = 0.9219, Top5 = 1.0000
-Iter 28150, Validation Loss= 3.093112, Accuracy Top1 = 0.2812, Top5 = 0.7266
[2017-11-06 04:50:57]:
-Iter 28200, Training Loss= 0.227237, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 28200, Validation Loss= 2.364316, Accuracy Top1 = 0.4766, Top5 = 0.7422
[2017-11-06 04:52:09]:
-Iter 28250, Training Loss= 0.498398, Accuracy Top1 = 0.8438, Top5 = 0.9766
-Iter 28250, Validation Loss= 3.102706, Accuracy Top1 = 0.3828, Top5 = 0.6719
[2017-11-06 04:53:22]:
-Iter 28300, Training Loss= 0.240278, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 28300, Validation Loss= 3.036279, Accuracy Top1 = 0.3594, Top5 = 0.6250
[2017-11-06 04:54:35]:
-Iter 28350, Training Loss= 0.263658, Accuracy Top1 = 0.9219, Top5 = 1.0000
-Iter 28350, Validation Loss= 2.373291, Accuracy Top1 = 0.4844, Top5 = 0.8047
[2017-11-06 04:55:47]:
-Iter 28400, Training Loss= 0.234030, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 28400, Validation Loss= 2.891877, Accuracy Top1 = 0.4375, Top5 = 0.7031
[2017-11-06 04:57:01]:
-Iter 28450, Training Loss= 0.318390, Accuracy Top1 = 0.9453, Top5 = 0.9922
-Iter 28450, Validation Loss= 3.366435, Accuracy Top1 = 0.3906, Top5 = 0.6406
[2017-11-06 04:58:14]:
-Iter 28500, Training Loss= 0.323348, Accuracy Top1 = 0.9062, Top5 = 0.9922
-Iter 28500, Validation Loss= 2.602066, Accuracy Top1 = 0.4688, Top5 = 0.7656
[2017-11-06 04:59:27]:
-Iter 28550, Training Loss= 0.297529, Accuracy Top1 = 0.9141, Top5 = 0.9922
-Iter 28550, Validation Loss= 3.294197, Accuracy Top1 = 0.3359, Top5 = 0.7344
[2017-11-06 05:00:39]:
-Iter 28600, Training Loss= 0.283673, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 28600, Validation Loss= 2.766952, Accuracy Top1 = 0.3516, Top5 = 0.7422
[2017-11-06 05:01:53]:
-Iter 28650, Training Loss= 0.186786, Accuracy Top1 = 0.9688, Top5 = 1.0000
-Iter 28650, Validation Loss= 3.163498, Accuracy Top1 = 0.3828, Top5 = 0.7109
[2017-11-06 05:03:05]:
-Iter 28700, Training Loss= 0.221409, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 28700, Validation Loss= 3.004355, Accuracy Top1 = 0.3438, Top5 = 0.6797
[2017-11-06 05:04:18]:
-Iter 28750, Training Loss= 0.247160, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 28750, Validation Loss= 3.081588, Accuracy Top1 = 0.4297, Top5 = 0.6797
[2017-11-06 05:05:32]:
-Iter 28800, Training Loss= 0.252801, Accuracy Top1 = 0.9297, Top5 = 0.9922
-Iter 28800, Validation Loss= 2.953861, Accuracy Top1 = 0.4297, Top5 = 0.7109
[2017-11-06 05:06:45]:
-Iter 28850, Training Loss= 0.268133, Accuracy Top1 = 0.9297, Top5 = 0.9844
-Iter 28850, Validation Loss= 2.638891, Accuracy Top1 = 0.4062, Top5 = 0.7500
[2017-11-06 05:07:57]:
-Iter 28900, Training Loss= 0.292148, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 28900, Validation Loss= 2.721634, Accuracy Top1 = 0.4375, Top5 = 0.7266
[2017-11-06 05:09:10]:
-Iter 28950, Training Loss= 0.412152, Accuracy Top1 = 0.8828, Top5 = 0.9766
-Iter 28950, Validation Loss= 3.020901, Accuracy Top1 = 0.4453, Top5 = 0.6562
[2017-11-06 05:10:23]:
-Iter 29000, Training Loss= 0.455262, Accuracy Top1 = 0.8672, Top5 = 0.9922
-Iter 29000, Validation Loss= 3.135133, Accuracy Top1 = 0.4219, Top5 = 0.7109
[2017-11-06 05:11:36]:
-Iter 29050, Training Loss= 0.251252, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 29050, Validation Loss= 2.520030, Accuracy Top1 = 0.4375, Top5 = 0.7344
[2017-11-06 05:12:49]:
-Iter 29100, Training Loss= 0.232442, Accuracy Top1 = 0.9375, Top5 = 0.9922
-Iter 29100, Validation Loss= 3.135634, Accuracy Top1 = 0.3750, Top5 = 0.7422
[2017-11-06 05:14:02]:
-Iter 29150, Training Loss= 0.309315, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 29150, Validation Loss= 3.992493, Accuracy Top1 = 0.3750, Top5 = 0.5938
[2017-11-06 05:15:15]:
-Iter 29200, Training Loss= 0.210146, Accuracy Top1 = 0.9609, Top5 = 0.9922
-Iter 29200, Validation Loss= 3.597363, Accuracy Top1 = 0.3672, Top5 = 0.6406
[2017-11-06 05:16:28]:
-Iter 29250, Training Loss= 0.369384, Accuracy Top1 = 0.8906, Top5 = 1.0000
-Iter 29250, Validation Loss= 2.807868, Accuracy Top1 = 0.4062, Top5 = 0.7266
[2017-11-06 05:17:41]:
-Iter 29300, Training Loss= 0.204850, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 29300, Validation Loss= 2.797439, Accuracy Top1 = 0.4609, Top5 = 0.7109
[2017-11-06 05:18:54]:
-Iter 29350, Training Loss= 0.256855, Accuracy Top1 = 0.9141, Top5 = 1.0000
-Iter 29350, Validation Loss= 2.885984, Accuracy Top1 = 0.4531, Top5 = 0.6953
[2017-11-06 05:20:06]:
-Iter 29400, Training Loss= 0.249549, Accuracy Top1 = 0.9453, Top5 = 0.9922
-Iter 29400, Validation Loss= 2.601180, Accuracy Top1 = 0.4375, Top5 = 0.7422
[2017-11-06 05:21:19]:
-Iter 29450, Training Loss= 0.157906, Accuracy Top1 = 0.9766, Top5 = 1.0000
-Iter 29450, Validation Loss= 2.311783, Accuracy Top1 = 0.4453, Top5 = 0.7969
[2017-11-06 05:22:32]:
-Iter 29500, Training Loss= 0.176203, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 29500, Validation Loss= 2.854847, Accuracy Top1 = 0.4141, Top5 = 0.7188
[2017-11-06 05:23:45]:
-Iter 29550, Training Loss= 0.201052, Accuracy Top1 = 0.9609, Top5 = 1.0000
-Iter 29550, Validation Loss= 2.506473, Accuracy Top1 = 0.4453, Top5 = 0.7109
[2017-11-06 05:24:58]:
-Iter 29600, Training Loss= 0.208736, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 29600, Validation Loss= 3.082619, Accuracy Top1 = 0.3594, Top5 = 0.6562
[2017-11-06 05:26:11]:
-Iter 29650, Training Loss= 0.337594, Accuracy Top1 = 0.9062, Top5 = 0.9844
-Iter 29650, Validation Loss= 2.806403, Accuracy Top1 = 0.4453, Top5 = 0.7188
[2017-11-06 05:27:23]:
-Iter 29700, Training Loss= 0.629049, Accuracy Top1 = 0.9219, Top5 = 0.9766
-Iter 29700, Validation Loss= 3.044400, Accuracy Top1 = 0.4062, Top5 = 0.7578
[2017-11-06 05:28:36]:
-Iter 29750, Training Loss= 0.208490, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 29750, Validation Loss= 2.870163, Accuracy Top1 = 0.3906, Top5 = 0.7109
[2017-11-06 05:29:50]:
-Iter 29800, Training Loss= 0.504963, Accuracy Top1 = 0.8438, Top5 = 0.9844
-Iter 29800, Validation Loss= 3.343421, Accuracy Top1 = 0.4453, Top5 = 0.6797
[2017-11-06 05:31:02]:
-Iter 29850, Training Loss= 0.163055, Accuracy Top1 = 0.9844, Top5 = 1.0000
-Iter 29850, Validation Loss= 3.229704, Accuracy Top1 = 0.3750, Top5 = 0.6953
[2017-11-06 05:32:15]:
-Iter 29900, Training Loss= 0.149587, Accuracy Top1 = 0.9609, Top5 = 0.9922
-Iter 29900, Validation Loss= 3.063696, Accuracy Top1 = 0.4375, Top5 = 0.7578
[2017-11-06 05:33:28]:
-Iter 29950, Training Loss= 0.154337, Accuracy Top1 = 0.9609, Top5 = 0.9922
-Iter 29950, Validation Loss= 3.521512, Accuracy Top1 = 0.3828, Top5 = 0.6406
Model saved at Iter 30000 !
[2017-11-06 05:34:44]:
-Iter 30000, Training Loss= 0.188394, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 30000, Validation Loss= 2.880429, Accuracy Top1 = 0.4219, Top5 = 0.6953
[2017-11-06 05:35:58]:
-Iter 30050, Training Loss= 0.415611, Accuracy Top1 = 0.8984, Top5 = 0.9844
-Iter 30050, Validation Loss= 2.972530, Accuracy Top1 = 0.3594, Top5 = 0.6562
[2017-11-06 05:37:11]:
-Iter 30100, Training Loss= 0.188392, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 30100, Validation Loss= 2.812228, Accuracy Top1 = 0.4609, Top5 = 0.7109
[2017-11-06 05:38:24]:
-Iter 30150, Training Loss= 0.198934, Accuracy Top1 = 0.9453, Top5 = 0.9922
-Iter 30150, Validation Loss= 2.958969, Accuracy Top1 = 0.4766, Top5 = 0.7344
[2017-11-06 05:39:38]:
-Iter 30200, Training Loss= 0.212991, Accuracy Top1 = 0.9297, Top5 = 0.9922
-Iter 30200, Validation Loss= 2.340911, Accuracy Top1 = 0.5234, Top5 = 0.7812
[2017-11-06 05:40:51]:
-Iter 30250, Training Loss= 0.200564, Accuracy Top1 = 0.9531, Top5 = 1.0000
-Iter 30250, Validation Loss= 2.705117, Accuracy Top1 = 0.4844, Top5 = 0.7031
[2017-11-06 05:42:05]:
-Iter 30300, Training Loss= 0.237343, Accuracy Top1 = 0.9531, Top5 = 0.9844
-Iter 30300, Validation Loss= 2.866019, Accuracy Top1 = 0.4688, Top5 = 0.7031
[2017-11-06 05:43:19]:
-Iter 30350, Training Loss= 0.181132, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 30350, Validation Loss= 3.219765, Accuracy Top1 = 0.3906, Top5 = 0.6953
[2017-11-06 05:44:32]:
-Iter 30400, Training Loss= 0.179671, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 30400, Validation Loss= 3.362242, Accuracy Top1 = 0.3984, Top5 = 0.6953
[2017-11-06 05:45:46]:
-Iter 30450, Training Loss= 0.230248, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 30450, Validation Loss= 3.083202, Accuracy Top1 = 0.3359, Top5 = 0.6562
[2017-11-06 05:47:00]:
-Iter 30500, Training Loss= 0.373201, Accuracy Top1 = 0.9297, Top5 = 0.9922
-Iter 30500, Validation Loss= 2.963013, Accuracy Top1 = 0.4219, Top5 = 0.7109
[2017-11-06 05:48:14]:
-Iter 30550, Training Loss= 0.128160, Accuracy Top1 = 0.9766, Top5 = 1.0000
-Iter 30550, Validation Loss= 2.985421, Accuracy Top1 = 0.4609, Top5 = 0.7188
[2017-11-06 05:49:27]:
-Iter 30600, Training Loss= 0.383018, Accuracy Top1 = 0.9219, Top5 = 0.9922
-Iter 30600, Validation Loss= 2.585092, Accuracy Top1 = 0.4375, Top5 = 0.7734
[2017-11-06 05:50:42]:
-Iter 30650, Training Loss= 0.301351, Accuracy Top1 = 0.8984, Top5 = 0.9922
-Iter 30650, Validation Loss= 3.033981, Accuracy Top1 = 0.3828, Top5 = 0.6953
[2017-11-06 05:51:57]:
-Iter 30700, Training Loss= 0.241063, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 30700, Validation Loss= 3.020505, Accuracy Top1 = 0.4219, Top5 = 0.6719
[2017-11-06 05:53:11]:
-Iter 30750, Training Loss= 0.188418, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 30750, Validation Loss= 3.049839, Accuracy Top1 = 0.4141, Top5 = 0.7109
[2017-11-06 05:54:25]:
-Iter 30800, Training Loss= 0.263025, Accuracy Top1 = 0.9297, Top5 = 0.9922
-Iter 30800, Validation Loss= 2.935841, Accuracy Top1 = 0.4609, Top5 = 0.7188
[2017-11-06 05:55:43]:
-Iter 30850, Training Loss= 0.259673, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 30850, Validation Loss= 3.050700, Accuracy Top1 = 0.4219, Top5 = 0.7578
[2017-11-06 05:57:01]:
-Iter 30900, Training Loss= 0.223054, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 30900, Validation Loss= 2.687020, Accuracy Top1 = 0.4688, Top5 = 0.7188
[2017-11-06 05:58:19]:
-Iter 30950, Training Loss= 0.190585, Accuracy Top1 = 0.9375, Top5 = 1.0000
-Iter 30950, Validation Loss= 3.073958, Accuracy Top1 = 0.3750, Top5 = 0.7578
[2017-11-06 05:59:38]:
-Iter 31000, Training Loss= 0.215126, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 31000, Validation Loss= 3.613119, Accuracy Top1 = 0.3828, Top5 = 0.6250
[2017-11-06 06:00:57]:
-Iter 31050, Training Loss= 0.175231, Accuracy Top1 = 0.9609, Top5 = 0.9922
-Iter 31050, Validation Loss= 3.090575, Accuracy Top1 = 0.4141, Top5 = 0.6719
[2017-11-06 06:02:16]:
-Iter 31100, Training Loss= 0.201426, Accuracy Top1 = 0.9297, Top5 = 1.0000
-Iter 31100, Validation Loss= 3.066723, Accuracy Top1 = 0.3984, Top5 = 0.7109
[2017-11-06 06:03:36]:
-Iter 31150, Training Loss= 0.144688, Accuracy Top1 = 0.9766, Top5 = 1.0000
-Iter 31150, Validation Loss= 2.999562, Accuracy Top1 = 0.4688, Top5 = 0.7266
[2017-11-06 06:04:55]:
-Iter 31200, Training Loss= 0.203223, Accuracy Top1 = 0.9453, Top5 = 1.0000
-Iter 31200, Validation Loss= 3.096045, Accuracy Top1 = 0.4375, Top5 = 0.7031
[2017-11-06 06:06:15]:
-Iter 31250, Training Loss= 0.232453, Accuracy Top1 = 0.9531, Top5 = 0.9922
-Iter 31250, Validation Loss= 3.116306, Accuracy Top1 = 0.3906, Top5 = 0.6875
Traceback (most recent call last):
  File "alexnet_bn_train.py", line 157, in <module>
    images_batch, labels_batch = loader_train.next_batch(batch_size)
  File "/home/ubuntu/6.869-MiniPlaces/model/tensorflow/DataLoader.py", line 99, in next_batch
    images_batch = np.zeros((batch_size, self.fine_size, self.fine_size, 3)) 
MemoryError
ubuntu@ip-172-31-5-64:~/6.869-MiniPlaces/model/tensorflow$ 
